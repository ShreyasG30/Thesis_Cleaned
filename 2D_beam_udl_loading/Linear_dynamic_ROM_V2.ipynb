{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def process_displacement_vector(displacement_matrix):\n",
    "    \"\"\"Process displacement matrix for 2D analysis (remove z-component).\"\"\"\n",
    "    flattened = displacement_matrix.flatten()\n",
    "    displacement_2d = flattened[np.where(np.arange(len(flattened)) % 3 != 2)]\n",
    "    return displacement_2d\n",
    "\n",
    "def analyze_matrix(matrix, name, magnitude):\n",
    "    \"\"\"Analyze a matrix and return results in a tabular format.\"\"\"\n",
    "    nonzeros = np.count_nonzero(matrix)\n",
    "    density = nonzeros / matrix.size\n",
    "    is_symmetric = np.allclose(matrix, matrix.T, rtol=1e-8, atol=1e-8)\n",
    "    max_asymmetry = np.max(np.abs(matrix - matrix.T)) if is_symmetric else 0.0\n",
    "\n",
    "    # Eigenvalue analysis\n",
    "    try:\n",
    "        eigvals = np.linalg.eigvals(matrix)\n",
    "        min_eigval = np.min(np.real(eigvals))\n",
    "        max_eigval = np.max(np.real(eigvals))\n",
    "        is_spd_eigen = True if min_eigval > 0 else False\n",
    "    except np.linalg.LinAlgError:\n",
    "        min_eigval = max_eigval = np.nan\n",
    "        is_spd_eigen = False\n",
    "\n",
    "    # Cholesky decomposition for SPD check\n",
    "    try:\n",
    "        np.linalg.cholesky(matrix)\n",
    "        is_spd_cholesky = True\n",
    "    except np.linalg.LinAlgError:\n",
    "        is_spd_cholesky = False\n",
    "\n",
    "    # Prepare table row\n",
    "    return [\n",
    "        magnitude,\n",
    "        matrix.shape,\n",
    "        matrix.dtype,\n",
    "        f\"{matrix.nbytes / 1024:.2f} KB\",\n",
    "        nonzeros,\n",
    "        f\"{density:.2%}\",\n",
    "        matrix.size - nonzeros,\n",
    "        is_symmetric,\n",
    "        f\"{max_asymmetry:.2e}\",\n",
    "        f\"{np.min(matrix):.2e}\",\n",
    "        f\"{np.max(matrix):.2e}\",\n",
    "        f\"{np.mean(matrix):.2e}\",\n",
    "        f\"{np.std(matrix):.2e}\",\n",
    "        f\"{min_eigval:.2e}\",\n",
    "        f\"{max_eigval:.2e}\",\n",
    "        is_spd_eigen,\n",
    "        is_spd_cholesky,\n",
    "    ]\n",
    "\n",
    "def analyze_vector(vector, name, magnitude):\n",
    "    \"\"\"Analyze a vector and return results in a tabular format.\"\"\"\n",
    "    nonzeros = np.count_nonzero(vector)\n",
    "    density = nonzeros / vector.size\n",
    "    return [\n",
    "        magnitude,\n",
    "        vector.shape,\n",
    "        vector.dtype,\n",
    "        f\"{vector.nbytes / 1024:.2f} KB\",\n",
    "        nonzeros,\n",
    "        f\"{density:.2%}\",\n",
    "        vector.size - nonzeros,\n",
    "        \"-\", \"-\",  # Symmetry checks (N/A for vectors)\n",
    "        f\"{np.min(vector):.2e}\",\n",
    "        f\"{np.max(vector):.2e}\",\n",
    "        f\"{np.mean(vector):.2e}\",\n",
    "        f\"{np.std(vector):.2e}\",\n",
    "        \"-\", \"-\",  # Eigenvalue analysis (N/A for vectors)\n",
    "        \"-\", \"-\",  # Symmetry checks (N/A for vectors)\n",
    "    ]\n",
    "\n",
    "def extract_magnitude(filename):\n",
    "    \"\"\"Extract the magnitude from the filename.\"\"\"\n",
    "    start = filename.find('[')\n",
    "    end = filename.find(']')\n",
    "    if start == -1 or end == -1:\n",
    "        return None\n",
    "    magnitude_str = filename[start + 1:end]\n",
    "    return tuple(map(float, magnitude_str.split(',')))\n",
    "\n",
    "def load_and_analyze_components(folder, component_name, analysis_function):\n",
    "    \"\"\"Load and analyze components (matrices or vectors) from a folder.\"\"\"\n",
    "    files = sorted(glob.glob(os.path.join(folder, \"*.npy\")))\n",
    "    table_data = []\n",
    "    magnitudes = []\n",
    "\n",
    "    if not files:\n",
    "        print(f\"No files found in {component_name} folder.\")\n",
    "        return None, None\n",
    "\n",
    "    for file in files:\n",
    "        component = np.load(file)\n",
    "        magnitude = extract_magnitude(os.path.basename(file))\n",
    "        magnitudes.append(magnitude)\n",
    "        table_data.append(analysis_function(component, component_name, magnitude))\n",
    "\n",
    "    headers = [\n",
    "        \"Magnitude\", \"Shape\", \"Data Type\", \"Memory Size\", \"Non-Zero Elements\", \"Density\",\n",
    "        \"Zero Elements\", \"Symmetry Check\", \"Max Asymmetry\", \"Min Value\", \"Max Value\",\n",
    "        \"Mean Value\", \"Std Dev\", \"Min Eig Value\", \"Max Eig Value\", \"SPD (Eigen)\", \"Symmetric PD\"\n",
    "    ]\n",
    "    print(f\"\\nDetailed Analysis of {component_name}:\")\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "    return files, magnitudes\n",
    "\n",
    "def load_and_analyze_displacement_vectors(folder):\n",
    "    \"\"\"Load and analyze displacement vectors, including processed data.\"\"\"\n",
    "    files = sorted(glob.glob(os.path.join(folder, \"*.npy\")))\n",
    "    original_table_data = []\n",
    "    processed_table_data = []\n",
    "    magnitudes = []\n",
    "\n",
    "    if not files:\n",
    "        print(\"No files found in Displacement Vector folder.\")\n",
    "        return None, None\n",
    "\n",
    "    for file in files:\n",
    "        original_vector = np.load(file)\n",
    "        processed_vector = process_displacement_vector(original_vector)\n",
    "        magnitude = extract_magnitude(os.path.basename(file))\n",
    "        magnitudes.append(magnitude)\n",
    "\n",
    "        # Analyze both original and processed vectors\n",
    "        original_table_data.append(analyze_vector(original_vector, \"Original Displacement Vector\", magnitude))\n",
    "        processed_table_data.append(analyze_vector(processed_vector, \"Processed Displacement Vector\", magnitude))\n",
    "\n",
    "    headers = [\n",
    "        \"Magnitude\", \"Shape\", \"Data Type\", \"Memory Size\", \"Non-Zero Elements\", \"Density\",\n",
    "        \"Zero Elements\", \"Symmetry Check\", \"Max Asymmetry\", \"Min Value\", \"Max Value\",\n",
    "        \"Mean Value\", \"Std Dev\", \"Min Eig Value\", \"Max Eig Value\", \"SPD (Eigen)\", \"Symmetric PD\"\n",
    "    ]\n",
    "\n",
    "    # Print tables\n",
    "    print(\"\\nDetailed Analysis of Original Displacement Vectors:\")\n",
    "    print(tabulate(original_table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "    print(\"\\nDetailed Analysis of Processed Displacement Vectors:\")\n",
    "    print(tabulate(processed_table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "    return files, magnitudes\n",
    "\n",
    "def check_missing_files(mass_mags, stiffness_mags, disp_mags, force_mags):\n",
    "    \"\"\"Check for missing magnitudes across components and report.\"\"\"\n",
    "    all_magnitudes = set(mass_mags) & set(stiffness_mags) & set(disp_mags) & set(force_mags)\n",
    "    missing = {\n",
    "        \"Mass Matrix\": set(mass_mags) - all_magnitudes,\n",
    "        \"Stiffness Matrix\": set(stiffness_mags) - all_magnitudes,\n",
    "        \"Displacement Vector\": set(disp_mags) - all_magnitudes,\n",
    "        \"Force Vector\": set(force_mags) - all_magnitudes,\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== Missing Files Report ===\")\n",
    "    for component, missing_mags in missing.items():\n",
    "        if missing_mags:\n",
    "            print(f\" - Missing in {component}: {missing_mags}\")\n",
    "        else:\n",
    "            print(f\" - All magnitudes present in {component}.\")\n",
    "\n",
    "def final_compatibility_check(M, K, x, f):\n",
    "    \"\"\"Perform final compatibility check for dimensions.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"FINAL COMPATIBILITY CHECK\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    print(f\"Mass matrix shape: {M.shape}\")\n",
    "    print(f\"Stiffness matrix shape: {K.shape}\")\n",
    "    print(f\"2D Displacement vector shape: {x[0].shape}\")\n",
    "    print(f\"Force vector shape: {f[0].shape}\")\n",
    "\n",
    "    incompatible = []\n",
    "    if M.shape != K.shape:\n",
    "        incompatible.append(\"Mass and Stiffness matrices have different dimensions.\")\n",
    "    if M.shape[1] != x[0].shape[0]:\n",
    "        incompatible.append(\"Matrix and displacement vector dimensions don't match.\")\n",
    "    if M.shape[1] != f[0].shape[0]:\n",
    "        incompatible.append(\"Matrix and force vector dimensions don't match.\")\n",
    "\n",
    "    if incompatible:\n",
    "        print(\"\\nWARNING: Found incompatibilities:\")\n",
    "        for issue in incompatible:\n",
    "            print(f\" - {issue}\")\n",
    "    else:\n",
    "        print(\"\\nAll components have compatible dimensions!\")\n",
    "        print(\"\\nAvailable components:\")\n",
    "        print(f\"M: Shape {M.shape}\")\n",
    "        print(f\"K: Shape {K.shape}\")\n",
    "        print(f\"x_original: {len(x)} vectors\")\n",
    "        print(f\"x: {x[0].shape} (Processed)\")\n",
    "        print(f\"f: {len(f)} vectors\")\n",
    "        print(\"is_compatible: True\")\n",
    "        print(\"loaded_successfully: True\")\n",
    "        print(\"compatibility_checked: True\")\n",
    "\n",
    "def load_structural_matrices():\n",
    "    \"\"\"Load and analyze all structural matrices and vectors.\"\"\"\n",
    "    current_path = os.getcwd()\n",
    "    kratos_results_path = os.path.join(current_path, \"Kratos_Results\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"LOADING MASS MATRIX\")\n",
    "    print(\"=\" * 50)\n",
    "    mass_folder = os.path.join(kratos_results_path, \"mass_results\")\n",
    "    M_files, mass_magnitudes = load_and_analyze_components(mass_folder, \"Mass Matrix\", analyze_matrix)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"LOADING STIFFNESS MATRIX\")\n",
    "    print(\"=\" * 50)\n",
    "    stiffness_folder = os.path.join(kratos_results_path, \"stiffness_results\")\n",
    "    K_files, stiffness_magnitudes = load_and_analyze_components(stiffness_folder, \"Stiffness Matrix\", analyze_matrix)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"LOADING DISPLACEMENT VECTOR\")\n",
    "    print(\"=\" * 50)\n",
    "    displacement_folder = os.path.join(kratos_results_path, \"displacement_results\")\n",
    "    x_files, disp_magnitudes = load_and_analyze_displacement_vectors(displacement_folder)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"LOADING FORCE VECTOR\")\n",
    "    print(\"=\" * 50)\n",
    "    force_folder = os.path.join(kratos_results_path, \"loading_results\")\n",
    "    f_files, force_magnitudes = load_and_analyze_components(force_folder, \"Force Vector\", analyze_vector)\n",
    "\n",
    "    # Check if all magnitudes are identical\n",
    "    if (\n",
    "        mass_magnitudes == stiffness_magnitudes == disp_magnitudes == force_magnitudes\n",
    "    ):\n",
    "        magnitudes = mass_magnitudes  # Use any of the lists as they are identical\n",
    "        print(\"\\nAll magnitudes are identical and saved under 'magnitudes'.\")\n",
    "    else:\n",
    "        print(\"\\nWarning: Magnitudes are not identical across components.\")\n",
    "        print(f\"Mass Magnitudes: {mass_magnitudes}\")\n",
    "        print(f\"Stiffness Magnitudes: {stiffness_magnitudes}\")\n",
    "        print(f\"Displacement Magnitudes: {disp_magnitudes}\")\n",
    "        print(f\"Force Magnitudes: {force_magnitudes}\")\n",
    "        magnitudes = None\n",
    "\n",
    "    # Perform compatibility check if all components are loaded\n",
    "    if M_files and K_files and x_files and f_files:\n",
    "        # Load matrices\n",
    "        M = np.load(M_files[0])\n",
    "        K = np.load(K_files[0])\n",
    "\n",
    "        # Load displacement and force vectors as 2D arrays (612 rows, columns = number of files)\n",
    "        x_original = np.column_stack([np.load(file) for file in x_files])\n",
    "        x = np.column_stack([process_displacement_vector(np.load(file)) for file in x_files])\n",
    "        f = np.column_stack([np.load(file) for file in f_files])\n",
    "\n",
    "        final_compatibility_check(M, K, x, f)\n",
    "        print(\"\\nMatrices successfully loaded and compatibility checked!\")\n",
    "\n",
    "        return M, K, x_original, x, f, magnitudes\n",
    "    else:\n",
    "        print(\"Error: One or more required components are missing.\")\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "\n",
    "def final_compatibility_check(M, K, x, f):\n",
    "    \"\"\"Perform final compatibility check for dimensions.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"FINAL COMPATIBILITY CHECK\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    print(f\"Mass matrix shape: {M.shape}\")\n",
    "    print(f\"Stiffness matrix shape: {K.shape}\")\n",
    "    print(f\"2D Displacement vector shape: {x.shape}\")\n",
    "    print(f\"Force vector shape: {f.shape}\")\n",
    "\n",
    "    incompatible = []\n",
    "\n",
    "    # Ensure matrix row sizes match vector row sizes\n",
    "    if M.shape[0] != x.shape[0]:\n",
    "        incompatible.append(\"Mass matrix row count and displacement vector row count don't match.\")\n",
    "    if M.shape[0] != f.shape[0]:\n",
    "        incompatible.append(\"Mass matrix row count and force vector row count don't match.\")\n",
    "    if K.shape != M.shape:\n",
    "        incompatible.append(\"Mass matrix and stiffness matrix dimensions don't match.\")\n",
    "\n",
    "    # Display compatibility results\n",
    "    if incompatible:\n",
    "        print(\"\\nWARNING: Found incompatibilities:\")\n",
    "        for issue in incompatible:\n",
    "            print(f\" - {issue}\")\n",
    "    else:\n",
    "        print(\"\\nAll components have compatible dimensions!\")\n",
    "\n",
    "    # Summary of components\n",
    "    print(\"\\nAvailable components:\")\n",
    "    print(f\"M: Shape {M.shape}\")\n",
    "    print(f\"K: Shape {K.shape}\")\n",
    "    print(f\"x_original: Shape {x.shape}\")\n",
    "    print(f\"x: Shape {x.shape} (Processed)\")\n",
    "    print(f\"f: Shape {f.shape}\")\n",
    "    print(\"is_compatible:\", not incompatible)\n",
    "    print(\"loaded_successfully: True\")\n",
    "    print(\"compatibility_checked: True\")\n",
    "\n",
    "\n",
    "# Run the function\n",
    "M, K, x_original, x, f, magnitudes = load_structural_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if matrices are already loaded\n",
    "if 'M' in globals() and 'K' in globals() and 'x' in globals() and 'f' in globals():\n",
    "    print(\"Matrices are already loaded and ready for boundary condition application.\")\n",
    "else:\n",
    "    print(\"Error: Matrices are not loaded. Please run `load_structural_matrices()` first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_boundary_conditions_multiple_components_with_nodes(M, K, f, magnitudes):\n",
    "    \"\"\"\n",
    "    Apply boundary conditions to the Mass matrix, Stiffness matrix, and Force vectors\n",
    "    for multiple cases. Provides a tabulated summary of the constrained DOFs and Nodes for each file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Locate .mdpa file\n",
    "        base_path = Path.cwd()\n",
    "        mdpa_file = next(base_path.glob('*.mdpa'), None)\n",
    "        if not mdpa_file:\n",
    "            raise FileNotFoundError(\"No .mdpa file found in the current directory.\")\n",
    "        print(f\"Using .mdpa file: {mdpa_file.name}\")\n",
    "\n",
    "        # Parse .mdpa file to identify fixed nodes\n",
    "        nodes = {}\n",
    "        fixed_nodes = set()\n",
    "        with open(mdpa_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        reading_nodes = False\n",
    "        reading_fixed = False\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif \"Begin SubModelPart DISPLACEMENT_fixed\" in line or \"Begin SubModelPart DISPLACEMENT_Fixed\" in line:\n",
    "                reading_fixed = True\n",
    "                continue\n",
    "            elif \"End SubModelPart\" in line:\n",
    "                reading_fixed = False\n",
    "                continue\n",
    "\n",
    "            if reading_nodes:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    node_id = int(parts[0])\n",
    "                    x_coord, y_coord, z_coord = map(float, parts[1:4])\n",
    "                    nodes[node_id] = (x_coord, y_coord, z_coord)\n",
    "\n",
    "            if reading_fixed:\n",
    "                try:\n",
    "                    node_id = int(line)\n",
    "                    print(f\"Found fixed node: {node_id}\")\n",
    "                    fixed_nodes.add(node_id)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        # Apply penalty method for boundary conditions\n",
    "        penalty_factor = 1e12\n",
    "        max_stiffness = np.max(np.abs(K))\n",
    "        penalty = penalty_factor * max_stiffness\n",
    "\n",
    "        print(\"\\nApplying boundary conditions to Mass, Stiffness, and Force for multiple cases...\")\n",
    "        summary_data = []\n",
    "        headers = [\"File Index\", \"Magnitude\", \"Node Numbers\", \"Constrained DOFs (Applied Nodes)\"]\n",
    "\n",
    "        # Initialize constrained matrices\n",
    "        M_constrained = np.copy(M)\n",
    "        K_constrained = np.copy(K)\n",
    "        f_constrained = np.copy(f)\n",
    "\n",
    "        for file_index in range(f.shape[1]):  # Loop through each case\n",
    "            applied_dofs = []\n",
    "            applied_nodes = []\n",
    "            for node_id in fixed_nodes:\n",
    "                x_dof = (node_id - 1) * 2\n",
    "                y_dof = x_dof + 1\n",
    "\n",
    "                # Apply penalties to M, K, and f for this file\n",
    "                M_constrained[x_dof, x_dof] = penalty\n",
    "                M_constrained[y_dof, y_dof] = penalty\n",
    "                K_constrained[x_dof, x_dof] = penalty\n",
    "                K_constrained[y_dof, y_dof] = penalty\n",
    "                f_constrained[x_dof, file_index] = 0.0\n",
    "                f_constrained[y_dof, file_index] = 0.0\n",
    "\n",
    "                applied_dofs.append(f\"{x_dof} (X), {y_dof} (Y)\")\n",
    "                applied_nodes.append(node_id)\n",
    "\n",
    "            # Append to summary table\n",
    "            summary_data.append(\n",
    "                [file_index + 1, magnitudes[file_index], \", \".join(map(str, applied_nodes)), \", \".join(applied_dofs)]\n",
    "            )\n",
    "\n",
    "        # Print summary table\n",
    "        print(\"\\nBoundary Condition Application Summary for Mass, Stiffness, and Force:\")\n",
    "        print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "        print(\"\\nBoundary conditions applied successfully!\")\n",
    "        print(f\"Number of constrained DOFs: {len(fixed_nodes) * 2}\")\n",
    "\n",
    "        return M_constrained, K_constrained, f_constrained, fixed_nodes\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying boundary conditions: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "\n",
    "# Main Execution\n",
    "try:\n",
    "    # Ensure matrices and vectors are loaded\n",
    "    if 'M' in globals() and 'K' in globals() and 'f' in globals() and 'magnitudes' in globals():\n",
    "        print(\"Matrices are already loaded and ready for boundary condition application.\")\n",
    "    else:\n",
    "        print(\"Error: Matrices are not loaded. Please load them using the proper function.\")\n",
    "\n",
    "    # Apply boundary conditions\n",
    "    print(\"\\nApplying boundary conditions for Mass, Stiffness, and Force across multiple cases...\")\n",
    "    M_constrained, K_constrained, f_constrained, fixed_nodes = apply_boundary_conditions_multiple_components_with_nodes(M, K, f, magnitudes)\n",
    "\n",
    "    if M_constrained is not None:\n",
    "        print(\"\\nVerification of constrained system:\")\n",
    "        print(f\"Original Mass Matrix Shape: {M.shape}\")\n",
    "        print(f\"Constrained Mass Matrix Shape: {M_constrained.shape}\")\n",
    "        print(f\"Original Stiffness Matrix Shape: {K.shape}\")\n",
    "        print(f\"Constrained Stiffness Matrix Shape: {K_constrained.shape}\")\n",
    "        print(f\"Original Force Vector Shape: {f.shape}\")\n",
    "        print(f\"Constrained Force Vector Shape: {f_constrained.shape}\")\n",
    "        print(f\"Number of constrained DOFs: {len(fixed_nodes) * 2}\")\n",
    "    else:\n",
    "        print(\"Boundary conditions could not be applied.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during boundary condition application: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_force_vectors_multiple(f_list, f_constrained_list, magnitudes):\n",
    "    \"\"\"\n",
    "    Compare multiple sets of original and constrained force vectors.\n",
    "    Display differences in a tabular format with magnitude headings.\n",
    "    \"\"\"\n",
    "    # Ensure inputs are NumPy arrays and have correct dimensions\n",
    "    if not isinstance(f_list, np.ndarray) or not isinstance(f_constrained_list, np.ndarray):\n",
    "        raise ValueError(\"f_list and f_constrained_list must be NumPy arrays.\")\n",
    "\n",
    "    # Check the shapes of the input arrays\n",
    "    if f_list.shape != f_constrained_list.shape:\n",
    "        raise ValueError(\"f_list and f_constrained_list must have the same shape.\")\n",
    "    if f_list.shape[1] != len(magnitudes):\n",
    "        raise ValueError(\"The number of magnitudes does not match the number of force vector files.\")\n",
    "\n",
    "    # Prepare summary table\n",
    "    summary_data = []\n",
    "    headers = [\"File Index\", \"Magnitude\", \"Total DOFs\", \"Non-Zero DOFs (Original)\", \"Non-Zero DOFs (Constrained)\", \"Differences Found\"]\n",
    "\n",
    "    # Iterate over each file (column)\n",
    "    for i, magnitude in enumerate(magnitudes):\n",
    "        f = f_list[:, i]\n",
    "        f_constrained = f_constrained_list[:, i]\n",
    "\n",
    "        # Check if the force vectors are identical within a tolerance\n",
    "        are_equal = np.allclose(f, f_constrained, rtol=1e-10)\n",
    "\n",
    "        # Compute differences\n",
    "        diff = np.abs(f - f_constrained)\n",
    "        different_dofs = np.where(diff > 1e-10)[0]  # Identify DOFs with significant differences\n",
    "        num_diff_dofs = len(different_dofs)\n",
    "\n",
    "        # Count non-zero elements\n",
    "        non_zero_original = np.count_nonzero(f)\n",
    "        non_zero_constrained = np.count_nonzero(f_constrained)\n",
    "\n",
    "        # Append results to the summary table\n",
    "        summary_data.append([\n",
    "            i + 1,\n",
    "            magnitude,\n",
    "            f.shape[0],\n",
    "            non_zero_original,\n",
    "            non_zero_constrained,\n",
    "            num_diff_dofs,\n",
    "        ])\n",
    "\n",
    "    # Print summary table\n",
    "    print(\"\\nForce Vector Comparison Summary:\")\n",
    "    print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "    # Detailed differences for each file\n",
    "    for i, magnitude in enumerate(magnitudes):\n",
    "        f = f_list[:, i]\n",
    "        f_constrained = f_constrained_list[:, i]\n",
    "\n",
    "        # Compute differences\n",
    "        diff = np.abs(f - f_constrained)\n",
    "        different_dofs = np.where(diff > 1e-10)[0]  # Identify DOFs with significant differences\n",
    "\n",
    "        if len(different_dofs) > 0:\n",
    "            print(f\"\\nDetailed Differences for File {i + 1} (Magnitude: {magnitude}):\")\n",
    "            headers = [\"DOF\", \"Node\", \"Original Value\", \"Constrained Value\", \"Difference\"]\n",
    "            table_data = []\n",
    "\n",
    "            for dof in different_dofs:\n",
    "                # Determine the corresponding node and DOF (assuming 2 DOFs per node)\n",
    "                node = dof // 2 + 1\n",
    "                dof_label = \"X\" if dof % 2 == 0 else \"Y\"\n",
    "                table_data.append([dof_label, node, f[dof], f_constrained[dof], diff[dof]])\n",
    "\n",
    "            print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "        else:\n",
    "            print(f\"\\nNo significant differences found for File {i + 1} (Magnitude: {magnitude}).\")\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    print(\"\\nComparing force vectors for multiple files...\")\n",
    "    # Assuming `f` is a NumPy array of shape (DOFs, Files)\n",
    "    # `f_constrained` is a NumPy array of shape (DOFs, Files)\n",
    "    # `magnitudes` is a list of magnitudes corresponding to the force vector files\n",
    "    compare_force_vectors_multiple(f, f_constrained, magnitudes)\n",
    "except Exception as e:\n",
    "    print(f\"Error during force vector comparison: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bc_applied_to_force(f_constrained, magnitudes, threshold=1e-7):\n",
    "    \"\"\"\n",
    "    Check whether boundary conditions (BC) have been applied to the constrained force vectors.\n",
    "    Display results in a tabular format with magnitude headings.\n",
    "    \"\"\"\n",
    "    # Convert 2D `f_constrained` to a list of vectors if necessary\n",
    "    if isinstance(f_constrained, np.ndarray) and len(f_constrained.shape) == 2:\n",
    "        print(\"Converting 2D array `f_constrained` to a list of vectors.\")\n",
    "        f_constrained = [f_constrained[:, i] for i in range(f_constrained.shape[1])]\n",
    "\n",
    "    # Ensure lengths match\n",
    "    if len(f_constrained) != len(magnitudes):\n",
    "        print(f\"Error: The number of constrained force vectors ({len(f_constrained)}) \"\n",
    "              f\"does not match the number of magnitudes ({len(magnitudes)}).\")\n",
    "        return\n",
    "\n",
    "    # Prepare table headers\n",
    "    headers = [\"File Index\", \"Magnitude\", \"DOF\", \"Node\", \"Direction\", \"Value\"]\n",
    "    summary_data = []\n",
    "\n",
    "    for file_idx, (f_cons, magnitude) in enumerate(zip(f_constrained, magnitudes)):\n",
    "        # Find non-zero DOFs\n",
    "        non_zero_indices = np.where(abs(f_cons) > threshold)[0]\n",
    "        if len(non_zero_indices) == 0:\n",
    "            print(f\"All DOFs are zero for Magnitude {magnitude}.\")\n",
    "            continue\n",
    "\n",
    "        # Collect data for the table\n",
    "        for dof in non_zero_indices:\n",
    "            node = dof // 2 + 1  # Calculate node ID\n",
    "            direction = \"X\" if dof % 2 == 0 else \"Y\"\n",
    "            value = f_cons[dof]\n",
    "            summary_data.append([file_idx + 1, magnitude, dof, node, direction, value])\n",
    "\n",
    "    # Print the table\n",
    "    if summary_data:\n",
    "        print(\"\\nBoundary Conditions Applied - Detailed Report:\")\n",
    "        print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "    else:\n",
    "        print(\"No non-zero entries found in the constrained force vectors.\")\n",
    "\n",
    "# Example Usage\n",
    "try:\n",
    "    print(\"\\nChecking if boundary conditions are applied to constrained force vectors...\")\n",
    "    # Pass `f_constrained` and `magnitudes` to the function\n",
    "    check_bc_applied_to_force(f_constrained, magnitudes)\n",
    "except Exception as e:\n",
    "    print(f\"Error during boundary condition check: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bc_applied_to_force(f_constrained, magnitudes, threshold=1e-7):\n",
    "    \"\"\"\n",
    "    Check whether boundary conditions (BC) have been applied to the constrained force vectors.\n",
    "    Display results in a tabular format with magnitude headings.\n",
    "    \"\"\"\n",
    "    # Convert 2D f_constrained to a list of vectors if necessary\n",
    "    if isinstance(f_constrained, np.ndarray) and len(f_constrained.shape) == 2:\n",
    "        print(\"Converting 2D array f_constrained to a list of vectors.\")\n",
    "        f_constrained = [f_constrained[:, i] for i in range(f_constrained.shape[1])]\n",
    "\n",
    "    # Ensure lengths match\n",
    "    if len(f_constrained) != len(magnitudes):\n",
    "        print(f\"Error: The number of constrained force vectors ({len(f_constrained)}) \"\n",
    "              f\"does not match the number of magnitudes ({len(magnitudes)}).\")\n",
    "        return\n",
    "\n",
    "    # Prepare table headers\n",
    "    summary_headers = [\"File Index\", \"Magnitude\", \"Non-Zero DOFs\"]\n",
    "    details_headers = [\"File Index\", \"Magnitude\", \"DOF\", \"Node\", \"Direction\", \"Value\"]\n",
    "\n",
    "    summary_data = []\n",
    "    details_data = []\n",
    "\n",
    "    for file_idx, (f_cons, magnitude) in enumerate(zip(f_constrained, magnitudes)):\n",
    "        # Find non-zero DOFs\n",
    "        non_zero_indices = np.where(abs(f_cons) > threshold)[0]\n",
    "\n",
    "        # Add summary information\n",
    "        summary_data.append([\n",
    "            file_idx + 1,\n",
    "            magnitude,\n",
    "            len(non_zero_indices),\n",
    "        ])\n",
    "\n",
    "        # Add details for non-zero DOFs\n",
    "        for dof in non_zero_indices:\n",
    "            node = dof // 2 + 1  # Calculate node ID\n",
    "            direction = \"X\" if dof % 2 == 0 else \"Y\"\n",
    "            details_data.append([\n",
    "                file_idx + 1,\n",
    "                magnitude,\n",
    "                dof,\n",
    "                node,\n",
    "                direction,\n",
    "                f_cons[dof],\n",
    "            ])\n",
    "\n",
    "    # Print the summary table\n",
    "    print(\"\\nBoundary Conditions Summary:\")\n",
    "    print(tabulate(summary_data, headers=summary_headers, tablefmt=\"grid\"))\n",
    "\n",
    "    # Print the detailed table if there are non-zero DOFs\n",
    "    if details_data:\n",
    "        print(\"\\nNon-Zero DOFs Details:\")\n",
    "        print(tabulate(details_data, headers=details_headers, tablefmt=\"grid\"))\n",
    "    else:\n",
    "        print(\"\\nAll DOFs are zero across all cases.\")\n",
    "\n",
    "# Example Usage\n",
    "try:\n",
    "    print(\"\\nChecking if boundary conditions are applied to constrained force vectors...\")\n",
    "    # Pass f_constrained and magnitudes to the function\n",
    "    check_bc_applied_to_force(f_constrained, magnitudes)\n",
    "except Exception as e:\n",
    "    print(f\"Error during boundary condition check: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_loads_to_force_vector_multiple_cases(f, f_constrained, fixed_dofs, magnitudes, mdpa_file):\n",
    "    \"\"\"\n",
    "    Apply loads to force vectors for multiple cases using a single `.mdpa` file and magnitude values.\n",
    "    Display the results in a well-structured tabular format with the specified format.\n",
    "    \"\"\"\n",
    "    # Extract load nodes from the `.mdpa` file\n",
    "    load_nodes = {'LinePressure2D_Load_1': [], 'LinePressure2D_Load_2': [], 'LinePressure2D_Load_3': []}\n",
    "    current_load = None\n",
    "    reading_nodes = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin SubModelPart LinePressure2D_Load_1\" in line or \"Begin SubModelPart PointLoad2D_Load_1\" in line:\n",
    "                current_load = 'LinePressure2D_Load_1'\n",
    "            elif \"Begin SubModelPart LinePressure2D_Load_2\" in line or \"Begin SubModelPart PointLoad2D_Load_2\" in line:\n",
    "                current_load = 'LinePressure2D_Load_2'\n",
    "            elif \"Begin SubModelPart LinePressure2D_Load_3\" in line or \"Begin SubModelPart PointLoad2D_Load_3\" in line:\n",
    "                current_load = 'LinePressure2D_Load_3'\n",
    "            elif \"End SubModelPart\" in line:\n",
    "                current_load = None\n",
    "                reading_nodes = False\n",
    "            elif current_load and \"Begin SubModelPartNodes\" in line:\n",
    "                reading_nodes = True\n",
    "            elif current_load and \"End SubModelPartNodes\" in line:\n",
    "                reading_nodes = False\n",
    "            elif reading_nodes and current_load and line:\n",
    "                try:\n",
    "                    node = int(line)\n",
    "                    load_nodes[current_load].append(node)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "    # Prepare results for tabular output\n",
    "    headers = [\"File Index\", \"Magnitude\", \"Load 1 (Value, Direction)\", \"Nodes (DOF)\", \n",
    "               \"Load 2 (Value, Direction)\", \"Nodes (DOF)\", \"Load 3 (Value, Direction)\", \"Nodes (DOF)\"]\n",
    "    table_data = []\n",
    "\n",
    "    print(\"\\nApplying loads to constrained force vectors for multiple cases...\")\n",
    "    for i, magnitude in enumerate(magnitudes):\n",
    "        load_1_details = []\n",
    "        load_2_details = []\n",
    "        load_3_details = []\n",
    "\n",
    "        # Apply loads and collect node/DOF information\n",
    "        for load_name, nodes in load_nodes.items():\n",
    "            if load_name == 'LinePressure2D_Load_1':  # Use the first value of magnitude for vertical load\n",
    "                value = magnitude[0]\n",
    "                for node in nodes:\n",
    "                    dof_y = (node - 1) * 2 + 1\n",
    "                    f_constrained[dof_y, i] = value\n",
    "                    load_1_details.append(f\"{node} (Y-DOF {dof_y})\")\n",
    "            elif load_name == 'LinePressure2D_Load_2':  # Use the second value of magnitude for horizontal load\n",
    "                value = magnitude[1]\n",
    "                for node in nodes:\n",
    "                    dof_x = (node - 1) * 2\n",
    "                    f_constrained[dof_x, i] = value\n",
    "                    load_2_details.append(f\"{node} (X-DOF {dof_x})\")\n",
    "            elif load_name == 'LinePressure2D_Load_3':  # Use the third value of magnitude for horizontal load\n",
    "                value = magnitude[2]\n",
    "                for node in nodes:\n",
    "                    dof_x = (node - 1) * 2\n",
    "                    f_constrained[dof_x, i] = value\n",
    "                    load_3_details.append(f\"{node} (X-DOF {dof_x})\")\n",
    "\n",
    "        # Zero out forces at constrained DOFs\n",
    "        for dof in fixed_dofs:\n",
    "            f_constrained[dof, i] = 0.0\n",
    "\n",
    "        # Add to the summary table\n",
    "        table_data.append([\n",
    "            i + 1,\n",
    "            magnitude,\n",
    "            f\"{magnitude[0]} (Y)\",\n",
    "            \", \".join(load_1_details),\n",
    "            f\"{magnitude[1]} (X)\",\n",
    "            \", \".join(load_2_details),\n",
    "            f\"{magnitude[2]} (X)\",\n",
    "            \", \".join(load_3_details)\n",
    "        ])\n",
    "\n",
    "    # Display summary table\n",
    "    print(\"\\nLoad Application Summary:\")\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "    print(\"\\nLoads successfully applied to all cases.\")\n",
    "    return f_constrained\n",
    "\n",
    "# Example Usage\n",
    "try:\n",
    "    print(\"\\nApplying loads to constrained force vectors for multiple cases...\")\n",
    "    # Dynamic file reading\n",
    "    folder_path = Path.cwd()\n",
    "    mdpa_file = next(folder_path.glob(\"*.mdpa\"), None)\n",
    "\n",
    "    if mdpa_file:\n",
    "        print(f\"Using MDPA file: {mdpa_file.name}\")\n",
    "\n",
    "        # Assuming `f`, `f_constrained`, `fixed_nodes`, and `magnitudes` are already defined\n",
    "        f_constrained = apply_loads_to_force_vector_multiple_cases(\n",
    "            f=f,\n",
    "            f_constrained=f_constrained,\n",
    "            fixed_dofs=list(fixed_nodes),\n",
    "            magnitudes=magnitudes,  # Magnitudes is a list of tuples (e.g., [(-213.96, -286.3, 284.39), ...])\n",
    "            mdpa_file=mdpa_file\n",
    "        )\n",
    "    else:\n",
    "        print(\"Error: MDPA file not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "def solve_newmark_dynamic_single_case(structural_components, initial_displacement, total_time, dt, \n",
    "                                     beta, gamma, tol, max_iter):\n",
    "    M = structural_components['M_constrained']\n",
    "    K = structural_components['K_constrained']\n",
    "    F = structural_components['f_constrained']\n",
    "    n = M.shape[0]\n",
    "\n",
    "    n_steps = int(total_time / dt) + 1\n",
    "    t = np.linspace(0, total_time, n_steps)\n",
    "\n",
    "    x = np.zeros((n_steps, n))\n",
    "    xdot = np.zeros((n_steps, n))\n",
    "    xddot = np.zeros((n_steps, n))\n",
    "    x[0, :] = initial_displacement\n",
    "\n",
    "    c1 = 1 / (beta * dt**2)\n",
    "    c2 = gamma / (beta * dt)\n",
    "    c3 = 1 / (beta * dt)\n",
    "    c5 = (1 - 2 * beta) / (2 * beta)\n",
    "    K_eff = K + c1 * M\n",
    "\n",
    "    iterations_per_step = []\n",
    "    residuals_per_step = []\n",
    "    convergence_status = []\n",
    "    converged_steps = 0\n",
    "    non_converged_steps = []\n",
    "\n",
    "    for i in range(1, n_steps):\n",
    "        F_ext = F\n",
    "        x_pred = x[i - 1, :]\n",
    "        xdot_pred = xdot[i - 1, :]\n",
    "        xddot_pred = xddot[i - 1, :]\n",
    "        x_new = x_pred.copy()\n",
    "\n",
    "        converged = False\n",
    "        for iteration in range(max_iter):\n",
    "            acc_term = x_pred * c1 + xdot_pred * c3 + xddot_pred * c5\n",
    "            F_eff = F_ext + M @ acc_term\n",
    "            R = F_eff - K_eff @ x_new\n",
    "            delta_x = np.linalg.solve(K_eff, R)\n",
    "            x_new += delta_x\n",
    "\n",
    "            residual_norm = np.linalg.norm(R)\n",
    "            residuals_per_step.append(residual_norm)\n",
    "\n",
    "            if np.linalg.norm(delta_x) < tol:\n",
    "                converged = True\n",
    "                converged_steps += 1\n",
    "                break\n",
    "\n",
    "        iterations_per_step.append(iteration + 1)\n",
    "        convergence_status.append(converged)\n",
    "\n",
    "        if not converged:\n",
    "            non_converged_steps.append((i, iteration + 1))\n",
    "            print(f\"[Warning] Time step {i} did not converge within {max_iter} iterations. Final residual norm: {residual_norm:.2e}\")\n",
    "\n",
    "        xddot[i, :] = (x_new - x_pred) / (beta * dt**2) - xdot_pred / (beta * dt) - ((1 / (2 * beta)) - 1) * xddot_pred\n",
    "        xdot[i, :] = xdot_pred + dt * ((1 - gamma) * xddot_pred + gamma * xddot[i, :])\n",
    "        x[i, :] = x_new\n",
    "\n",
    "    # Compute internal force F = M*a + K*u\n",
    "    force = np.zeros_like(x)\n",
    "    for i in range(n_steps):\n",
    "        force[i, :] = M @ xddot[i, :] + K @ x[i, :]\n",
    "\n",
    "    if non_converged_steps:\n",
    "        print(\"\\n⚠️ Non-Converged Time Steps Summary:\")\n",
    "        for step_id, iters in non_converged_steps:\n",
    "            print(f\"  - Time step {step_id} failed to converge in {iters} iterations.\")\n",
    "    else:\n",
    "        print(\"✅ All time steps converged successfully.\")\n",
    "\n",
    "    return {\n",
    "        'time': t,\n",
    "        'displacement': x,\n",
    "        'velocity': xdot,\n",
    "        'acceleration': xddot,\n",
    "        'force': force,\n",
    "        'iterations_per_step': np.array(iterations_per_step),\n",
    "        'residuals_per_step': residuals_per_step,\n",
    "        'converged_steps': converged_steps,\n",
    "        'convergence_status': np.array(convergence_status),\n",
    "        'non_converged_steps': non_converged_steps,\n",
    "        'scales': {'M_scale': 1, 'K_scale': 1, 'F_scale': 1}\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_and_print_results(case_results, case_times, magnitudes):\n",
    "    \"\"\"\n",
    "    Analyze results from all cases and print detailed tabulated information\n",
    "    \"\"\"\n",
    "    n_cases = len(case_results)\n",
    "    \n",
    "    # Prepare data for summary table\n",
    "    summary_data = []\n",
    "    convergence_data = []\n",
    "    performance_data = []\n",
    "    \n",
    "    for idx, (results, solve_time, magnitude) in enumerate(zip(case_results, case_times, magnitudes)):\n",
    "        iterations = results['iterations_per_step']\n",
    "        residuals = results['residuals_per_step']\n",
    "        conv_status = results['convergence_status']\n",
    "        n_steps = len(results['time'])\n",
    "        \n",
    "        # Summary statistics\n",
    "        converged_steps = np.sum(conv_status)\n",
    "        non_converged = n_steps - converged_steps\n",
    "        max_disp = np.max(np.abs(results['displacement']))\n",
    "        max_vel = np.max(np.abs(results['velocity']))\n",
    "        max_acc = np.max(np.abs(results['acceleration']))\n",
    "        \n",
    "        # Iteration statistics\n",
    "        converged_iters = iterations[conv_status]\n",
    "        avg_iters = np.mean(converged_iters) if len(converged_iters) > 0 else 0\n",
    "        max_iters = np.max(iterations)\n",
    "        min_iters = np.min(converged_iters) if len(converged_iters) > 0 else 0\n",
    "        \n",
    "        # Add to summary table\n",
    "        summary_data.append([\n",
    "            idx + 1,\n",
    "            str(magnitude),\n",
    "            f\"{max_disp:.2e}\",\n",
    "            f\"{max_vel:.2e}\",\n",
    "            f\"{max_acc:.2e}\",\n",
    "            f\"{solve_time:.2f}\"\n",
    "        ])\n",
    "        \n",
    "        # Add to convergence table\n",
    "        convergence_data.append([\n",
    "            idx + 1,\n",
    "            str(magnitude),\n",
    "            converged_steps,\n",
    "            non_converged,\n",
    "            f\"{(converged_steps/n_steps)*100:.1f}%\",\n",
    "            f\"{min_iters:.1f}\",\n",
    "            f\"{avg_iters:.1f}\",\n",
    "            max_iters\n",
    "        ])\n",
    "        \n",
    "        # Collect iteration distribution\n",
    "        iter_dist = {}\n",
    "        for i in range(1, max_iters + 1):\n",
    "            count = np.sum(iterations == i)\n",
    "            if count > 0:\n",
    "                iter_dist[i] = count\n",
    "        \n",
    "        # Add to performance table\n",
    "        performance_data.append([\n",
    "            idx + 1,\n",
    "            str(magnitude),\n",
    "            f\"{np.min(residuals):.2e}\",\n",
    "            f\"{np.mean(residuals):.2e}\",\n",
    "            f\"{np.max(residuals):.2e}\",\n",
    "            f\"{solve_time/n_steps:.4f}\",\n",
    "            str(iter_dist)\n",
    "        ])\n",
    "    \n",
    "    # Print Summary Table\n",
    "    print(\"\\nResults Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    headers = [\"Case\", \"Magnitude\", \"Max Displacement\", \"Max Velocity\", \"Max Acceleration\", \"Solve Time (s)\"]\n",
    "    print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "    # Print Convergence Table\n",
    "    print(\"\\nConvergence Analysis:\")\n",
    "    print(\"=\" * 80)\n",
    "    headers = [\"Case\", \"Magnitude\", \"Converged Steps\", \"Non-converged\", \"Success Rate\", \n",
    "              \"Min Iters\", \"Avg Iters\", \"Max Iters\"]\n",
    "    print(tabulate(convergence_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "    # Print Performance Table\n",
    "    print(\"\\nPerformance Analysis:\")\n",
    "    print(\"=\" * 80)\n",
    "    headers = [\"Case\", \"Magnitude\", \"Min Residual\", \"Avg Residual\", \"Max Residual\", \n",
    "              \"Time per Step (s)\", \"Iteration Distribution\"]\n",
    "    print(tabulate(performance_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "    # Print Overall Statistics\n",
    "    print(\"\\nOverall Statistics:\")\n",
    "    print(\"=\" * 80)\n",
    "    total_time = np.sum(case_times)\n",
    "    print(f\"Total computation time: {total_time:.2f} seconds\")\n",
    "    print(f\"Average time per case: {total_time/n_cases:.2f} seconds\")\n",
    "    print(f\"Number of cases: {n_cases}\")\n",
    "    print(f\"Fastest case: {np.min(case_times):.2f} seconds (Case {np.argmin(case_times)+1})\")\n",
    "    print(f\"Slowest case: {np.max(case_times):.2f} seconds (Case {np.argmax(case_times)+1})\")\n",
    "\n",
    "def save_case_results(results, case_dir):\n",
    "    solution_dir = case_dir / 'solution'\n",
    "    solution_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    np.save(solution_dir / 'time.npy', results['time'])\n",
    "    np.save(solution_dir / 'displacement.npy', results['displacement'])\n",
    "    np.save(solution_dir / 'velocity.npy', results['velocity'])\n",
    "    np.save(solution_dir / 'acceleration.npy', results['acceleration'])\n",
    "    np.save(solution_dir / 'force.npy', results['force'])\n",
    "\n",
    "    np.savez(case_dir / 'time_history.npz',\n",
    "             time=results['time'],\n",
    "             displacement=results['displacement'],\n",
    "             velocity=results['velocity'],\n",
    "             acceleration=results['acceleration'])\n",
    "\n",
    "    np.savez(case_dir / 'convergence_data.npz',\n",
    "             iterations=results['iterations_per_step'],\n",
    "             residuals=results['residuals_per_step'],\n",
    "             convergence_status=results['convergence_status'])\n",
    "\n",
    "    np.savez(case_dir / 'scaling_factors.npz', **results['scales'])\n",
    "\n",
    "    with open(case_dir / 'summary.txt', 'w') as f:\n",
    "        f.write(\"Results Summary:\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(f\"Time steps completed: {len(results['time'])}\\n\")\n",
    "        f.write(f\"Maximum displacement: {np.max(np.abs(results['displacement'])):.2e}\\n\")\n",
    "        f.write(f\"Maximum velocity: {np.max(np.abs(results['velocity'])):.2e}\\n\")\n",
    "        f.write(f\"Maximum acceleration: {np.max(np.abs(results['acceleration'])):.2e}\\n\")\n",
    "        f.write(f\"Converged steps: {np.sum(results['convergence_status'])}\\n\")\n",
    "        f.write(f\"Non-converged steps: {np.sum(~results['convergence_status'])}\\n\")\n",
    "        f.write(\"\\nFile Locations:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(f\"Solution arrays (.npy files): {solution_dir}\\n\")\n",
    "        f.write(f\"Time history: {case_dir/'time_history.npz'}\\n\")\n",
    "        f.write(f\"Convergence data: {case_dir/'convergence_data.npz'}\\n\")\n",
    "        f.write(f\"Scaling factors: {case_dir/'scaling_factors.npz'}\\n\")\n",
    "        f.write(f\"Force data: {solution_dir/'force.npy'}\\n\")\n",
    "\n",
    "\n",
    "def solve_newmark_dynamic_multi_case(M, K, f, magnitudes, x, total_time=1.0, dt=0.01, beta=0.25, gamma=0.5, tol=1e-6, max_iter=50,subfolder_name=\"Numerical_Solution\"):\n",
    "    print(\"Function called with:\")\n",
    "    print(f\"M: {M.shape}, K: {K.shape}, f: {f.shape}, magnitudes: {magnitudes}, x: {x.shape}\")\n",
    "    # Rest of the function implementation\n",
    "    \"\"\"\n",
    "    Solve dynamic system for multiple cases using Newmark-β method\n",
    "\n",
    "    Args:\n",
    "        M (np.array): Mass matrix\n",
    "        K (np.array): Stiffness matrix\n",
    "        f (np.array): Force matrix (each column corresponds to a case)\n",
    "        magnitudes (list): List of magnitudes for each case\n",
    "        x (np.array): Initial displacement matrix (each column corresponds to a case)\n",
    "        total_time (float): Total simulation time\n",
    "        dt (float): Time step size\n",
    "        beta (float): Newmark-β parameter\n",
    "        gamma (float): Newmark-γ parameter\n",
    "        tol (float): Convergence tolerance\n",
    "        max_iter (int): Maximum iterations per time step\n",
    "\n",
    "    Returns:\n",
    "        output_dir (Path): Directory where results are saved\n",
    "        case_results (list): List of results for each case\n",
    "        case_times (list): List of computation times for each case\n",
    "    \"\"\"\n",
    "    output_dir = Path(\"Dynamic_solution\")\n",
    "\n",
    "    n_dof = M.shape[0]\n",
    "    n_cases = f.shape[1]\n",
    "\n",
    "    # # Only clear and recreate the base directory for FOM (assuming large DOFs)\n",
    "    # if not output_dir.exists():\n",
    "    #     output_dir.mkdir()\n",
    "    # elif M.shape[0] >= n_dof / 2:\n",
    "    #     if subfolder_name == \"ROM_solution\":\n",
    "    #         print(f\"\\n[Error] Detected full-order system (DOFs = {M.shape[0]}) while expecting a reduced-order system.\")\n",
    "    #         print(\"Terminating execution as subfolder_name is set to 'ROM_solution'.\")\n",
    "    #         raise SystemExit(\"Execution terminated due to invalid system type.\")\n",
    "    #     # print(f\"\\nDetected full-order system (DOFs = {M.shape[0]}). Resetting folder.\")\n",
    "    #     # shutil.rmtree(output_dir)\n",
    "    #     # output_dir.mkdir()\n",
    "    # else:\n",
    "    #     print(f\"\\nROM detected (DOFs = {M.shape[0]}). Keeping existing results.\")\n",
    "    \n",
    "    # Only clear and recreate the base directory for FOM (assuming large DOFs)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    elif M.shape[0] >= n_dof / 2:\n",
    "        # Case: Large DOFs (equal to or greater than half of full system)\n",
    "        if subfolder_name == \"ROM_solution\":\n",
    "            print(f\"\\n[Error] Detected full-order system (DOFs = {M.shape[0]}) while expecting a reduced-order system.\")\n",
    "            print(f\"The model is not properly reduced (DOFs should be < {n_dof/2}).\")\n",
    "            print(\"Please check your model reduction parameters.\")\n",
    "            raise SystemExit(\"Execution terminated due to invalid system type.\")\n",
    "        elif subfolder_name == \"FOM_Solution\" and M.shape[0] == n_dof:\n",
    "            print(f\"\\nDetected full-order system (DOFs = {M.shape[0]}). Resetting folder for fresh start.\")\n",
    "            import shutil\n",
    "            shutil.rmtree(output_dir)\n",
    "            output_dir.mkdir()\n",
    "        else:\n",
    "            print(f\"\\nWarning: System DOFs ({M.shape[0]}) are large but not equal to full order ({n_dof}).\")\n",
    "            print(\"Continuing without resetting the folder.\")\n",
    "    else:\n",
    "        # Case: Small DOFs (properly reduced model)\n",
    "        if subfolder_name == \"ROM_solution\":\n",
    "            print(f\"\\nROM detected (DOFs = {M.shape[0]} < {n_dof/2}). Keeping existing results.\")\n",
    "        else:\n",
    "            print(f\"\\nSmall system detected (DOFs = {M.shape[0]}) in non-ROM folder ({subfolder_name}).\")\n",
    "            print(\"Keeping existing results.\")\n",
    "    \n",
    "    \n",
    "    print(f\"\\nStarting multi-case dynamic analysis...\")\n",
    "    print(f\"Number of DOFs: {n_dof}\")\n",
    "    print(f\"Number of cases: {n_cases}\")\n",
    "    \n",
    "    # Track results and timing for each case\n",
    "    case_results = []\n",
    "    case_times = []\n",
    "    \n",
    "    for case_idx in tqdm(range(n_cases), desc=\"Processing cases\"):\n",
    "        case_dir = output_dir / f\"case_{case_idx+1}_magnitude_{magnitudes[case_idx]}\" / subfolder_name\n",
    "        case_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        structural_components = {\n",
    "            'M_constrained': M,\n",
    "            'K_constrained': K,\n",
    "            'f_constrained': f[:, case_idx]\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nSolving case {case_idx+1}/{n_cases}\")\n",
    "        print(f\"Magnitude: {magnitudes[case_idx]}\")\n",
    "        \n",
    "        try:\n",
    "            # Time the solution\n",
    "            start_time = time.time()\n",
    "            results = solve_newmark_dynamic_single_case(\n",
    "                structural_components,\n",
    "                initial_displacement=x[:, case_idx],  # Pass initial displacement for this case\n",
    "                total_time=total_time,\n",
    "                dt=dt,\n",
    "                beta=beta,\n",
    "                gamma=gamma,\n",
    "                tol=tol,\n",
    "                max_iter=max_iter\n",
    "            )\n",
    "            solve_time = time.time() - start_time\n",
    "            \n",
    "            # Store results and timing\n",
    "            case_results.append(results)\n",
    "            case_times.append(solve_time)\n",
    "            \n",
    "            # Save results\n",
    "            save_case_results(results, case_dir)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in case {case_idx+1}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Analyze and print detailed results\n",
    "    analyze_and_print_results(case_results, case_times, magnitudes)\n",
    "    \n",
    "    return output_dir, case_results, case_times\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"Starting multi-case dynamic analysis...\")\n",
    "        \n",
    "        output_dir, case_results, case_times = solve_newmark_dynamic_multi_case(\n",
    "            M=M_constrained,\n",
    "            K=K_constrained,\n",
    "            f=f_constrained,\n",
    "            magnitudes=magnitudes,\n",
    "            x=x,  \n",
    "            total_time=1.0,\n",
    "            dt=1e-3,\n",
    "            beta=0.25,\n",
    "            gamma=0.5,\n",
    "            tol=1e-8,\n",
    "            max_iter=50,\n",
    "            subfolder_name=\"FOM_Solution\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nAnalysis complete. Results saved in: {output_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in dynamic analysis: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.tri as tri\n",
    "\n",
    "# def read_mdpa_and_select_boundary_nodes(mdpa_file):\n",
    "#     \"\"\"\n",
    "#     Reads the mdpa file and identifies boundary nodes.\n",
    "#     Returns the node coordinates and boundary nodes.\n",
    "#     \"\"\"\n",
    "#     node_coords = []\n",
    "#     elements = []\n",
    "#     boundary_nodes = set()\n",
    "#     reading_nodes = False\n",
    "#     reading_elements = False\n",
    "\n",
    "#     with open(mdpa_file, 'r') as file:\n",
    "#         for line in file:\n",
    "#             line = line.strip()\n",
    "\n",
    "#             if \"Begin Nodes\" in line:\n",
    "#                 reading_nodes = True\n",
    "#                 continue\n",
    "#             elif \"End Nodes\" in line:\n",
    "#                 reading_nodes = False\n",
    "#                 continue\n",
    "#             elif reading_nodes and line:\n",
    "#                 parts = line.split()\n",
    "#                 if len(parts) >= 4:\n",
    "#                     node_coords.append([int(parts[0]), float(parts[1]), float(parts[2])])\n",
    "\n",
    "#             if \"Begin Elements\" in line:\n",
    "#                 reading_elements = True\n",
    "#                 continue\n",
    "#             elif \"End Elements\" in line:\n",
    "#                 reading_elements = False\n",
    "#                 continue\n",
    "#             elif reading_elements and line:\n",
    "#                 parts = line.split()\n",
    "#                 if len(parts) >= 5:\n",
    "#                     n1, n2, n3 = int(parts[2]), int(parts[3]), int(parts[4])\n",
    "#                     elements.append([n1, n2, n3])\n",
    "#                     boundary_nodes.update([n1, n2, n3])\n",
    "\n",
    "#     node_coords = np.array(node_coords)\n",
    "#     elements = np.array(elements)\n",
    "#     return node_coords, elements, boundary_nodes\n",
    "\n",
    "# def select_boundary_points(node_coords, boundary_nodes):\n",
    "#     \"\"\"\n",
    "#     Selects 3 boundary points: one at the bottom, one in the middle, and one at the top.\n",
    "#     \"\"\"\n",
    "#     boundary_coords = node_coords[np.isin(node_coords[:, 0], list(boundary_nodes))]\n",
    "#     sorted_coords = boundary_coords[np.argsort(boundary_coords[:, 2])]  # Sort by Y-coordinate\n",
    "\n",
    "#     bottom_node = sorted_coords[0]\n",
    "#     top_node = sorted_coords[-1]\n",
    "#     middle_node = sorted_coords[len(sorted_coords) // 2]\n",
    "\n",
    "#     return bottom_node, middle_node, top_node\n",
    "\n",
    "# def plot_node_representation(mdpa_file, node_id):\n",
    "#     \"\"\"\n",
    "#     Highlights the selected node on the mesh by drawing a circle around it.\n",
    "#     \"\"\"\n",
    "#     node_coords, elements, _ = read_mdpa_and_select_boundary_nodes(mdpa_file)\n",
    "#     x = node_coords[:, 1]\n",
    "#     y = node_coords[:, 2]\n",
    "\n",
    "#     triangulation = tri.Triangulation(x, y, elements - 1)\n",
    "\n",
    "#     selected_node = node_coords[node_coords[:, 0] == node_id][0]\n",
    "\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.triplot(triangulation, 'k-', lw=0.5, alpha=0.5)\n",
    "#     plt.scatter(selected_node[1], selected_node[2], color='red', label=f'Selected Node {node_id}')\n",
    "#     plt.gca().add_artist(plt.Circle((selected_node[1], selected_node[2]), radius=0.1, color='red', fill=False))\n",
    "#     plt.xlabel('X')\n",
    "#     plt.ylabel('Y')\n",
    "#     plt.title(f'Mesh with Highlighted Node {node_id}')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.axis('equal')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# def plot_displacement(time_newmark, displacement_newmark, time_ivp, displacement_ivp, node_id, node_x, node_y):\n",
    "#     \"\"\"\n",
    "#     Plots displacement vs time for the selected node.\n",
    "#     \"\"\"\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(time_newmark, displacement_newmark, label='Newmark Method', color='blue')\n",
    "#     # plt.plot(time_ivp, displacement_ivp, label='Solve IVP Method', color='red', linestyle='--')\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Displacement (m)')\n",
    "#     plt.title(f'Displacement vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# def plot_velocity(time_newmark, velocity_newmark, time_ivp, velocity_ivp, node_id, node_x, node_y):\n",
    "#     \"\"\"\n",
    "#     Plots velocity vs time for the selected node.\n",
    "#     \"\"\"\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(time_newmark, velocity_newmark, label='Newmark Method', color='blue')\n",
    "#     # plt.plot(time_ivp, velocity_ivp, label='Solve IVP Method', color='red', linestyle='--')\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Velocity (m/s)')\n",
    "#     plt.title(f'Velocity vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# def plot_acceleration(time_newmark, acceleration_newmark, time_ivp, acceleration_ivp, node_id, node_x, node_y):\n",
    "#     \"\"\"\n",
    "#     Plots acceleration vs time for the selected node.\n",
    "#     \"\"\"\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(time_newmark, acceleration_newmark, label='Newmark Method', color='blue')\n",
    "#     # plt.plot(time_ivp, acceleration_ivp, label='Solve IVP Method', color='red', linestyle='--')\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Acceleration (m/s²)')\n",
    "#     plt.title(f'Acceleration vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Main execution\n",
    "# node_coords, elements, boundary_nodes = read_mdpa_and_select_boundary_nodes(mdpa_file)\n",
    "# bottom_node, middle_node, top_node = select_boundary_points(node_coords, boundary_nodes)\n",
    "\n",
    "# selected_nodes = [bottom_node, middle_node, top_node]\n",
    "\n",
    "\n",
    "\n",
    "# # Plot displacement, velocity, and acceleration for each selected node\n",
    "# for node in selected_nodes:\n",
    "#     node_id = int(node[0])\n",
    "#     node_x, node_y = node[1], node[2]\n",
    "\n",
    "#     # Plot node representation\n",
    "#     plot_node_representation(mdpa_file, node_id)\n",
    "\n",
    "#     idx = np.where(node_coords[:, 0] == node_id)[0][0]\n",
    "#     displacement_newmark = case_results[0]['displacement'][:, idx]\n",
    "#     # displacement_ivp = u[:, idx]  \n",
    "#     velocity_newmark = case_results[0]['velocity'][:, idx]\n",
    "#     # velocity_ivp = v[:, idx]\n",
    "#     acceleration_newmark = case_results[0]['acceleration'][:, idx]\n",
    "#     # acceleration_ivp = a[:, idx]\n",
    "\n",
    "#     plot_displacement(case_results[0]['time'], displacement_newmark, case_results[0]['time'], displacement_newmark, node_id, node_x, node_y)\n",
    "#     plot_velocity(case_results[0]['time'], velocity_newmark, case_results[0]['time'], velocity_newmark, node_id, node_x, node_y)\n",
    "#     plot_acceleration(case_results[0]['time'], acceleration_newmark, case_results[0]['time'], acceleration_newmark, node_id, node_x, node_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot convergence for each case\n",
    "plt.figure(figsize=(10, 6))\n",
    "for idx, case in enumerate(case_results):\n",
    "    iterations = case['iterations_per_step']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(len(iterations)), iterations, label=f'Case {idx + 1} (Magnitude: {magnitudes[idx]})')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Number of Iterations')\n",
    "    plt.title(f'Convergence Plot for Case {idx + 1}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def plot_displacement_timestep(x_data, time_step, mdpa_file, scale_factor=1e7):\n",
    "    \"\"\"\n",
    "    Plot displacement field for a single time step.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x_data: ndarray of shape (612, 5), displacement data\n",
    "    time_step: int, which time step to plot\n",
    "    mdpa_file: str, path to mdpa file\n",
    "    scale_factor: float, scaling factor for displacements\n",
    "    \"\"\"\n",
    "    # Read node coordinates and elements\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "    \n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    x, y = float(parts[1]), float(parts[2])\n",
    "                    node_coords.append([x, y])\n",
    "                    \n",
    "            if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif reading_elements and \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "                    elements.append([n1, n2, n3])\n",
    "    \n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "    \n",
    "    # Get displacements for the specified time step\n",
    "    displacements = x_data[:, time_step].reshape(-1, 2) * scale_factor\n",
    "    disp_mag = np.sqrt(displacements[:, 0]**2 + displacements[:, 1]**2)\n",
    "    \n",
    "    # Calculate deformed coordinates\n",
    "    deformed_coords = node_coords + displacements\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 15))\n",
    "    \n",
    "    # Create triangulations\n",
    "    triangulation_orig = tri.Triangulation(node_coords[:, 0], node_coords[:, 1], elements)\n",
    "    triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "    \n",
    "    # Plot undeformed mesh\n",
    "    ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "    \n",
    "    # Plot deformed mesh with displacement magnitude coloring\n",
    "    tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm')\n",
    "    ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(f'Displacement Field at Time Step {time_step}')\n",
    "    ax.grid(True)\n",
    "    ax.axis('equal')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print displacement statistics\n",
    "    print(\"\\nDisplacement Statistics:\")\n",
    "    print(f\"Maximum displacement magnitude: {np.max(disp_mag):.2e}\")\n",
    "    print(f\"Minimum displacement magnitude: {np.min(disp_mag):.2e}\")\n",
    "    print(f\"Mean displacement magnitude: {np.mean(disp_mag):.2e}\")\n",
    "\n",
    "try:\n",
    "    # Plot displacement for time step 0 (or change to any desired time step)\n",
    "    plot_displacement_timestep(\n",
    "        x_data=x,  # Your displacement data\n",
    "        time_step=0,  # Change this to see different time steps\n",
    "        mdpa_file=[file for file in os.listdir() if file.endswith('.mdpa')][0],\n",
    "        scale_factor=1e6  # Adjust this to make displacements more visible\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error plotting displacement: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.tri as tri\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "\n",
    "# def plot_displacement_at_timesteps(case_folder, mdpa_file, output_folder_name=\"displacement_plots\", scale_factor=1e7):\n",
    "#     \"\"\"Plot displacement at each timestep and save plots as images in a new folder.\"\"\"\n",
    "#     try:\n",
    "#         # Construct path for the new folder\n",
    "#         output_folder = case_folder / output_folder_name\n",
    "\n",
    "#         # Create the output folder if it doesn't exist\n",
    "#         output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         print(f\"\\nProcessing: {case_folder.name}\")\n",
    "\n",
    "#         # Load solution data\n",
    "#         time = np.load(case_folder / \"FOM_Solution\" / \"solution\" / \"time.npy\")\n",
    "#         displacement = np.load(case_folder / \"FOM_Solution\" / \"solution\" / \"displacement.npy\")\n",
    "\n",
    "#         print(f\"Loaded displacement data shape: {displacement.shape}\")\n",
    "#         print(f\"Time steps available: {len(time)}\")\n",
    "\n",
    "#         # Read node coordinates and elements\n",
    "#         node_coords = []\n",
    "#         elements = []\n",
    "#         reading_nodes = False\n",
    "#         reading_elements = False\n",
    "\n",
    "#         with open(mdpa_file, 'r') as file:\n",
    "#             for line in file:\n",
    "#                 line = line.strip()\n",
    "\n",
    "#                 if \"Begin Nodes\" in line:\n",
    "#                     reading_nodes = True\n",
    "#                     continue\n",
    "#                 elif \"End Nodes\" in line:\n",
    "#                     reading_nodes = False\n",
    "#                     continue\n",
    "#                 elif reading_nodes and line:\n",
    "#                     parts = line.split()\n",
    "#                     if len(parts) >= 4:\n",
    "#                         x, y = float(parts[1]), float(parts[2])\n",
    "#                         node_coords.append([x, y])\n",
    "\n",
    "#                 if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "#                     reading_elements = True\n",
    "#                     continue\n",
    "#                 elif reading_elements and \"End Elements\" in line:\n",
    "#                     reading_elements = False\n",
    "#                     continue\n",
    "#                 elif reading_elements and line:\n",
    "#                     parts = line.split()\n",
    "#                     if len(parts) >= 5:\n",
    "#                         n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "#                         elements.append([n1, n2, n3])\n",
    "\n",
    "#         node_coords = np.array(node_coords)\n",
    "#         elements = np.array(elements)\n",
    "\n",
    "#         # Create triangulation for undeformed mesh\n",
    "#         x = node_coords[:, 0]\n",
    "#         y = node_coords[:, 1]\n",
    "#         triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "\n",
    "#         # Find global displacement limits for consistent colorbar\n",
    "#         disp_magnitudes = []\n",
    "#         for step in range(len(time)):\n",
    "#             disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "#             disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "#             disp_magnitudes.append(disp_mag)\n",
    "\n",
    "#         global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "#         global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "\n",
    "#         print(f\"Plotting Information:\")\n",
    "#         print(f\"Total plots: {len(time)}\")\n",
    "#         print(f\"Time range: [{time[0]:.3f}, {time[-1]:.3f}] seconds\")\n",
    "#         print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "#         # Loop through timesteps and plot\n",
    "#         for frame in range(len(time)):\n",
    "#             # Get displacements for current frame\n",
    "#             disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "#             disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "\n",
    "#             # Calculate deformed coordinates\n",
    "#             deformed_coords = node_coords + disp\n",
    "\n",
    "#             # Create figure and axis for each plot\n",
    "#             fig, ax = plt.subplots(figsize=(10, 15))\n",
    "\n",
    "#             # Plot undeformed mesh\n",
    "#             ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "\n",
    "#             # Plot deformed mesh with displacement magnitude coloring\n",
    "#             triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "#             tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "#                                vmin=global_min, vmax=global_max)\n",
    "#             ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "#             # Set labels and title\n",
    "#             ax.set_xlabel('X')\n",
    "#             ax.set_ylabel('Y')\n",
    "#             ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time) - 1})')\n",
    "\n",
    "#             ax.grid(True)\n",
    "#             ax.axis('equal')\n",
    "#             ax.legend()\n",
    "\n",
    "#             # Add colorbar only once\n",
    "#             if frame == 0:\n",
    "#                 plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "\n",
    "#             plt.tight_layout()\n",
    "\n",
    "#             # Save plot as image\n",
    "#             output_file = output_folder / f\"displacement_frame_{frame:04d}.png\"\n",
    "#             plt.savefig(output_file)\n",
    "#             plt.close(fig)\n",
    "\n",
    "#             # Print progress\n",
    "#             if frame % 10 == 0:\n",
    "#                 print(f\"Processed and saved plot for frame {frame}/{len(time) - 1}\")\n",
    "\n",
    "#         print(\"All plots completed and saved!\")\n",
    "#         return True\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {case_folder.name}: {str(e)}\")\n",
    "#         return False\n",
    "\n",
    "# def process_all_cases(base_dir=\"Dynamic_solution\", mdpa_file=\"2D_beam_udl_loading.mdpa\", scale_factor=1e7):\n",
    "#     \"\"\"Process all cases in the Dynamic_solution directory.\"\"\"\n",
    "#     base_path = Path(base_dir)\n",
    "\n",
    "#     # Find all case folders dynamically\n",
    "#     case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "\n",
    "#     # Sort case folders by case number\n",
    "#     def extract_case_number(folder_name):\n",
    "#         # Extract the case number from the folder name (e.g., \"case_1_magnitude_0.1\" -> 1)\n",
    "#         return int(folder_name.name.split(\"_\")[1])\n",
    "\n",
    "#     case_folders.sort(key=extract_case_number)\n",
    "\n",
    "#     print(f\"Found {len(case_folders)} cases to process\")\n",
    "#     print(\"\\nProcessing order:\")\n",
    "#     for folder in case_folders:\n",
    "#         print(f\"  {folder.name}\")\n",
    "\n",
    "#     # Process each case\n",
    "#     successful = 0\n",
    "#     failed = 0\n",
    "\n",
    "#     for folder in case_folders:\n",
    "#         print(\"\\n\" + \"=\" * 50)\n",
    "#         print(f\"Processing {folder.name}\")\n",
    "#         print(\"=\" * 50)\n",
    "\n",
    "#         if plot_displacement_at_timesteps(folder, mdpa_file, scale_factor=scale_factor):\n",
    "#             successful += 1\n",
    "#         else:\n",
    "#             failed += 1\n",
    "\n",
    "#     print(\"\\n\" + \"=\" * 50)\n",
    "#     print(\"Processing Complete!\")\n",
    "#     print(f\"Successfully processed: {successful} cases\")\n",
    "#     print(f\"Failed to process: {failed} cases\")\n",
    "#     print(\"=\" * 50)\n",
    "\n",
    "# # Run the processing\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         process_all_cases(\n",
    "#             base_dir=\"Dynamic_solution\",\n",
    "#             mdpa_file=\"2D_beam_udl_loading.mdpa\",\n",
    "#             scale_factor=1e6  # Adjust this if needed\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in main execution: {str(e)}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def plot_displacement_at_timesteps(case_folder, mdpa_file, output_folder_name=\"displacement_plots\", scale_factor=1e7):\n",
    "    \"\"\"Plot displacement at each timestep and save plots as images in a new folder.\"\"\"\n",
    "    try:\n",
    "        # Construct path for the new folder\n",
    "        output_folder = case_folder / output_folder_name\n",
    "\n",
    "        # Create the output folder if it doesn't exist\n",
    "        output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(f\"\\nProcessing: {case_folder.name}\")\n",
    "\n",
    "        # Load solution data\n",
    "        time = np.load(case_folder / \"FOM_Solution\" / \"solution\" / \"time.npy\")\n",
    "        displacement = np.load(case_folder / \"FOM_Solution\" / \"solution\" / \"displacement.npy\")\n",
    "\n",
    "        print(f\"Loaded displacement data shape: {displacement.shape}\")\n",
    "        print(f\"Time steps available: {len(time)}\")\n",
    "\n",
    "        # Read node coordinates and elements\n",
    "        node_coords = []\n",
    "        elements = []\n",
    "        reading_nodes = False\n",
    "        reading_elements = False\n",
    "\n",
    "        with open(mdpa_file, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "\n",
    "                if \"Begin Nodes\" in line:\n",
    "                    reading_nodes = True\n",
    "                    continue\n",
    "                elif \"End Nodes\" in line:\n",
    "                    reading_nodes = False\n",
    "                    continue\n",
    "                elif reading_nodes and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4:\n",
    "                        x, y = float(parts[1]), float(parts[2])\n",
    "                        node_coords.append([x, y])\n",
    "\n",
    "                if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                    reading_elements = True\n",
    "                    continue\n",
    "                elif reading_elements and \"End Elements\" in line:\n",
    "                    reading_elements = False\n",
    "                    continue\n",
    "                elif reading_elements and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 5:\n",
    "                        n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "                        elements.append([n1, n2, n3])\n",
    "\n",
    "        node_coords = np.array(node_coords)\n",
    "        elements = np.array(elements)\n",
    "\n",
    "        # Create triangulation for undeformed mesh\n",
    "        x = node_coords[:, 0]\n",
    "        y = node_coords[:, 1]\n",
    "        triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "\n",
    "        # Find global displacement limits for consistent colorbar\n",
    "        disp_magnitudes = []\n",
    "        for step in range(len(time)):\n",
    "            disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            disp_magnitudes.append(disp_mag)\n",
    "\n",
    "        global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "        global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "\n",
    "        print(f\"Plotting Information:\")\n",
    "        print(f\"Total plots: {len(time)}\")\n",
    "        print(f\"Time range: [{time[0]:.3f}, {time[-1]:.3f}] seconds\")\n",
    "        print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "        # Loop through timesteps and plot\n",
    "        for frame in range(len(time)):\n",
    "            # Get displacements for current frame\n",
    "            disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "\n",
    "            # Calculate deformed coordinates\n",
    "            deformed_coords = node_coords + disp\n",
    "\n",
    "            # Create figure and axis for each plot\n",
    "            fig, ax = plt.subplots(figsize=(10, 15))\n",
    "\n",
    "            # Plot undeformed mesh\n",
    "            ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "\n",
    "            # Plot deformed mesh with displacement magnitude coloring\n",
    "            triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "            tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                               vmin=global_min, vmax=global_max)\n",
    "            ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "            # Set labels and title\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time) - 1})')\n",
    "\n",
    "            ax.grid(True)\n",
    "            ax.axis('equal')\n",
    "            ax.legend()\n",
    "\n",
    "            # Add colorbar only once\n",
    "            if frame == 0:\n",
    "                plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save plot as image\n",
    "            output_file = output_folder / f\"displacement_frame_{frame:04d}.png\"\n",
    "            plt.savefig(output_file)\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Print progress\n",
    "            if frame % 10 == 0:\n",
    "                print(f\"Processed and saved plot for frame {frame}/{len(time) - 1}\")\n",
    "\n",
    "        print(\"All plots completed and saved!\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {case_folder.name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def process_all_cases(base_dir=\"Dynamic_solution\", mdpa_file=\"2D_beam_udl_loading.mdpa\", scale_factor=1e7, num_files=None):\n",
    "    \"\"\"\n",
    "    Process cases in the Dynamic_solution directory.\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory containing case folders\n",
    "        mdpa_file: Name of the mdpa file\n",
    "        scale_factor: Scale factor for displacement visualization\n",
    "        num_files: Number of files to process (None for all files)\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "\n",
    "    # Find all case folders dynamically\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "\n",
    "    # Sort case folders by case number\n",
    "    def extract_case_number(folder_name):\n",
    "        # Extract the case number from the folder name (e.g., \"case_1_magnitude_0.1\" -> 1)\n",
    "        return int(folder_name.name.split(\"_\")[1])\n",
    "\n",
    "    case_folders.sort(key=extract_case_number)\n",
    "    \n",
    "    total_cases = len(case_folders)\n",
    "    \n",
    "    if num_files is None:\n",
    "        # If num_files is not provided, ask the user\n",
    "        try:\n",
    "            user_input = input(f\"Found {total_cases} case folders. How many would you like to process? (Enter 'all' for all folders): \")\n",
    "            if user_input.lower() == 'all':\n",
    "                num_files = total_cases\n",
    "            else:\n",
    "                num_files = int(user_input)\n",
    "                if num_files <= 0 or num_files > total_cases:\n",
    "                    print(f\"Invalid number. Using all {total_cases} files.\")\n",
    "                    num_files = total_cases\n",
    "        except ValueError:\n",
    "            print(f\"Invalid input. Processing all {total_cases} files.\")\n",
    "            num_files = total_cases\n",
    "    else:\n",
    "        # Ensure num_files is valid\n",
    "        num_files = min(max(1, num_files), total_cases)\n",
    "    \n",
    "    # Limit to the specified number of files\n",
    "    case_folders = case_folders[:num_files]\n",
    "    \n",
    "    print(f\"\\nWill process {len(case_folders)} of {total_cases} cases\")\n",
    "    print(\"\\nProcessing order:\")\n",
    "    for folder in case_folders:\n",
    "        print(f\"  {folder.name}\")\n",
    "\n",
    "    # Process each case\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "\n",
    "    for folder in case_folders:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"Processing {folder.name}\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        if plot_displacement_at_timesteps(folder, mdpa_file, scale_factor=scale_factor):\n",
    "            successful += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Processing Complete!\")\n",
    "    print(f\"Successfully processed: {successful} cases\")\n",
    "    print(f\"Failed to process: {failed} cases\")\n",
    "    print(f\"Skipped: {total_cases - num_files} cases\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# For Jupyter notebooks - run this directly\n",
    "def run_processing(base_dir=\"Dynamic_solution\", mdpa_file=\"2D_beam_udl_loading.mdpa\", scale_factor=1e6, num_files=None):\n",
    "    \"\"\"Function to call from Jupyter notebook cells\"\"\"\n",
    "    try:\n",
    "        process_all_cases(\n",
    "            base_dir=base_dir,\n",
    "            mdpa_file=mdpa_file,\n",
    "            scale_factor=scale_factor,\n",
    "            num_files=num_files\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error in execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Detect if we're in Jupyter and run accordingly\n",
    "if __name__ == \"__main__\":\n",
    "    # Directly run the function without argparse for Jupyter\n",
    "    run_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.tri as tri\n",
    "# from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "\n",
    "# def create_displacement_animation(case_folder, mdpa_file, scale_factor=1e7, step_interval=100):\n",
    "#     \"\"\"\n",
    "#     Create an animated GIF of displacement field for a specific case.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     case_folder: Path object, full path to case folder\n",
    "#     mdpa_file: str, path to mdpa file\n",
    "#     scale_factor: float, scaling factor for displacements\n",
    "#     step_interval: int, time in milliseconds between frames\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Create output filename from case folder name\n",
    "#         output_file = case_folder / 'displacement_animation_scaled.gif'\n",
    "        \n",
    "#         print(f\"\\nProcessing: {case_folder.name}\")\n",
    "        \n",
    "#         # Load solution data\n",
    "#         time = np.load(case_folder / \"solution\" / \"time.npy\")\n",
    "#         displacement = np.load(case_folder / \"solution\" / \"displacement.npy\")\n",
    "        \n",
    "#         print(f\"Loaded displacement data shape: {displacement.shape}\")\n",
    "#         print(f\"Time steps available: {len(time)}\")\n",
    "        \n",
    "#         # Read node coordinates and elements\n",
    "#         node_coords = []\n",
    "#         elements = []\n",
    "#         reading_nodes = False\n",
    "#         reading_elements = False\n",
    "        \n",
    "#         with open(mdpa_file, 'r') as file:\n",
    "#             for line in file:\n",
    "#                 line = line.strip()\n",
    "                \n",
    "#                 if \"Begin Nodes\" in line:\n",
    "#                     reading_nodes = True\n",
    "#                     continue\n",
    "#                 elif \"End Nodes\" in line:\n",
    "#                     reading_nodes = False\n",
    "#                     continue\n",
    "#                 elif reading_nodes and line:\n",
    "#                     parts = line.split()\n",
    "#                     if len(parts) >= 4:\n",
    "#                         x, y = float(parts[1]), float(parts[2])\n",
    "#                         node_coords.append([x, y])\n",
    "                        \n",
    "#                 if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "#                     reading_elements = True\n",
    "#                     continue\n",
    "#                 elif reading_elements and \"End Elements\" in line:\n",
    "#                     reading_elements = False\n",
    "#                     continue\n",
    "#                 elif reading_elements and line:\n",
    "#                     parts = line.split()\n",
    "#                     if len(parts) >= 5:\n",
    "#                         n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "#                         elements.append([n1, n2, n3])\n",
    "        \n",
    "#         node_coords = np.array(node_coords)\n",
    "#         elements = np.array(elements)\n",
    "        \n",
    "#         # Create figure\n",
    "#         fig, ax = plt.subplots(figsize=(10, 15))\n",
    "        \n",
    "#         # Create base triangulation for undeformed mesh\n",
    "#         x = node_coords[:, 0]\n",
    "#         y = node_coords[:, 1]\n",
    "#         triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "        \n",
    "#         # Find global displacement limits for consistent colorbar\n",
    "#         disp_magnitudes = []\n",
    "#         for step in range(len(time)):\n",
    "#             disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "#             disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "#             disp_magnitudes.append(disp_mag)\n",
    "        \n",
    "#         global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "#         global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "        \n",
    "#         print(f\"Animation Information:\")\n",
    "#         print(f\"Total frames: {len(time)}\")\n",
    "#         print(f\"Time range: [{time[0]:.3f}, {time[-1]:.3f}] seconds\")\n",
    "#         print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "        \n",
    "#         def update(frame):\n",
    "#             ax.clear()\n",
    "            \n",
    "#             # Get displacements for current frame\n",
    "#             disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "#             disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            \n",
    "#             # Calculate deformed coordinates\n",
    "#             deformed_coords = node_coords + disp\n",
    "            \n",
    "#             # Plot undeformed mesh\n",
    "#             ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "            \n",
    "#             # Plot deformed mesh with displacement magnitude coloring\n",
    "#             triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "#             tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "#                              vmin=global_min, vmax=global_max)\n",
    "#             ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "            \n",
    "#             # Set labels and title\n",
    "#             ax.set_xlabel('X')\n",
    "#             ax.set_ylabel('Y')\n",
    "#             ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "            \n",
    "#             ax.grid(True)\n",
    "#             ax.axis('equal')\n",
    "#             ax.legend()\n",
    "            \n",
    "#             # Add colorbar only once\n",
    "#             if frame == 0:\n",
    "#                 plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "            \n",
    "#             plt.tight_layout()\n",
    "            \n",
    "#             # Print progress\n",
    "#             if frame % 10 == 0:\n",
    "#                 print(f\"Processing frame {frame}/{len(time)-1}\")\n",
    "        \n",
    "#         # Create animation\n",
    "#         print(\"Creating animation...\")\n",
    "#         anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "        \n",
    "#         # Save animation\n",
    "#         print(f\"Saving animation to {output_file}\")\n",
    "#         writer = PillowWriter(fps=1000/step_interval)\n",
    "#         anim.save(output_file, writer=writer)\n",
    "        \n",
    "#         plt.close()\n",
    "#         print(\"Animation completed!\")\n",
    "        \n",
    "#         return True\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {case_folder.name}: {str(e)}\")\n",
    "#         return False\n",
    "    \n",
    "# def process_all_cases(base_dir=\"Dynamic_solution\", mdpa_file=\"2D_beam_udl_loading.mdpa\", scale_factor=1e7):\n",
    "#     \"\"\"Process all cases in the Dynamic_solution directory.\"\"\"\n",
    "#     base_path = Path(base_dir)\n",
    "    \n",
    "#     # Find all case folders dynamically\n",
    "#     case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "    \n",
    "#     # Sort case folders by case number\n",
    "#     def extract_case_number(folder_name):\n",
    "#         # Extract the case number from the folder name (e.g., \"case_1_magnitude_0.1\" -> 1)\n",
    "#         return int(folder_name.name.split(\"_\")[1])\n",
    "    \n",
    "#     case_folders.sort(key=extract_case_number)\n",
    "    \n",
    "#     print(f\"Found {len(case_folders)} cases to process\")\n",
    "#     print(\"\\nProcessing order:\")\n",
    "#     for folder in case_folders:\n",
    "#         print(f\"  {folder.name}\")\n",
    "    \n",
    "#     # Process each case\n",
    "#     successful = 0\n",
    "#     failed = 0\n",
    "    \n",
    "#     for folder in case_folders:\n",
    "#         print(\"\\n\" + \"=\"*50)\n",
    "#         print(f\"Processing {folder.name}\")\n",
    "#         print(\"=\"*50)\n",
    "        \n",
    "#         # Adjust path to include Numerical_Solution subfolder\n",
    "#         solution_folder = folder / \"FOM_Solution\"\n",
    "        \n",
    "#         if solution_folder.exists():\n",
    "#             if create_displacement_animation(solution_folder, mdpa_file, scale_factor):\n",
    "#                 successful += 1\n",
    "#             else:\n",
    "#                 failed += 1\n",
    "#         else:\n",
    "#             print(f\"Error: Numerical_Solution folder not found in {folder.name}\")\n",
    "#             failed += 1\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*50)\n",
    "#     print(\"Processing Complete!\")\n",
    "#     print(f\"Successfully processed: {successful} cases\")\n",
    "#     print(f\"Failed to process: {failed} cases\")\n",
    "#     print(\"=\"*50)\n",
    "\n",
    "# # Run the processing\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         process_all_cases(\n",
    "#             base_dir=\"Dynamic_solution\",\n",
    "#             mdpa_file=[file for file in os.listdir() if file.endswith('.mdpa')][0],\n",
    "#             scale_factor=1e6  # Adjust this if needed\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in main execution: {str(e)}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_displacement_animation(case_folder, mdpa_file, scale_factor=1e7, step_interval=100):\n",
    "    \"\"\"\n",
    "    Create an animated GIF of displacement field for a specific case.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    case_folder: Path object, full path to case folder\n",
    "    mdpa_file: str, path to mdpa file\n",
    "    scale_factor: float, scaling factor for displacements\n",
    "    step_interval: int, time in milliseconds between frames\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output filename from case folder name\n",
    "        output_file = case_folder / 'displacement_animation_scaled.gif'\n",
    "        \n",
    "        print(f\"\\nProcessing: {case_folder.name}\")\n",
    "        \n",
    "        # Load solution data\n",
    "        time = np.load(case_folder / \"solution\" / \"time.npy\")\n",
    "        displacement = np.load(case_folder / \"solution\" / \"displacement.npy\")\n",
    "        \n",
    "        print(f\"Loaded displacement data shape: {displacement.shape}\")\n",
    "        print(f\"Time steps available: {len(time)}\")\n",
    "        \n",
    "        # Read node coordinates and elements\n",
    "        node_coords = []\n",
    "        elements = []\n",
    "        reading_nodes = False\n",
    "        reading_elements = False\n",
    "        \n",
    "        with open(mdpa_file, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                \n",
    "                if \"Begin Nodes\" in line:\n",
    "                    reading_nodes = True\n",
    "                    continue\n",
    "                elif \"End Nodes\" in line:\n",
    "                    reading_nodes = False\n",
    "                    continue\n",
    "                elif reading_nodes and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4:\n",
    "                        x, y = float(parts[1]), float(parts[2])\n",
    "                        node_coords.append([x, y])\n",
    "                        \n",
    "                if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                    reading_elements = True\n",
    "                    continue\n",
    "                elif reading_elements and \"End Elements\" in line:\n",
    "                    reading_elements = False\n",
    "                    continue\n",
    "                elif reading_elements and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 5:\n",
    "                        n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "                        elements.append([n1, n2, n3])\n",
    "        \n",
    "        node_coords = np.array(node_coords)\n",
    "        elements = np.array(elements)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=(10, 15))\n",
    "        \n",
    "        # Create base triangulation for undeformed mesh\n",
    "        x = node_coords[:, 0]\n",
    "        y = node_coords[:, 1]\n",
    "        triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "        \n",
    "        # Find global displacement limits for consistent colorbar\n",
    "        disp_magnitudes = []\n",
    "        for step in range(len(time)):\n",
    "            disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            disp_magnitudes.append(disp_mag)\n",
    "        \n",
    "        global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "        global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "        \n",
    "        print(f\"Animation Information:\")\n",
    "        print(f\"Total frames: {len(time)}\")\n",
    "        print(f\"Time range: [{time[0]:.3f}, {time[-1]:.3f}] seconds\")\n",
    "        print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "        \n",
    "        def update(frame):\n",
    "            ax.clear()\n",
    "            \n",
    "            # Get displacements for current frame\n",
    "            disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            \n",
    "            # Calculate deformed coordinates\n",
    "            deformed_coords = node_coords + disp\n",
    "            \n",
    "            # Plot undeformed mesh\n",
    "            ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "            \n",
    "            # Plot deformed mesh with displacement magnitude coloring\n",
    "            triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "            tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                             vmin=global_min, vmax=global_max)\n",
    "            ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "            \n",
    "            # Set labels and title\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "            \n",
    "            ax.grid(True)\n",
    "            ax.axis('equal')\n",
    "            ax.legend()\n",
    "            \n",
    "            # Add colorbar only once\n",
    "            if frame == 0:\n",
    "                plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Print progress\n",
    "            if frame % 10 == 0:\n",
    "                print(f\"Processing frame {frame}/{len(time)-1}\")\n",
    "        \n",
    "        # Create animation\n",
    "        print(\"Creating animation...\")\n",
    "        anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "        \n",
    "        # Save animation\n",
    "        print(f\"Saving animation to {output_file}\")\n",
    "        writer = PillowWriter(fps=1000/step_interval)\n",
    "        anim.save(output_file, writer=writer)\n",
    "        \n",
    "        plt.close()\n",
    "        print(\"Animation completed!\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {case_folder.name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def get_case_folders(base_dir=\"Dynamic_solution\"):\n",
    "    \"\"\"Get all available case folders and sort them by case number.\"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    \n",
    "    # Find all case folders dynamically\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "    \n",
    "    # Sort case folders by case number\n",
    "    def extract_case_number(folder_name):\n",
    "        # Extract the case number from the folder name (e.g., \"case_1_magnitude_0.1\" -> 1)\n",
    "        return int(folder_name.name.split(\"_\")[1])\n",
    "    \n",
    "    case_folders.sort(key=extract_case_number)\n",
    "    return case_folders\n",
    "\n",
    "def user_select_cases(case_folders):\n",
    "    \"\"\"Allow user to select which cases to process.\"\"\"\n",
    "    print(\"\\nAvailable case folders:\")\n",
    "    for i, folder in enumerate(case_folders, 1):\n",
    "        print(f\"{i}. {folder.name}\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\nEnter case numbers to process (comma-separated, e.g., '1,3,5' or 'all' for all cases): \")\n",
    "            \n",
    "            if user_input.lower() == 'all':\n",
    "                print(\"Processing all cases.\")\n",
    "                selected_folders = case_folders\n",
    "                break\n",
    "            \n",
    "            # Get user-selected case numbers\n",
    "            selected_indices = [int(x.strip()) for x in user_input.split(',')]\n",
    "            \n",
    "            # Validate indices\n",
    "            if any(idx < 1 or idx > len(case_folders) for idx in selected_indices):\n",
    "                print(f\"Error: Please enter valid case numbers between 1 and {len(case_folders)}\")\n",
    "                continue\n",
    "            \n",
    "            # Get the selected folders\n",
    "            selected_folders = [case_folders[idx-1] for idx in selected_indices]\n",
    "            \n",
    "            if not selected_folders:\n",
    "                print(\"No valid cases selected.\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\nSelected {len(selected_folders)} cases to process:\")\n",
    "            for folder in selected_folders:\n",
    "                print(f\"  {folder.name}\")\n",
    "            \n",
    "            break\n",
    "            \n",
    "        except ValueError:\n",
    "            print(\"Error: Please enter valid numbers separated by commas.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "    \n",
    "    return selected_folders\n",
    "\n",
    "def process_selected_cases(selected_folders, mdpa_file, scale_factor=1e6):\n",
    "    \"\"\"Process only the selected case folders.\"\"\"\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for folder in selected_folders:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {folder.name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Adjust path to include FOM_Solution subfolder\n",
    "        solution_folder = folder / \"FOM_Solution\"\n",
    "        \n",
    "        if solution_folder.exists():\n",
    "            if create_displacement_animation(solution_folder, mdpa_file, scale_factor):\n",
    "                successful += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "        else:\n",
    "            print(f\"Error: FOM_Solution folder not found in {folder.name}\")\n",
    "            failed += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Processing Complete!\")\n",
    "    print(f\"Successfully processed: {successful} cases\")\n",
    "    print(f\"Failed to process: {failed} cases\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Run the processing\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        base_dir = \"Dynamic_solution\"\n",
    "        \n",
    "        # Find MDPA file\n",
    "        mdpa_files = [file for file in os.listdir() if file.endswith('.mdpa')]\n",
    "        if not mdpa_files:\n",
    "            print(\"Error: No .mdpa files found in the current directory.\")\n",
    "            exit(1)\n",
    "        mdpa_file = mdpa_files[0]\n",
    "        \n",
    "        # Get available case folders\n",
    "        case_folders = get_case_folders(base_dir)\n",
    "        \n",
    "        if not case_folders:\n",
    "            print(f\"Error: No case folders found in {base_dir}.\")\n",
    "            exit(1)\n",
    "        \n",
    "        print(f\"Found {len(case_folders)} total cases\")\n",
    "        \n",
    "        # Let user select cases\n",
    "        selected_folders = user_select_cases(case_folders)\n",
    "        \n",
    "        # Use the same scale factor as in the original code\n",
    "        scale_factor = 1e6\n",
    "        \n",
    "        process_selected_cases(selected_folders, mdpa_file, scale_factor)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.tri as tri\n",
    "# from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "\n",
    "# def create_displacement_animation(case_folder, mdpa_file, scale_factor=1e7, step_interval=100):\n",
    "#     \"\"\"\n",
    "#     Create an animated GIF of displacement field for a specific case.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     case_folder: Path object, full path to case folder\n",
    "#     mdpa_file: str, path to mdpa file\n",
    "#     scale_factor: float, scaling factor for displacements\n",
    "#     step_interval: int, time in milliseconds between frames\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Create output filename from case folder name\n",
    "#         output_file = case_folder / 'displacement_animation.gif'\n",
    "        \n",
    "#         print(f\"\\nProcessing: {case_folder.name}\")\n",
    "        \n",
    "#         # Load solution data\n",
    "#         time = np.load(case_folder / \"solution\" / \"time.npy\")\n",
    "#         displacement = np.load(case_folder / \"solution\" / \"displacement.npy\")\n",
    "        \n",
    "#         print(f\"Loaded displacement data shape: {displacement.shape}\")\n",
    "#         print(f\"Time steps available: {len(time)}\")\n",
    "        \n",
    "#         # Read node coordinates and elements\n",
    "#         node_coords = []\n",
    "#         elements = []\n",
    "#         reading_nodes = False\n",
    "#         reading_elements = False\n",
    "        \n",
    "#         with open(mdpa_file, 'r') as file:\n",
    "#             for line in file:\n",
    "#                 line = line.strip()\n",
    "                \n",
    "#                 if \"Begin Nodes\" in line:\n",
    "#                     reading_nodes = True\n",
    "#                     continue\n",
    "#                 elif \"End Nodes\" in line:\n",
    "#                     reading_nodes = False\n",
    "#                     continue\n",
    "#                 elif reading_nodes and line:\n",
    "#                     parts = line.split()\n",
    "#                     if len(parts) >= 4:\n",
    "#                         x, y = float(parts[1]), float(parts[2])\n",
    "#                         node_coords.append([x, y])\n",
    "                        \n",
    "#                 if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "#                     reading_elements = True\n",
    "#                     continue\n",
    "#                 elif reading_elements and \"End Elements\" in line:\n",
    "#                     reading_elements = False\n",
    "#                     continue\n",
    "#                 elif reading_elements and line:\n",
    "#                     parts = line.split()\n",
    "#                     if len(parts) >= 5:\n",
    "#                         n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "#                         elements.append([n1, n2, n3])\n",
    "        \n",
    "#         node_coords = np.array(node_coords)\n",
    "#         elements = np.array(elements)\n",
    "        \n",
    "#         # Create figure\n",
    "#         fig, ax = plt.subplots(figsize=(10, 15))\n",
    "        \n",
    "#         # Create base triangulation for undeformed mesh\n",
    "#         x = node_coords[:, 0]\n",
    "#         y = node_coords[:, 1]\n",
    "#         triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "        \n",
    "#         # Find global displacement limits for consistent colorbar\n",
    "#         disp_magnitudes = []\n",
    "#         for step in range(len(time)):\n",
    "#             disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "#             disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "#             disp_magnitudes.append(disp_mag)\n",
    "        \n",
    "#         global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "#         global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "        \n",
    "#         print(f\"Animation Information:\")\n",
    "#         print(f\"Total frames: {len(time)}\")\n",
    "#         print(f\"Time range: [{time[0]:.3f}, {time[-1]:.3f}] seconds\")\n",
    "#         print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "        \n",
    "#         def update(frame):\n",
    "#             ax.clear()\n",
    "            \n",
    "#             # Get displacements for current frame\n",
    "#             disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "#             disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            \n",
    "#             # Calculate deformed coordinates\n",
    "#             deformed_coords = node_coords + disp\n",
    "            \n",
    "#             # Plot undeformed mesh\n",
    "#             ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "            \n",
    "#             # Plot deformed mesh with displacement magnitude coloring\n",
    "#             triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "#             tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "#                              vmin=global_min, vmax=global_max)\n",
    "#             ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "            \n",
    "#             # Set labels and title\n",
    "#             ax.set_xlabel('X')\n",
    "#             ax.set_ylabel('Y')\n",
    "#             ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "            \n",
    "#             ax.grid(True)\n",
    "#             ax.axis('equal')\n",
    "#             ax.legend()\n",
    "            \n",
    "#             # Add colorbar only once\n",
    "#             if frame == 0:\n",
    "#                 plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "            \n",
    "#             plt.tight_layout()\n",
    "            \n",
    "#             # Print progress\n",
    "#             if frame % 10 == 0:\n",
    "#                 print(f\"Processing frame {frame}/{len(time)-1}\")\n",
    "        \n",
    "#         # Create animation\n",
    "#         print(\"Creating animation...\")\n",
    "#         anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "        \n",
    "#         # Save animation\n",
    "#         print(f\"Saving animation to {output_file}\")\n",
    "#         writer = PillowWriter(fps=1000/step_interval)\n",
    "#         anim.save(output_file, writer=writer)\n",
    "        \n",
    "#         plt.close()\n",
    "#         print(\"Animation completed!\")\n",
    "        \n",
    "#         return True\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {case_folder.name}: {str(e)}\")\n",
    "#         return False\n",
    "    \n",
    "# def process_all_cases(base_dir=\"Dynamic_solution\", mdpa_file=\"2D_beam_udl_loading.mdpa\", scale_factor=1e7):\n",
    "#     \"\"\"Process all cases in the Dynamic_solution directory.\"\"\"\n",
    "#     base_path = Path(base_dir)\n",
    "    \n",
    "#     # Find all case folders dynamically\n",
    "#     case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "    \n",
    "#     # Sort case folders by case number\n",
    "#     def extract_case_number(folder_name):\n",
    "#         # Extract the case number from the folder name (e.g., \"case_1_magnitude_0.1\" -> 1)\n",
    "#         return int(folder_name.name.split(\"_\")[1])\n",
    "    \n",
    "#     case_folders.sort(key=extract_case_number)\n",
    "    \n",
    "#     print(f\"Found {len(case_folders)} cases to process\")\n",
    "#     print(\"\\nProcessing order:\")\n",
    "#     for folder in case_folders:\n",
    "#         print(f\"  {folder.name}\")\n",
    "    \n",
    "#     # Process each case\n",
    "#     successful = 0\n",
    "#     failed = 0\n",
    "    \n",
    "#     for folder in case_folders:\n",
    "#         print(\"\\n\" + \"=\"*50)\n",
    "#         print(f\"Processing {folder.name}\")\n",
    "#         print(\"=\"*50)\n",
    "        \n",
    "#         # Adjust path to include Numerical_Solution subfolder\n",
    "#         solution_folder = folder / \"Numerical_Solution\"\n",
    "        \n",
    "#         if solution_folder.exists():\n",
    "#             if create_displacement_animation(solution_folder, mdpa_file, scale_factor):\n",
    "#                 successful += 1\n",
    "#             else:\n",
    "#                 failed += 1\n",
    "#         else:\n",
    "#             print(f\"Error: Numerical_Solution folder not found in {folder.name}\")\n",
    "#             failed += 1\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*50)\n",
    "#     print(\"Processing Complete!\")\n",
    "#     print(f\"Successfully processed: {successful} cases\")\n",
    "#     print(f\"Failed to process: {failed} cases\")\n",
    "#     print(\"=\"*50)\n",
    "\n",
    "# # Run the processing\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         process_all_cases(\n",
    "#             base_dir=\"Dynamic_solution\",\n",
    "#             mdpa_file=[file for file in os.listdir() if file.endswith('.mdpa')][0],\n",
    "#             scale_factor=1  # Adjust this if needed\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in main execution: {str(e)}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def save_displacement_frames(case_folder, mdpa_file, scale_factor=1e7):\n",
    "    \"\"\"\n",
    "    Save displacement screenshots for each time step as .png images.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    case_folder: Path object, full path to case folder\n",
    "    mdpa_file: str, path to mdpa file\n",
    "    scale_factor: float, scaling factor for displacements\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\n📂 Processing: {case_folder.name}\")\n",
    "        \n",
    "        # Load solution data\n",
    "        time_file = case_folder / \"solution\" / \"time.npy\"\n",
    "        displacement_file = case_folder / \"solution\" / \"displacement.npy\"\n",
    "        time = np.load(time_file)\n",
    "        displacement = np.load(displacement_file)\n",
    "\n",
    "        print(f\"📥 Loaded:\")\n",
    "        print(f\"   Time file        : {time_file.resolve()}\")\n",
    "        print(f\"   Displacement file: {displacement_file.resolve()}\")\n",
    "        print(f\"   Shape of displacement data: {displacement.shape}\")\n",
    "        print(f\"   Number of time steps: {len(time)}\")\n",
    "        \n",
    "        # Read mesh\n",
    "        node_coords = []\n",
    "        elements = []\n",
    "        reading_nodes = False\n",
    "        reading_elements = False\n",
    "        \n",
    "        print(f\"📄 Reading mesh from: {Path(mdpa_file).resolve()}\")\n",
    "        with open(mdpa_file, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                \n",
    "                if \"Begin Nodes\" in line:\n",
    "                    reading_nodes = True\n",
    "                    continue\n",
    "                elif \"End Nodes\" in line:\n",
    "                    reading_nodes = False\n",
    "                    continue\n",
    "                elif reading_nodes and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4:\n",
    "                        x, y = float(parts[1]), float(parts[2])\n",
    "                        node_coords.append([x, y])\n",
    "                        \n",
    "                if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                    reading_elements = True\n",
    "                    continue\n",
    "                elif reading_elements and \"End Elements\" in line:\n",
    "                    reading_elements = False\n",
    "                    continue\n",
    "                elif reading_elements and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 5:\n",
    "                        n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "                        elements.append([n1, n2, n3])\n",
    "        \n",
    "        node_coords = np.array(node_coords)\n",
    "        elements = np.array(elements)\n",
    "        \n",
    "        # Create triangulation\n",
    "        triangulation_orig = tri.Triangulation(node_coords[:, 0], node_coords[:, 1], elements)\n",
    "\n",
    "        # Output folder for images\n",
    "        output_dir = case_folder / \"solution\" / \"displacement_frames\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        print(f\"🖼️  Saving displacement plots to: {output_dir.resolve()}\")\n",
    "        \n",
    "        # Global color scale\n",
    "        disp_magnitudes = []\n",
    "        for step in range(len(time)):\n",
    "            disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            disp_magnitudes.append(disp_mag)\n",
    "\n",
    "        global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "        global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "        print(f\"📊 Displacement magnitude range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "        # Plot and save each frame\n",
    "        for frame in range(len(time)):\n",
    "            fig, ax = plt.subplots(figsize=(10, 15))\n",
    "            disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            deformed_coords = node_coords + disp\n",
    "\n",
    "            triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "\n",
    "            ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "            tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                               vmin=global_min, vmax=global_max)\n",
    "            ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "            ax.grid(True)\n",
    "            ax.axis('equal')\n",
    "            ax.legend()\n",
    "            plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "            plt.tight_layout()\n",
    "\n",
    "            frame_path = output_dir / f\"frame_{frame:04d}.png\"\n",
    "            plt.savefig(frame_path)\n",
    "            plt.close()\n",
    "            print(f\"✅ Saved: {frame_path.name}\")\n",
    "\n",
    "        print(f\"🎉 All displacement frames saved for: {case_folder.name}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {case_folder.name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def process_all_cases(base_dir=\"Dynamic_solution\", mdpa_file=\"2D_beam_udl_loading.mdpa\", scale_factor=1e7):\n",
    "    \"\"\"Process all cases in the Dynamic_solution directory by saving PNG frames instead of GIFs.\"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "\n",
    "    # Sort folders\n",
    "    def extract_case_number(folder_name):\n",
    "        return int(folder_name.name.split(\"_\")[1])\n",
    "\n",
    "    case_folders.sort(key=extract_case_number)\n",
    "\n",
    "    print(f\"🔍 Found {len(case_folders)} cases to process\")\n",
    "    print(\"📦 Processing order:\")\n",
    "    for folder in case_folders:\n",
    "        print(f\"  - {folder.name}\")\n",
    "\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "\n",
    "    for folder in case_folders:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"🚀 Processing {folder.name}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        solution_folder = folder / \"Numerical_Solution\"\n",
    "\n",
    "        if solution_folder.exists():\n",
    "            if save_displacement_frames(solution_folder, mdpa_file, scale_factor):\n",
    "                successful += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "        else:\n",
    "            print(f\"❌ Error: Numerical_Solution folder not found in {folder.name}\")\n",
    "            failed += 1\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✅ Processing Complete!\")\n",
    "    print(f\"✅ Successfully processed: {successful}\")\n",
    "    print(f\"❌ Failed to process: {failed}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# Run the processing\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        process_all_cases(\n",
    "            base_dir=\"Dynamic_solution\",\n",
    "            mdpa_file=[file for file in os.listdir() if file.endswith('.mdpa')][0],\n",
    "            scale_factor=1e6\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in main execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "s = f_constrained.shape[0]\n",
    "num_cases = f_constrained.shape[1]\n",
    "\n",
    "def constant_force_factory(F):\n",
    "    return lambda t: F\n",
    "\n",
    "# Initial velocity and identity/zero matrices\n",
    "v0 = np.zeros((s, num_cases))\n",
    "I = np.eye(s)\n",
    "Z = np.zeros((s, s))\n",
    "\n",
    "# Combined matrices for state-space formulation\n",
    "M_star = np.block([[M_constrained, Z], [Z, I]])\n",
    "K_star = np.block([[Z, K_constrained], [-I, Z]])\n",
    "M_star_inv = np.linalg.inv(M_star)\n",
    "\n",
    "# Time settings\n",
    "total_time = 1.0\n",
    "dt = 1e-3\n",
    "t_span = (0, total_time)\n",
    "t_eval = np.arange(t_span[0], t_span[1] + dt, dt)\n",
    "\n",
    "# Define the ODE system\n",
    "\n",
    "def dUdt(t, U, M_star_inv, K_star, F_star):\n",
    "    return M_star_inv @ (F_star - (K_star @ U))\n",
    "\n",
    "# Create results directory\n",
    "base_dir = Path(\"Dynamic_solution\")\n",
    "base_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Starting multi-case dynamic analysis (solve_ivp)...\")\n",
    "print(f\"M: {M_constrained.shape}, K: {K_constrained.shape}, f: {f_constrained.shape}, cases: {num_cases}\\n\")\n",
    "\n",
    "results = []\n",
    "case_times = []\n",
    "\n",
    "# Solve each case\n",
    "for case in tqdm(range(num_cases), desc=\"Solving cases\"):\n",
    "    case_start = time.time()\n",
    "    magnitude = magnitudes[case]\n",
    "    magnitude_str = \", \".join(str(val) for val in magnitude)\n",
    "\n",
    "    case_folder = base_dir / f\"case_{case+1}_magnitude_({magnitude_str})\"\n",
    "    # analytical_folder = case_folder / \"Analytical_Solution\"\n",
    "    # analytical_folder.mkdir(parents=True, exist_ok=True)\n",
    "    analytical_folder = case_folder / \"Analytical_Solution\"\n",
    "    if analytical_folder.exists() and analytical_folder.is_dir():\n",
    "        shutil.rmtree(analytical_folder)\n",
    "    analytical_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Prepare initial state and force vector\n",
    "    U0 = np.concatenate((v0[:, case], x[:, case]))\n",
    "    F_star = np.concatenate((f_constrained[:, case], np.zeros(s)))\n",
    "\n",
    "    # Solve\n",
    "    sol = solve_ivp(dUdt, t_span, U0, args=(M_star_inv, K_star, F_star),\n",
    "                    t_eval=t_eval, method='Radau', rtol=1e-8) # Radau\n",
    "\n",
    "    t = sol.t\n",
    "    U = sol.y\n",
    "    v = U[:s].T\n",
    "    u = U[s:].T\n",
    "    # a = np.gradient(v, t, axis=0)\n",
    "    a = np.zeros_like(v)\n",
    "    a[1:] = (v[1:] - v[:-1]) / dt\n",
    "    a[0] = a[1]  # or zero\n",
    "    # Compute internal force F = M * a + K * u\n",
    "    f_internal = np.zeros_like(u)\n",
    "    for i in range(len(t)):\n",
    "        f_internal[i, :] = M_constrained @ a[i, :] + K_constrained @ u[i, :]\n",
    "\n",
    "\n",
    "    # np.save(analytical_folder / 'time_analytical.npy', t)\n",
    "    # np.save(analytical_folder / 'displacement_analytical.npy', u)\n",
    "    # np.save(analytical_folder / 'velocity_analytical.npy', v)\n",
    "    # np.save(analytical_folder / 'acceleration_analytical.npy', a)\n",
    "    # Save solution\n",
    "    np.save(analytical_folder / 'time_analytical.npy', t)\n",
    "    np.save(analytical_folder / 'displacement_analytical.npy', u)\n",
    "    np.save(analytical_folder / 'velocity_analytical.npy', v)\n",
    "    np.save(analytical_folder / 'acceleration_analytical.npy', a)\n",
    "    np.save(analytical_folder / 'force_analytical.npy', f_internal)\n",
    "\n",
    "    case_time = time.time() - case_start\n",
    "    case_times.append(case_time)\n",
    "\n",
    "    results.append({\n",
    "        \"case\": case + 1,\n",
    "        \"magnitude\": magnitude,\n",
    "        \"max_displacement\": np.max(np.abs(u)),\n",
    "        \"max_velocity\": np.max(np.abs(v)),\n",
    "        \"max_acceleration\": np.max(np.abs(a)),\n",
    "        \"solve_time\": case_time\n",
    "    })\n",
    "\n",
    "# Results summary\n",
    "print(\"\\nResults Summary:\")\n",
    "print(\"=\" * 80)\n",
    "summary_data = [[r[\"case\"], str(r[\"magnitude\"]),\n",
    "                 f\"{r['max_displacement']:.2e}\",\n",
    "                 f\"{r['max_velocity']:.2e}\",\n",
    "                 f\"{r['max_acceleration']:.2e}\",\n",
    "                 f\"{r['solve_time']:.2f}\"] for r in results]\n",
    "headers = [\"Case\", \"Magnitude\", \"Max Displacement\", \"Max Velocity\", \"Max Acceleration\", \"Solve Time (s)\"]\n",
    "print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Overall statistics\n",
    "total_runtime = sum(case_times)\n",
    "print(\"\\nOverall Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total computation time: {total_runtime:.2f} seconds\")\n",
    "print(f\"Average time per case: {total_runtime / num_cases:.2f} seconds\")\n",
    "print(f\"Fastest case: {min(case_times):.2f} seconds (Case {np.argmin(case_times)+1})\")\n",
    "print(f\"Slowest case: {max(case_times):.2f} seconds (Case {np.argmax(case_times)+1})\")\n",
    "\n",
    "print(f\"\\nAnalysis complete. Results saved in: {base_dir.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def plot_node_comparison(mdpa_file, node_ids, case_results, analytical_folder, scale_factor=1e6):\n",
    "    \"\"\"\n",
    "    Plot displacement, velocity, and acceleration vs. time for specified nodes.\n",
    "    Compare Newmark and analytical solutions.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    mdpa_file: str, path to the .mdpa file containing mesh information.\n",
    "    node_ids: list of int, node IDs to analyze.\n",
    "    case_results: dict, results from Newmark method.\n",
    "    analytical_folder: Path, folder containing analytical solution data.\n",
    "    scale_factor: float, scaling factor for displacements.\n",
    "    \"\"\"\n",
    "    # Read mesh information from the .mdpa file\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    node_coords.append([int(parts[0]), float(parts[1]), float(parts[2])])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "                    elements.append([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "\n",
    "    # Load analytical solution data\n",
    "    time_analytical = np.load(analytical_folder / 'time_analytical.npy')\n",
    "    displacement_analytical = np.load(analytical_folder / 'displacement_analytical.npy')\n",
    "    velocity_analytical = np.load(analytical_folder / 'velocity_analytical.npy')\n",
    "    acceleration_analytical = np.load(analytical_folder / 'acceleration_analytical.npy')\n",
    "\n",
    "    # Extract Newmark solution data\n",
    "    time_newmark = case_results['time']\n",
    "    displacement_newmark = case_results['displacement']\n",
    "    velocity_newmark = case_results['velocity']\n",
    "    acceleration_newmark = case_results['acceleration']\n",
    "\n",
    "    # Highlight nodes and plot graphs\n",
    "    for node_id in node_ids:\n",
    "        # Find the node in the mesh\n",
    "        selected_node = node_coords[node_coords[:, 0] == node_id][0]\n",
    "        node_x, node_y = selected_node[1], selected_node[2]\n",
    "        idx = np.where(node_coords[:, 0] == node_id)[0][0]\n",
    "\n",
    "        # Highlight the node on the mesh\n",
    "        triangulation = tri.Triangulation(node_coords[:, 1], node_coords[:, 2], elements)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.triplot(triangulation, 'k-', lw=0.5, alpha=0.5)\n",
    "        plt.scatter(node_x, node_y, color='red', label=f'Selected Node {node_id}')\n",
    "        plt.gca().add_artist(plt.Circle((node_x, node_y), radius=0.1, color='red', fill=False))\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.title(f'Mesh with Highlighted Node {node_id}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.axis('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot displacement vs. time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_newmark, displacement_newmark[:, idx], label='Newmark Method', color='blue')\n",
    "        plt.plot(time_analytical, displacement_analytical[:, idx], label='Analytical Solution', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Displacement (m)')\n",
    "        plt.title(f'Displacement vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot velocity vs. time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_newmark, velocity_newmark[:, idx], label='Newmark Method', color='blue')\n",
    "        plt.plot(time_analytical, velocity_analytical[:, idx], label='Analytical Solution', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Velocity (m/s)')\n",
    "        plt.title(f'Velocity vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot acceleration vs. time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_newmark, acceleration_newmark[:, idx], label='Newmark Method', color='blue')\n",
    "        plt.plot(time_analytical, acceleration_analytical[:, idx], label='Analytical Solution', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Acceleration (m/s²)')\n",
    "        plt.title(f'Acceleration vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "node_ids_to_analyze = [1, 154, 305]  # Replace with desired node IDs\n",
    "plot_node_comparison(mdpa_file, node_ids_to_analyze, case_results[0], Path(\"Dynamic_solution/case_1_magnitude_(-137.59, -63.13, 362.93)/Analytical_Solution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "import os\n",
    "\n",
    "def create_displacement_gif(folder_path, mdpa_file, scale_factor=1e6, step_interval=100):\n",
    "    \"\"\"\n",
    "    Create a displacement GIF for a specific case.\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    output_file = folder_path / 'displacement_animation.gif'\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"🎯 Processing folder: {folder_path.resolve()}\")\n",
    "\n",
    "    # Load solution data\n",
    "    time_file = folder_path / 'time_analytical.npy'\n",
    "    displacement_file = folder_path / 'displacement_analytical.npy'\n",
    "    print(f\"📥 Reading displacement data from:\")\n",
    "    print(f\"   ⏱️  Time data       : {time_file.resolve()}\")\n",
    "    print(f\"   📌 Displacement data: {displacement_file.resolve()}\")\n",
    "\n",
    "    time = np.load(time_file)\n",
    "    displacement = np.load(displacement_file)\n",
    "\n",
    "    # Read node coordinates and elements from the .mdpa file\n",
    "    print(f\"📄 Reading mesh connectivity from: {mdpa_file.resolve()}\")\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    x, y = float(parts[1]), float(parts[2])\n",
    "                    node_coords.append([x, y])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "                    elements.append([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 15))\n",
    "\n",
    "    # Base triangulation\n",
    "    x = node_coords[:, 0]\n",
    "    y = node_coords[:, 1]\n",
    "    triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "\n",
    "    # Global displacement limits\n",
    "    disp_magnitudes = []\n",
    "    for step in range(len(time)):\n",
    "        disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "        disp_magnitudes.append(disp_mag)\n",
    "\n",
    "    global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "    global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "    print(f\"📊 Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "        disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "        deformed_coords = node_coords + disp\n",
    "\n",
    "        # Undeformed\n",
    "        ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "\n",
    "        # Deformed mesh\n",
    "        triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "        tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                           vmin=global_min, vmax=global_max)\n",
    "        ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "        ax.grid(True)\n",
    "        ax.axis('equal')\n",
    "        ax.legend()\n",
    "\n",
    "        if frame == 0:\n",
    "            plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Print progress\n",
    "        if frame % 10 == 0:\n",
    "            print(f\"   🔄 Processing frame {frame}/{len(time)-1}\")\n",
    "\n",
    "    print(\"🛠️  Creating animation frames...\")\n",
    "    anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "\n",
    "    # Save animation\n",
    "    print(f\"💾 Saving animation to: {output_file.resolve()}\")\n",
    "    writer = PillowWriter(fps=1000 / step_interval)\n",
    "    anim.save(output_file, writer=writer)\n",
    "    plt.close()\n",
    "    print(\"✅ Animation complete!\\n\")\n",
    "    return True\n",
    "\n",
    "def get_case_folders(base_dir=\"Dynamic_solution\"):\n",
    "    \"\"\"Get all available case folders and sort them by case number.\"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    \n",
    "    # Find all case folders dynamically\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "    \n",
    "    # Sort case folders by case number\n",
    "    def extract_case_number(folder_name):\n",
    "        # Extract the case number from the folder name (e.g., \"case_1_magnitude_0.1\" -> 1)\n",
    "        return int(folder_name.name.split(\"_\")[1])\n",
    "    \n",
    "    case_folders.sort(key=extract_case_number)\n",
    "    return case_folders\n",
    "\n",
    "def user_select_cases(case_folders):\n",
    "    \"\"\"Allow user to select which cases to process.\"\"\"\n",
    "    print(\"\\nAvailable case folders:\")\n",
    "    for i, folder in enumerate(case_folders, 1):\n",
    "        print(f\"{i}. {folder.name}\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\nEnter case numbers to process (comma-separated, e.g., '1,3,5' or 'all' for all cases): \")\n",
    "            \n",
    "            if user_input.lower() == 'all':\n",
    "                print(\"Processing all cases.\")\n",
    "                selected_folders = case_folders\n",
    "                break\n",
    "            \n",
    "            # Get user-selected case numbers\n",
    "            selected_indices = [int(x.strip()) for x in user_input.split(',')]\n",
    "            \n",
    "            # Validate indices\n",
    "            if any(idx < 1 or idx > len(case_folders) for idx in selected_indices):\n",
    "                print(f\"Error: Please enter valid case numbers between 1 and {len(case_folders)}\")\n",
    "                continue\n",
    "            \n",
    "            # Get the selected folders\n",
    "            selected_folders = [case_folders[idx-1] for idx in selected_indices]\n",
    "            \n",
    "            if not selected_folders:\n",
    "                print(\"No valid cases selected.\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\n🔍 Selected {len(selected_folders)} cases to process:\")\n",
    "            for folder in selected_folders:\n",
    "                print(f\"  📁 {folder.name}\")\n",
    "            \n",
    "            break\n",
    "            \n",
    "        except ValueError:\n",
    "            print(\"❌ Error: Please enter valid numbers separated by commas.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {str(e)}\")\n",
    "    \n",
    "    return selected_folders\n",
    "\n",
    "def process_selected_cases(selected_folders, mdpa_file, scale_factor=1e6):\n",
    "    \"\"\"Process only the selected case folders.\"\"\"\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for folder in selected_folders:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"📂 Processing {folder.name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Adjust path to include Analytical_Solution subfolder\n",
    "        solution_folder = folder / \"Analytical_Solution\"\n",
    "        \n",
    "        if solution_folder.exists():\n",
    "            if create_displacement_gif(solution_folder, mdpa_file, scale_factor):\n",
    "                successful += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "        else:\n",
    "            print(f\"❌ Error: Analytical_Solution folder not found in {folder.name}\")\n",
    "            failed += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"🏁 Processing Complete!\")\n",
    "    print(f\"✅ Successfully processed: {successful} cases\")\n",
    "    print(f\"❌ Failed to process: {failed} cases\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        base_dir = \"Dynamic_solution\"\n",
    "        \n",
    "        # Find MDPA file\n",
    "        mdpa_files = [file for file in os.listdir() if file.endswith('.mdpa')]\n",
    "        if not mdpa_files:\n",
    "            print(\"❌ Error: No .mdpa files found in the current directory.\")\n",
    "            exit(1)\n",
    "        mdpa_file = Path(mdpa_files[0])\n",
    "        \n",
    "        # Get available case folders\n",
    "        case_folders = get_case_folders(base_dir)\n",
    "        \n",
    "        if not case_folders:\n",
    "            print(f\"❌ Error: No case folders found in {base_dir}.\")\n",
    "            exit(1)\n",
    "        \n",
    "        print(f\"📊 Found {len(case_folders)} total cases\")\n",
    "        \n",
    "        # Let user select cases\n",
    "        selected_folders = user_select_cases(case_folders)\n",
    "        \n",
    "        # Use the fixed scale factor\n",
    "        scale_factor = 1e6\n",
    "        \n",
    "        process_selected_cases(selected_folders, mdpa_file, scale_factor)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in main execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "# from pathlib import Path\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.tri as tri\n",
    "\n",
    "# def create_displacement_gif(folder_path, mdpa_file, scale_factor=1e6, step_interval=100):\n",
    "#     \"\"\"\n",
    "#     Create a displacement GIF for a specific case.\n",
    "#     \"\"\"\n",
    "#     folder_path = Path(folder_path)\n",
    "#     output_file = folder_path / 'displacement_animation.gif'\n",
    "\n",
    "#     print(\"=\" * 80)\n",
    "#     print(f\"🎯 Processing folder: {folder_path.resolve()}\")\n",
    "\n",
    "#     # Load solution data\n",
    "#     time_file = folder_path / 'time_analytical.npy'\n",
    "#     displacement_file = folder_path / 'displacement_analytical.npy'\n",
    "#     print(f\"📥 Reading displacement data from:\")\n",
    "#     print(f\"   ⏱️  Time data       : {time_file.resolve()}\")\n",
    "#     print(f\"   📌 Displacement data: {displacement_file.resolve()}\")\n",
    "\n",
    "#     time = np.load(time_file)\n",
    "#     displacement = np.load(displacement_file)\n",
    "\n",
    "#     # Read node coordinates and elements from the .mdpa file\n",
    "#     print(f\"📄 Reading mesh connectivity from: {mdpa_file.resolve()}\")\n",
    "#     node_coords = []\n",
    "#     elements = []\n",
    "#     reading_nodes = False\n",
    "#     reading_elements = False\n",
    "\n",
    "#     with open(mdpa_file, 'r') as file:\n",
    "#         for line in file:\n",
    "#             line = line.strip()\n",
    "#             if \"Begin Nodes\" in line:\n",
    "#                 reading_nodes = True\n",
    "#                 continue\n",
    "#             elif \"End Nodes\" in line:\n",
    "#                 reading_nodes = False\n",
    "#                 continue\n",
    "#             elif reading_nodes and line:\n",
    "#                 parts = line.split()\n",
    "#                 if len(parts) >= 4:\n",
    "#                     x, y = float(parts[1]), float(parts[2])\n",
    "#                     node_coords.append([x, y])\n",
    "\n",
    "#             if \"Begin Elements\" in line:\n",
    "#                 reading_elements = True\n",
    "#                 continue\n",
    "#             elif \"End Elements\" in line:\n",
    "#                 reading_elements = False\n",
    "#                 continue\n",
    "#             elif reading_elements and line:\n",
    "#                 parts = line.split()\n",
    "#                 if len(parts) >= 5:\n",
    "#                     n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "#                     elements.append([n1, n2, n3])\n",
    "\n",
    "#     node_coords = np.array(node_coords)\n",
    "#     elements = np.array(elements)\n",
    "\n",
    "#     # Create figure\n",
    "#     fig, ax = plt.subplots(figsize=(10, 15))\n",
    "\n",
    "#     # Base triangulation\n",
    "#     x = node_coords[:, 0]\n",
    "#     y = node_coords[:, 1]\n",
    "#     triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "\n",
    "#     # Global displacement limits\n",
    "#     disp_magnitudes = []\n",
    "#     for step in range(len(time)):\n",
    "#         disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "#         disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "#         disp_magnitudes.append(disp_mag)\n",
    "\n",
    "#     global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "#     global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "#     print(f\"📊 Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "#     def update(frame):\n",
    "#         ax.clear()\n",
    "#         disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "#         disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "#         deformed_coords = node_coords + disp\n",
    "\n",
    "#         # Undeformed\n",
    "#         ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "\n",
    "#         # Deformed mesh\n",
    "#         triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "#         tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "#                            vmin=global_min, vmax=global_max)\n",
    "#         ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "#         ax.set_xlabel('X')\n",
    "#         ax.set_ylabel('Y')\n",
    "#         ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "#         ax.grid(True)\n",
    "#         ax.axis('equal')\n",
    "#         ax.legend()\n",
    "\n",
    "#         if frame == 0:\n",
    "#             plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "#         plt.tight_layout()\n",
    "\n",
    "#     print(\"🛠️  Creating animation frames...\")\n",
    "#     anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "\n",
    "#     # Save animation\n",
    "#     print(f\"💾 Saving animation to: {output_file.resolve()}\")\n",
    "#     writer = PillowWriter(fps=1000 / step_interval)\n",
    "#     anim.save(output_file, writer=writer)\n",
    "#     plt.close()\n",
    "#     print(\"✅ Animation complete!\\n\")\n",
    "\n",
    "# # Run for all results\n",
    "# for case in results:\n",
    "#     folder_path = f\"Dynamic_solution/case_{case['case']}_magnitude_({', '.join(map(str, case['magnitude']))})/Analytical_Solution\"\n",
    "#     create_displacement_gif(folder_path, mdpa_file, scale_factor=1e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def save_displacement_frames(folder_path, mdpa_file, scale_factor=1e6):\n",
    "    \"\"\"\n",
    "    Save displacement screenshots for each time step as .png images.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    folder_path: str or Path, path to the folder containing displacement and time data.\n",
    "    mdpa_file: Path, path to the .mdpa file with mesh info.\n",
    "    scale_factor: float, scale applied to displacement values.\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    frame_output_dir = folder_path / 'displacement_frames'\n",
    "    frame_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"📂 Processing folder: {folder_path.resolve()}\")\n",
    "\n",
    "    # Load displacement and time data\n",
    "    time_file = folder_path / 'time_analytical.npy'\n",
    "    displacement_file = folder_path / 'displacement_analytical.npy'\n",
    "    print(f\"📥 Loading:\")\n",
    "    print(f\"   ⏱️  Time:        {time_file.resolve()}\")\n",
    "    print(f\"   📌 Displacement: {displacement_file.resolve()}\")\n",
    "\n",
    "    time = np.load(time_file)\n",
    "    displacement = np.load(displacement_file)\n",
    "\n",
    "    # Load mesh from .mdpa file\n",
    "    print(f\"📄 Reading mesh from: {mdpa_file.resolve()}\")\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    x, y = float(parts[1]), float(parts[2])\n",
    "                    node_coords.append([x, y])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "                    elements.append([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "\n",
    "    # Base mesh\n",
    "    triangulation_orig = tri.Triangulation(node_coords[:, 0], node_coords[:, 1], elements)\n",
    "\n",
    "    # Displacement range for consistent colorbar\n",
    "    disp_magnitudes = []\n",
    "    for step in range(len(time)):\n",
    "        disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "        disp_magnitudes.append(disp_mag)\n",
    "\n",
    "    global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "    global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "\n",
    "    print(f\"📊 Displacement magnitude range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "    print(f\"📸 Saving frames to: {frame_output_dir.resolve()}\\n\")\n",
    "\n",
    "    # Plot and save each frame\n",
    "    for frame in range(len(time)):\n",
    "        fig, ax = plt.subplots(figsize=(10, 15))\n",
    "        disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "        deformed_coords = node_coords + disp\n",
    "\n",
    "        triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "\n",
    "        ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "        tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                           vmin=global_min, vmax=global_max)\n",
    "        ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "        ax.axis('equal')\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the figure\n",
    "        frame_path = frame_output_dir / f\"frame_{frame:04d}.png\"\n",
    "        plt.savefig(frame_path)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Saved: {frame_path.name}\")\n",
    "\n",
    "    print(\"\\n🎉 All displacement frames saved successfully!\\n\")\n",
    "\n",
    "# Run for all results\n",
    "for case in results:\n",
    "    folder_path = f\"Dynamic_solution/case_{case['case']}_magnitude_({', '.join(map(str, case['magnitude']))})/Analytical_Solution\"\n",
    "    save_displacement_frames(folder_path, mdpa_file, scale_factor=1e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def read_and_organize_data(base_dir, variable_name):\n",
    "    \"\"\"\n",
    "    Read and organize data (displacement, velocity, acceleration, or force) from the Numerical_Solution folder of each case.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_dir: str, path to the base directory containing case folders.\n",
    "    variable_name: str, name of the variable to read (e.g., 'displacement', 'velocity', 'acceleration', 'force').\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    organized_data: dict, organized data for each case.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "\n",
    "    organized_data = {}\n",
    "\n",
    "    for case_folder in case_folders:\n",
    "        try:\n",
    "            # Extract case number and magnitude from folder name\n",
    "            case_name = case_folder.name\n",
    "            case_number = int(case_name.split(\"_\")[1])\n",
    "            magnitude = tuple(map(float, case_name.split(\"_magnitude_\")[1].strip(\"()\").split(\", \")))\n",
    "\n",
    "            # Path to the variable file\n",
    "            variable_file = case_folder / \"FOM_Solution\" / \"solution\" / f\"{variable_name}.npy\"\n",
    "\n",
    "            if variable_file.exists():\n",
    "                # Load variable data\n",
    "                variable_data = np.load(variable_file)\n",
    "\n",
    "                # Organize data\n",
    "                organized_data[case_number] = {\n",
    "                    \"magnitude\": magnitude,\n",
    "                    variable_name: variable_data\n",
    "                }\n",
    "                print(f\"✅ Successfully loaded {variable_name} data for Case {case_number}\")\n",
    "            else:\n",
    "                print(f\"❌ {variable_name.capitalize()} file not found for Case {case_number}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {case_folder.name}: {str(e)}\")\n",
    "\n",
    "    return organized_data\n",
    "\n",
    "# Example usage\n",
    "base_dir = \"Dynamic_solution\"\n",
    "\n",
    "# Initialize lists to store data for all cases\n",
    "displacement_list = []\n",
    "velocity_list = []\n",
    "acceleration_list = []\n",
    "force_list = []\n",
    "\n",
    "# Read and concatenate data for all variables\n",
    "for variable_name, data_list in zip(\n",
    "    [\"displacement\", \"velocity\", \"acceleration\", \"force\"],\n",
    "    [displacement_list, velocity_list, acceleration_list, force_list]\n",
    "):\n",
    "    organized_data = read_and_organize_data(base_dir, variable_name)\n",
    "    for case_number in sorted(organized_data.keys()):\n",
    "        data_list.append(organized_data[case_number][variable_name].T)  # Transpose to align DOF as rows\n",
    "\n",
    "    # Concatenate along the time axis if data_list is not empty\n",
    "    if data_list:\n",
    "        globals()[f\"organized_{variable_name}_data\"] = np.hstack(data_list)\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: No data found for variable '{variable_name}'.\")\n",
    "        globals()[f\"organized_{variable_name}_data\"] = np.array([])  # Create an empty array for consistency\n",
    "\n",
    "# Print summary\n",
    "print(\"📂 Data organized successfully.\")\n",
    "print(f\"📊 Total cases processed: {len(organized_data)}\")\n",
    "print(f\"📐 Final displacement data shape: {organized_displacement_data.shape}\")\n",
    "print(f\"📐 Final velocity data shape: {organized_velocity_data.shape}\")\n",
    "print(f\"📐 Final acceleration data shape: {organized_acceleration_data.shape}\")\n",
    "print(f\"📐 Final force data shape: {organized_force_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "def perform_complete_svd_analysis(displacement_matrix, energy_threshold=0.999, sv_threshold=1e-19):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" COMPLETE SVD AND REDUCED BASIS ANALYSIS \".center(80))\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Perform SVD\n",
    "    U, S, VT = np.linalg.svd(displacement_matrix, full_matrices=False)\n",
    "    num_modes = len(S)\n",
    "    cum_energy = np.cumsum(S) / np.sum(S)\n",
    "\n",
    "    # Reduced basis computation\n",
    "    r_energy = np.argmax(cum_energy >= energy_threshold) + 1 if any(cum_energy >= energy_threshold) else num_modes\n",
    "    r_threshold = np.sum(S >= sv_threshold)\n",
    "    final_rank = min(r_energy, r_threshold)\n",
    "    V_r = U[:, :final_rank]\n",
    "\n",
    "    results = {\n",
    "        'U': U,\n",
    "        'S': S,\n",
    "        'VT': VT,\n",
    "        'cumulative_energy': cum_energy,\n",
    "        'matrix_shape': displacement_matrix.shape,\n",
    "        'rank': np.linalg.matrix_rank(displacement_matrix),\n",
    "        'condition_number': np.max(S)/np.min(S) if np.min(S) > 0 else np.inf,\n",
    "        'effective_rank': np.sum(S > 1e-10 * S[0]),\n",
    "        'num_modes': num_modes,\n",
    "        'energy_threshold': energy_threshold,\n",
    "        'sv_threshold': sv_threshold,\n",
    "        'r_energy': r_energy,\n",
    "        'r_threshold': r_threshold,\n",
    "        'final_rank': final_rank,\n",
    "        'V_r': V_r,\n",
    "        'dimensionality_reduction': 100*(1 - final_rank/displacement_matrix.shape[0])\n",
    "    }\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.semilogy(S, 'b-', linewidth=2, marker='o', markersize=5)\n",
    "    plt.title(\"Singular Values (Log Scale)\", fontsize=12)\n",
    "    plt.xlabel(\"Mode Number\")\n",
    "    plt.ylabel(\"Singular Value (\\u03c3)\")\n",
    "    plt.grid(True, which=\"both\", linestyle='--', alpha=0.5)\n",
    "    plt.axhline(y=sv_threshold, color='r', linestyle='--', label=f'Threshold ({sv_threshold:.1e})')\n",
    "    plt.axvline(x=final_rank, color='g', linestyle=':', label=f'Selected rank ({final_rank})')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(cum_energy, 'g-', linewidth=2, marker='s', markersize=5)\n",
    "    plt.title(\"Cumulative Energy\", fontsize=12)\n",
    "    plt.xlabel(\"Mode Number\")\n",
    "    plt.ylabel(\"Fraction of Total Energy\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.axhline(y=energy_threshold, color='r', linestyle='--', label=f'{energy_threshold*100:.1f}% threshold')\n",
    "    plt.axvline(x=final_rank, color='g', linestyle=':', label=f'Selected rank ({final_rank})')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for i in range(min(3, final_rank)):\n",
    "        plt.plot(V_r[:50, i], label=f'Basis {i+1}')\n",
    "    plt.title(\"First 3 Basis Vectors (First 50 elements)\", fontsize=12)\n",
    "    plt.xlabel(\"Degree of Freedom\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Text output\n",
    "    print(f\"\\n{' MATRIX PROPERTIES ':-^80}\")\n",
    "    print(f\"{'Shape:':<25} {displacement_matrix.shape} (DOFs × snapshots)\")\n",
    "    print(f\"{'Numerical rank:':<25} {results['rank']}\")\n",
    "    print(f\"{'Condition number:':<25} {results['condition_number']:.2e}\")\n",
    "    print(f\"{'Effective rank (1e-10):':<25} {results['effective_rank']}\")\n",
    "\n",
    "    print(f\"\\n{' REDUCED BASIS SELECTION ':-^80}\")\n",
    "    print(f\"{'Energy threshold:':<25} {energy_threshold:.3f} ({(energy_threshold*100):.1f}%)\")\n",
    "    print(f\"{'SV threshold:':<25} {sv_threshold:.1e}\")\n",
    "    print(f\"{'Rank by energy:':<25} {r_energy} (captures {cum_energy[r_energy-1]*100:.2f}% energy)\")\n",
    "    print(f\"{'Rank by SV threshold:':<25} {r_threshold}\")\n",
    "    print(f\"{'Final selected rank:':<25} {final_rank}\")\n",
    "    print(f\"{'Dimensionality reduction:':<25} {results['dimensionality_reduction']:.1f}% ({displacement_matrix.shape[0]} → {final_rank})\")\n",
    "\n",
    "    print(f\"\\n{' MODE ANALYSIS ':-^80}\")\n",
    "    print(tabulate([\n",
    "        [\"1\", f\"{S[0]:.3e}\", f\"{cum_energy[0]*100:.2f}%\"],\n",
    "        [\"2\", f\"{S[1]:.3e}\", f\"{cum_energy[1]*100:.2f}%\"],\n",
    "        [\"3\", f\"{S[2]:.3e}\", f\"{cum_energy[2]*100:.2f}%\"],\n",
    "        [\"...\", \"...\", \"...\"],\n",
    "        [str(final_rank), f\"{S[final_rank-1]:.3e}\", f\"{cum_energy[final_rank-1]*100:.2f}%\"],\n",
    "        [\"Full\", f\"{S[-1]:.3e}\", \"100.00%\"]\n",
    "    ], headers=[\"Mode\", \"Singular Value\", \"Cumulative Energy\"], tablefmt=\"grid\"))\n",
    "\n",
    "    print(f\"\\n{' REDUCED BASIS PROPERTIES ':-^80}\")\n",
    "    print(f\"{'Shape:':<25} {V_r.shape} (DOFs × modes)\")\n",
    "    print(f\"{'Orthogonality check:':<25} Max off-diagonal: {np.max(np.abs(V_r.T @ V_r - np.eye(final_rank))):.2e}\")\n",
    "    print(\"\\nFirst 5 elements of first 3 basis vectors:\")\n",
    "    for i in range(min(3, final_rank)):\n",
    "        print(f\"Basis {i+1}: {np.array2string(V_r[:5, i], precision=3, separator=', ')}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "# if 'organized_displacement_data' in globals() and organized_displacement_data.size > 0:\n",
    "#     analysis_results = perform_complete_svd_analysis(\n",
    "#         displacement_matrix=organized_displacement_data,\n",
    "#         energy_threshold=0.999,\n",
    "#         sv_threshold=1e-11\n",
    "if 'organized_displacement_data' in globals() and organized_displacement_data.size > 0:\n",
    "    analysis_results = perform_complete_svd_analysis(\n",
    "        displacement_matrix=organized_displacement_data,\n",
    "        energy_threshold=0.9999,\n",
    "        sv_threshold=1e-8\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nNo displacement data found for SVD analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_r = analysis_results['V_r']\n",
    "print(f\"\\n{' V_r (Reduced Basis) ':-^80}\")\n",
    "print(f\"Shape: {V_r.shape} (DOFs × modes)\")\n",
    "# print(V_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Ensure organized data and V_r from previous SVD are available\n",
    "assert 'organized_displacement_data' in globals()\n",
    "assert 'organized_velocity_data' in globals()\n",
    "assert 'organized_acceleration_data' in globals()\n",
    "assert 'organized_force_data' in globals()\n",
    "assert 'V_r' in globals()\n",
    "\n",
    "print(f\"\\n{' V_r (Reduced Basis) ':-^80}\")\n",
    "print(f\"Shape: {V_r.shape} (DOFs × modes)\")\n",
    "\n",
    "# Function to project and reconstruct a matrix\n",
    "\n",
    "def project_and_reconstruct(matrix, V_r, label=\"\"):\n",
    "    original_shape = matrix.shape\n",
    "    projected = V_r.T @ matrix\n",
    "    reconstructed = V_r @ projected\n",
    "    error = np.linalg.norm(matrix - reconstructed) / np.linalg.norm(matrix)\n",
    "    error_percent = error * 100\n",
    "\n",
    "    print(f\"\\n{' ' + label + ' RECONSTRUCTION DETAILS ':=^80}\")\n",
    "    print(f\"Original shape      : {original_shape}\")\n",
    "    print(f\"Reduced shape       : {projected.shape}\")\n",
    "    print(f\"Reconstructed shape : {reconstructed.shape}\")\n",
    "    print(f\"Reconstruction error: {error:.3e}\")\n",
    "    print(f\"Percentage error    : {error_percent:.3f}%\")\n",
    "\n",
    "    return projected, reconstructed, error\n",
    "\n",
    "# Apply to each variable\n",
    "projected_displacement, reconstructed_displacement, err_disp = project_and_reconstruct(\n",
    "    organized_displacement_data, V_r, label=\"Displacement\"\n",
    ")\n",
    "\n",
    "projected_velocity, reconstructed_velocity, err_vel = project_and_reconstruct(\n",
    "    organized_velocity_data, V_r, label=\"Velocity\"\n",
    ")\n",
    "\n",
    "projected_acceleration, reconstructed_acceleration, err_acc = project_and_reconstruct(\n",
    "    organized_acceleration_data, V_r, label=\"Acceleration\"\n",
    ")\n",
    "\n",
    "projected_force, reconstructed_force, err_force = project_and_reconstruct(\n",
    "    organized_force_data, V_r, label=\"Force\"\n",
    ")\n",
    "\n",
    "# Collect all errors into a dictionary for summary\n",
    "reconstruction_errors = {\n",
    "    \"Displacement\": err_disp,\n",
    "    \"Velocity\": err_vel,\n",
    "    \"Acceleration\": err_acc,\n",
    "    \"Force\": err_force\n",
    "}\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" RECONSTRUCTION ERROR SUMMARY \".center(80))\n",
    "print(\"=\"*80)\n",
    "for var, err in reconstruction_errors.items():\n",
    "    print(f\"{var:<20}: {err:.3e} ({err * 100:.3f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reduced_list = []\n",
    "f_reduced_list = []\n",
    "\n",
    "n_cases = x.shape[1]\n",
    "\n",
    "for i in range(n_cases):\n",
    "    x_case = x[:, i]                      # Full-order displacement for case i\n",
    "    f_case = f_constrained[:, i]         # Full-order force for case i\n",
    "\n",
    "    x_r = V_r.T @ x_case                 # Reduced displacement (r,)\n",
    "    f_r = V_r.T @ f_case                 # Reduced force (r,)\n",
    "\n",
    "    x_reduced_list.append(x_r)\n",
    "    f_reduced_list.append(f_r)\n",
    "\n",
    "# Stack to shape (r, n_cases)\n",
    "x_reduced = np.column_stack(x_reduced_list)\n",
    "f_reduced = np.column_stack(f_reduced_list)\n",
    "\n",
    "print(f\"\\n{' REDUCED INITIAL VALUES (Per Case Projection) ':-^80}\")\n",
    "print(f\"x_reduced shape: {x_reduced.shape}\")\n",
    "print(f\"f_reduced shape: {f_reduced.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([projected_acceleration.T, projected_displacement.T])   # Shape: (m × 2r)\n",
    "print(X.shape)  # Shape: (m × 2r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_regression_matrix(X):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REGRESSION MATRIX ANALYSIS (X = [Üᵗ | Uᵗ])\".center(60))\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    rank = np.linalg.matrix_rank(X)\n",
    "    condition_number = np.linalg.cond(X)\n",
    "    svals = np.linalg.svd(X, compute_uv=False)\n",
    "    \n",
    "    print(f\"{'Shape:':<25} {X.shape}\")\n",
    "    print(f\"{'Rank:':<25} {rank}\")\n",
    "    print(f\"{'Full rank:':<25} {rank == X.shape[1]}\")\n",
    "    print(f\"{'Condition number:':<25} {condition_number:.2e}\")\n",
    "    print(f\"{'Min singular value:':<25} {svals.min():.3e}\")\n",
    "    print(f\"{'Max singular value:':<25} {svals.max():.3e}\")\n",
    "\n",
    "# Call this inside your function or after defining X\n",
    "analyze_regression_matrix(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation without using velocity - Opertor Infered ROM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_A_matrix_general(projected_acceleration, projected_displacement):\n",
    "    r, m = projected_acceleration.shape\n",
    "    \n",
    "    # Generate M and K variable indices (upper triangle)\n",
    "    M_vars = [(i, j) for i in range(r) for j in range(i, r)]\n",
    "    K_vars = [(i, j) for i in range(r) for j in range(i, r)]\n",
    "    \n",
    "    # Create dictionaries for quick index lookup\n",
    "    M_var_dict = {(p, q): idx for idx, (p, q) in enumerate(M_vars)}\n",
    "    K_var_dict = {(p, q): idx for idx, (p, q) in enumerate(K_vars)}\n",
    "    \n",
    "    num_vars = len(M_vars) + len(K_vars)\n",
    "    A_rows = []\n",
    "    \n",
    "    # Generalized loop for any number of time steps\n",
    "    for j in range(m):        # loop over time step\n",
    "        for i in range(r):    # loop over mode\n",
    "            row = np.zeros(num_vars)\n",
    "            for k in range(r):\n",
    "                # M[i,k] contribution\n",
    "                mp, mq = (i, k) if i <= k else (k, i)\n",
    "                row[M_var_dict[(mp, mq)]] += projected_acceleration[k, j]\n",
    "\n",
    "                # K[i,k] contribution\n",
    "                kp, kq = (i, k) if i <= k else (k, i)\n",
    "                row[len(M_vars) + K_var_dict[(kp, kq)]] += projected_displacement[k, j]\n",
    "            A_rows.append(row)\n",
    "    \n",
    "    return np.vstack(A_rows)\n",
    "\n",
    "# Now test with the 1-column displacement/acceleration matrix\n",
    "A_single_fixed = construct_A_matrix_general(projected_acceleration, projected_displacement)\n",
    "\n",
    "print(A_single_fixed.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the force matrix column-wise (consistent with row ordering in A)\n",
    "fr_flattened = projected_force.T.flatten()\n",
    "\n",
    "# b_flattened.shape, b_flattened\n",
    "print(fr_flattened.shape)  # Should be (12,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute least squares using A_single_fixed and b_flattened\n",
    "x_single_solution, _, _, _ = np.linalg.lstsq(A_single_fixed, fr_flattened, rcond=None)\n",
    "\n",
    "# Dynamically determine the number of modes from the shape of A\n",
    "num_total_vars_single = A_single_fixed.shape[1]\n",
    "r_single = int((-1 + np.sqrt(1 + 8 * (num_total_vars_single // 2))) // 2)\n",
    "n_sym_single = r_single * (r_single + 1) // 2\n",
    "\n",
    "# Extract vec_M and vec_K\n",
    "vec_M_single = x_single_solution[:n_sym_single]\n",
    "vec_K_single = x_single_solution[n_sym_single:]\n",
    "\n",
    "r_single, n_sym_single, vec_M_single, vec_K_single\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the previously defined function to convert vec (upper triangle) to full symmetric matrices\n",
    "\n",
    "def vech_to_symmetric(vec, size):\n",
    "    mat = np.zeros((size, size))\n",
    "    triu_indices = np.triu_indices(size)\n",
    "    mat[triu_indices] = vec\n",
    "    mat[(triu_indices[1], triu_indices[0])] = vec  # fill lower triangle\n",
    "    return mat\n",
    "\n",
    "# Reconstruct M_tilde and K_tilde from the vectors\n",
    "M_tilde = vech_to_symmetric(vec_M_single, r_single)\n",
    "K_tilde = vech_to_symmetric(vec_K_single, r_single)\n",
    "\n",
    "# M_tilde_single, K_tilde_single\n",
    "print(M_tilde.shape, K_tilde.shape)  # Should be (r, r) for both\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "def check_matrix_properties(matrix, name):\n",
    "    \"\"\"\n",
    "    Check and return properties of a matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - matrix: The matrix to check.\n",
    "    - name: Name of the matrix (for display purposes).\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary containing the properties of the matrix.\n",
    "    \"\"\"\n",
    "    properties = {}\n",
    "    properties[\"Matrix\"] = name\n",
    "    properties[\"Shape\"] = matrix.shape\n",
    "    properties[\"Symmetric\"] = np.allclose(matrix, matrix.T, atol=1e-8)\n",
    "    properties[\"Real Values\"] = np.isreal(matrix).all()\n",
    "    properties[\"Positive Values\"] = (matrix > 0).all()\n",
    "    eigenvalues = np.linalg.eigvals(matrix)\n",
    "    properties[\"Real Eigenvalues\"] = np.isreal(eigenvalues).all()\n",
    "    properties[\"Positive Eigenvalues\"] = (eigenvalues > 0).all()\n",
    "    properties[\"Min Eigenvalue\"] = np.min(eigenvalues).real if np.isreal(eigenvalues).all() else \"Complex\"\n",
    "    properties[\"Max Eigenvalue\"] = np.max(eigenvalues).real if np.isreal(eigenvalues).all() else \"Complex\"\n",
    "    properties[\"Condition Number\"] = np.linalg.cond(matrix)\n",
    "    return properties\n",
    "\n",
    "# Check properties of M_tilde and K_tilde\n",
    "M_tilde_properties = check_matrix_properties(M_tilde, \"M_tilde\")\n",
    "K_tilde_properties = check_matrix_properties(K_tilde, \"K_tilde\")\n",
    "\n",
    "# Tabulate the results\n",
    "table = [M_tilde_properties, K_tilde_properties]\n",
    "headers = [\"Property\", \"M_tilde\", \"K_tilde\"]\n",
    "rows = [\n",
    "    [\"Shape\", M_tilde_properties[\"Shape\"], K_tilde_properties[\"Shape\"]],\n",
    "    [\"Symmetric\", M_tilde_properties[\"Symmetric\"], K_tilde_properties[\"Symmetric\"]],\n",
    "    [\"Real Values\", M_tilde_properties[\"Real Values\"], K_tilde_properties[\"Real Values\"]],\n",
    "    [\"Positive Values\", M_tilde_properties[\"Positive Values\"], K_tilde_properties[\"Positive Values\"]],\n",
    "    [\"Real Eigenvalues\", M_tilde_properties[\"Real Eigenvalues\"], K_tilde_properties[\"Real Eigenvalues\"]],\n",
    "    [\"Positive Eigenvalues\", M_tilde_properties[\"Positive Eigenvalues\"], K_tilde_properties[\"Positive Eigenvalues\"]],\n",
    "    [\"Min Eigenvalue\", M_tilde_properties[\"Min Eigenvalue\"], K_tilde_properties[\"Min Eigenvalue\"]],\n",
    "    [\"Max Eigenvalue\", M_tilde_properties[\"Max Eigenvalue\"], K_tilde_properties[\"Max Eigenvalue\"]],\n",
    "    [\"Condition Number\", f\"{M_tilde_properties['Condition Number']:.2e}\", f\"{K_tilde_properties['Condition Number']:.2e}\"],\n",
    "]\n",
    "\n",
    "print(\"\\nMatrix Properties:\")\n",
    "print(tabulate(rows, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.eigvals(M_tilde))\n",
    "print(np.linalg.eigvals(K_tilde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir, case_results, case_times = solve_newmark_dynamic_multi_case(\n",
    "    M=M_tilde,\n",
    "    K=K_tilde,\n",
    "    f=f_reduced,\n",
    "    magnitudes=magnitudes,\n",
    "    x=x_reduced,\n",
    "    total_time=1.0,\n",
    "    dt=1e-3,\n",
    "    beta=0.25,\n",
    "    gamma=0.5,\n",
    "    tol=1e-8,\n",
    "    max_iter=50,\n",
    "    subfolder_name=\"ROM_Solution\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = Path.cwd()\n",
    "\n",
    "# Navigate to the \"Dynamic_solution\" directory\n",
    "dynamic_solution_dir = cwd / \"Dynamic_solution\"\n",
    "\n",
    "# Initialize a list to store the tabulated data\n",
    "tabulated_data = []\n",
    "\n",
    "# Iterate through all case folders and collect data\n",
    "for case_folder in sorted(dynamic_solution_dir.glob(\"case_*_magnitude_*\"), key=lambda x: int(x.name.split(\"_\")[1])):\n",
    "    rom_dir = case_folder / \"ROM_Solution\" / \"solution\"\n",
    "    # Check if the directory exists\n",
    "    if rom_dir.exists() and rom_dir.is_dir():\n",
    "        case_data = [case_folder.name]  # Initialize row with case folder name\n",
    "        # Iterate through all files in the directory\n",
    "        for file in sorted(rom_dir.iterdir()):\n",
    "            if file.is_file():\n",
    "                # Get the size of the file in bytes\n",
    "                file_size = os.path.getsize(file)\n",
    "                # Load the file content if it's a numpy file\n",
    "                if file.suffix == '.npy':\n",
    "                    data = np.load(file)\n",
    "                    case_data.append(f\"{file.name}: {data.shape}\")\n",
    "                else:\n",
    "                    case_data.append(f\"{file.name}: N/A\")\n",
    "        tabulated_data.append(case_data)\n",
    "    else:\n",
    "        tabulated_data.append([case_folder.name, \"Directory does not exist\"])\n",
    "\n",
    "# Print the tabulated data\n",
    "headers = [\"Case Folder\"] + [f\"File {i+1}\" for i in range(len(tabulated_data[0]) - 1)]\n",
    "print(tabulate(tabulated_data, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define base path and target variables\n",
    "base_dir = Path.cwd() / \"Dynamic_solution\"\n",
    "variables = [\"displacement\", \"velocity\", \"acceleration\", \"force\"]\n",
    "\n",
    "# Display V_r shape once\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"{'FULL-ORDER RECONSTRUCTION USING REDUCED BASIS':^100}\")\n",
    "print(f\"{'='*100}\")\n",
    "print(f\"Using V_r of shape: {V_r.shape} (DOFs × Modes)\")\n",
    "\n",
    "# Table to store case summary\n",
    "tabulated_data = []\n",
    "\n",
    "# Process each case\n",
    "for case_folder in sorted(base_dir.glob(\"case_*_magnitude_*\"), key=lambda x: int(x.name.split(\"_\")[1])):\n",
    "    rom_input_dir = case_folder / \"ROM_Solution\" / \"solution\"\n",
    "    rom_output_dir = case_folder / \"ROM_constructed\"\n",
    "    rom_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    case_data = [case_folder.name]\n",
    "\n",
    "    if rom_input_dir.exists():\n",
    "        for var in variables:\n",
    "            input_file = rom_input_dir / f\"{var}.npy\"\n",
    "            output_file = rom_output_dir / f\"{var}.npy\"\n",
    "\n",
    "            if input_file.exists():\n",
    "                reduced_data = np.load(input_file)\n",
    "\n",
    "                # Validate shape\n",
    "                if reduced_data.shape[1] != V_r.shape[1]:\n",
    "                    case_data.append(f\"{var}: shape mismatch\")\n",
    "                    continue\n",
    "\n",
    "                # Reconstruct and save\n",
    "                full_data = reduced_data @ V_r.T  # Shape: (time_steps, dofs)\n",
    "                np.save(output_file, full_data)\n",
    "                case_data.append(f\"{var}.npy: {full_data.shape}\")\n",
    "            else:\n",
    "                case_data.append(f\"{var}: missing\")\n",
    "    else:\n",
    "        case_data.append(\"ROM_Solution missing\")\n",
    "\n",
    "    tabulated_data.append(case_data)\n",
    "\n",
    "# Build and display table\n",
    "headers = [\"Case Folder\"] + [var.capitalize() for var in variables]\n",
    "max_len = max(len(row) for row in tabulated_data)\n",
    "for row in tabulated_data:\n",
    "    while len(row) < max_len:\n",
    "        row.append(\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\" RECONSTRUCTED FULL-ORDER MATRICES FROM REDUCED VARIABLES \".center(100))\n",
    "print(\"=\" * 100)\n",
    "print(tabulate(tabulated_data, headers=headers, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define the base directory\n",
    "base_dir = Path(\"Dynamic_solution\")\n",
    "\n",
    "# Initialize a list to store the tabulated data\n",
    "table_data = []\n",
    "\n",
    "# Iterate through all case folders\n",
    "for case_folder in sorted(base_dir.glob(\"case_*_magnitude_*\"), key=lambda x: int(x.name.split(\"_\")[1])):\n",
    "    rom_constructed_dir = case_folder / \"ROM_constructed\"\n",
    "    if rom_constructed_dir.exists() and rom_constructed_dir.is_dir():\n",
    "        case_name = case_folder.name\n",
    "        displacement_file = rom_constructed_dir / \"displacement.npy\"\n",
    "        velocity_file = rom_constructed_dir / \"velocity.npy\"\n",
    "        acceleration_file = rom_constructed_dir / \"acceleration.npy\"\n",
    "\n",
    "        # Initialize variables to store max values, shapes, and file paths\n",
    "        max_displacement = max_velocity = max_acceleration = \"N/A\"\n",
    "        displacement_shape = velocity_shape = acceleration_shape = \"N/A\"\n",
    "        displacement_path = velocity_path = acceleration_path = \"N/A\"\n",
    "\n",
    "        # Read displacement\n",
    "        if displacement_file.exists():\n",
    "            displacement_data = np.load(displacement_file)\n",
    "            max_displacement = np.max(np.abs(displacement_data))\n",
    "            displacement_shape = displacement_data.shape\n",
    "            displacement_path = str(displacement_file)\n",
    "\n",
    "        # Read velocity\n",
    "        if velocity_file.exists():\n",
    "            velocity_data = np.load(velocity_file)\n",
    "            max_velocity = np.max(np.abs(velocity_data))\n",
    "            velocity_shape = velocity_data.shape\n",
    "            velocity_path = str(velocity_file)\n",
    "\n",
    "        # Read acceleration\n",
    "        if acceleration_file.exists():\n",
    "            acceleration_data = np.load(acceleration_file)\n",
    "            max_acceleration = np.max(np.abs(acceleration_data))\n",
    "            acceleration_shape = acceleration_data.shape\n",
    "            acceleration_path = str(acceleration_file)\n",
    "\n",
    "        # Append the data to the table\n",
    "        table_data.append([\n",
    "            case_name,\n",
    "            displacement_shape, max_displacement, displacement_path,\n",
    "            velocity_shape, max_velocity, velocity_path,\n",
    "            acceleration_shape, max_acceleration, acceleration_path\n",
    "        ])\n",
    "\n",
    "# Define the headers\n",
    "headers = [\n",
    "    \"Case Name\",\n",
    "    \"Displacement Shape\", \"Max Displacement\", \"Displacement Path\",\n",
    "    \"Velocity Shape\", \"Max Velocity\", \"Velocity Path\",\n",
    "    \"Acceleration Shape\", \"Max Acceleration\", \"Acceleration Path\"\n",
    "]\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Define the base directory for the cases\n",
    "base_dir = Path.cwd() / \"Dynamic_solution\"\n",
    "variables = [\"displacement\", \"velocity\", \"acceleration\", \"force\"]\n",
    "\n",
    "# Initialize a list to store the tabulated data\n",
    "comparison_results = []\n",
    "\n",
    "# Define the `results` variable based on the `magnitudes` list\n",
    "results = [{\"case\": i + 1, \"magnitude\": magnitude} for i, magnitude in enumerate(magnitudes)]\n",
    "\n",
    "# Iterate through all cases\n",
    "for case in results:\n",
    "    case_folder_name = f\"case_{case['case']}_magnitude_({', '.join(map(str, case['magnitude']))})\"\n",
    "    case_folder = base_dir / case_folder_name\n",
    "    fom_dir = case_folder / \"FOM_Solution\" / \"solution\"\n",
    "    rom_dir = case_folder / \"ROM_constructed\"\n",
    "\n",
    "    case_errors = {\"Case\": case_folder_name}\n",
    "\n",
    "    if fom_dir.exists() and rom_dir.exists():\n",
    "        for variable in variables:\n",
    "            fom_file = fom_dir / f\"{variable}.npy\"\n",
    "            rom_file = rom_dir / f\"{variable}.npy\"\n",
    "\n",
    "            if fom_file.exists() and rom_file.exists():\n",
    "                fom_data = np.load(fom_file)  # (time_steps, dofs)\n",
    "                rom_data = np.load(rom_file)  # (time_steps, dofs)\n",
    "\n",
    "                # Interpolate ROM if needed\n",
    "                if fom_data.shape[0] != rom_data.shape[0]:\n",
    "                    rom_steps = rom_data.shape[0]\n",
    "                    interpolator = interp1d(\n",
    "                        np.linspace(0, 1, rom_steps),\n",
    "                        rom_data, axis=0, kind='linear', fill_value=\"extrapolate\"\n",
    "                    )\n",
    "                    rom_data = interpolator(np.linspace(0, 1, fom_data.shape[0]))\n",
    "\n",
    "                # Final shape check\n",
    "                if fom_data.shape != rom_data.shape:\n",
    "                    case_errors[variable.capitalize()] = f\"Shape mismatch: FOM {fom_data.shape}, ROM {rom_data.shape}\"\n",
    "                    continue\n",
    "\n",
    "                # Compute error and accuracy\n",
    "                error = np.linalg.norm(fom_data - rom_data) / np.linalg.norm(fom_data)\n",
    "                accuracy = max(0.0, (1.0 - error)) * 100\n",
    "                case_errors[variable.capitalize()] = f\"{error:.2e} (Accuracy: {accuracy:.2f}%)\"\n",
    "            else:\n",
    "                case_errors[variable.capitalize()] = \"Missing Data\"\n",
    "    else:\n",
    "        for variable in variables:\n",
    "            case_errors[variable.capitalize()] = \"Missing FOM or ROM\"\n",
    "\n",
    "    comparison_results.append(case_errors)\n",
    "\n",
    "# Build and display table\n",
    "headers = [\"Case\"] + [var.capitalize() for var in variables]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\" COMPARISON OF FOM AND ROM VARIABLES \".center(100))\n",
    "print(\"=\" * 100)\n",
    "print(tabulate(comparison_results, headers=\"keys\", tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# Define the base directory containing all cases\n",
    "base_dir = Path(\"Dynamic_solution\")\n",
    "\n",
    "# Iterate through all case folders\n",
    "for case_folder in sorted(base_dir.glob(\"case_*_magnitude_*\"), key=lambda x: int(x.name.split(\"_\")[1])):\n",
    "    rom_solution_path = case_folder / \"ROM_Solution\" / \"solution\"\n",
    "    rom_constructed_path = case_folder / \"ROM_constructed\"\n",
    "\n",
    "    # Ensure the ROM_Constructed directory exists\n",
    "    rom_constructed_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Copy the time.npy file from ROM_Solution/solution to ROM_Constructed\n",
    "    time_file = rom_solution_path / \"time.npy\"\n",
    "    if time_file.exists():\n",
    "        shutil.copy(time_file, rom_constructed_path)\n",
    "        print(f\"Copied {time_file.name} to {rom_constructed_path.resolve()}\")\n",
    "    else:\n",
    "        print(f\"{time_file.name} does not exist in {rom_solution_path.resolve()}\")\n",
    "\n",
    "    # Print the shape of all .npy files in the ROM_Constructed folder\n",
    "    if rom_constructed_path.exists() and rom_constructed_path.is_dir():\n",
    "        print(f\"\\nReading .npy files from: {rom_constructed_path.resolve()}\\n\")\n",
    "        for npy_file in rom_constructed_path.glob(\"*.npy\"):\n",
    "            data = np.load(npy_file)\n",
    "            print(f\"{npy_file.name}: shape={data.shape}\")\n",
    "    else:\n",
    "        print(f\"Directory does not exist: {rom_constructed_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def plot_node_comparison(mdpa_file, node_ids, fom_folder, rom_folder, scale_factor=1e6):\n",
    "    \"\"\"\n",
    "    Plot displacement, velocity, and acceleration vs. time for specified nodes.\n",
    "    Compare FOM and ROM solutions.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    mdpa_file: str, path to the .mdpa file containing mesh information.\n",
    "    node_ids: list of int, node IDs to analyze.\n",
    "    fom_folder: Path, folder containing FOM solution data.\n",
    "    rom_folder: Path, folder containing ROM solution data.\n",
    "    scale_factor: float, scaling factor for displacements.\n",
    "    \"\"\"\n",
    "    # Read mesh information from the .mdpa file\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    node_coords.append([int(parts[0]), float(parts[1]), float(parts[2])])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "                    elements.append([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "\n",
    "    # Load FOM solution data\n",
    "    try:\n",
    "        time_fom = np.load(fom_folder / 'time.npy')\n",
    "        displacement_fom = np.load(fom_folder / 'displacement.npy')\n",
    "        velocity_fom = np.load(fom_folder / 'velocity.npy')\n",
    "        acceleration_fom = np.load(fom_folder / 'acceleration.npy')\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Please ensure the FOM solution files exist in the specified folder.\")\n",
    "        return\n",
    "\n",
    "    # Load ROM solution data\n",
    "    try:\n",
    "        time_rom = np.load(rom_folder / 'time.npy')\n",
    "        displacement_rom = np.load(rom_folder / 'displacement.npy')\n",
    "        velocity_rom = np.load(rom_folder / 'velocity.npy')\n",
    "        acceleration_rom = np.load(rom_folder / 'acceleration.npy')\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Please ensure the ROM solution files exist in the specified folder.\")\n",
    "        return\n",
    "\n",
    "    # Highlight nodes and plot graphs\n",
    "    for node_id in node_ids:\n",
    "        # Find the node in the mesh\n",
    "        selected_node = node_coords[node_coords[:, 0] == node_id][0]\n",
    "        node_x, node_y = selected_node[1], selected_node[2]\n",
    "        idx_array = np.where(node_coords[:, 0] == node_id)[0]\n",
    "        if len(idx_array) == 0:\n",
    "            print(f\"Warning: Node ID {node_id} not found in the mesh. Skipping this node.\")\n",
    "            continue\n",
    "        idx = idx_array[0]\n",
    "\n",
    "        # Highlight the node on the mesh\n",
    "        triangulation = tri.Triangulation(node_coords[:, 1], node_coords[:, 2], elements)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.triplot(triangulation, 'k-', lw=0.5, alpha=0.5)\n",
    "        plt.scatter(node_x, node_y, color='red', label=f'Selected Node {node_id}')\n",
    "        plt.gca().add_artist(plt.Circle((node_x, node_y), radius=0.1, color='red', fill=False))\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.title(f'Mesh with Highlighted Node {node_id}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.axis('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot displacement vs. time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_fom, displacement_fom[:, idx], label='FOM Solution', color='blue')\n",
    "        plt.plot(time_rom, displacement_rom[:, idx], label='ROM Constructed', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Displacement (m)')\n",
    "        plt.title(f'Displacement vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot velocity vs. time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_fom, velocity_fom[:, idx], label='FOM Solution', color='blue')\n",
    "        plt.plot(time_rom, velocity_rom[:, idx], label='ROM Constructed', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Velocity (m/s)')\n",
    "        plt.title(f'Velocity vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot acceleration vs. time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_fom, acceleration_fom[:, idx], label='FOM Solution', color='blue')\n",
    "        plt.plot(time_rom, acceleration_rom[:, idx], label='ROM Constructed', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Acceleration (m/s²)')\n",
    "        plt.title(f'Acceleration vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "node_ids_to_analyze = [1, 154, 305]  # Replace with desired node IDs\n",
    "# Print the path of the folder being accessed\n",
    "cwd = Path.cwd()\n",
    "folder_path = cwd / \"Dynamic_solution\" / \"case_9_magnitude_(391.22, -286.75, 386.86)\" / \"FOM_Solution\" / \"solution\"\n",
    "rom_folder_path = cwd / \"Dynamic_solution\" / \"case_9_magnitude_(391.22, -286.75, 386.86)\" / \"ROM_constructed\"\n",
    "print(f\"Accessing FOM folder: {folder_path.resolve()}\")\n",
    "print(f\"Accessing ROM folder: {rom_folder_path.resolve()}\")\n",
    "\n",
    "# List and print all files in the FOM folder\n",
    "if folder_path.exists() and folder_path.is_dir():\n",
    "    files = list(folder_path.iterdir())\n",
    "    print(\"Files present in the FOM folder:\")\n",
    "    for file in files:\n",
    "        print(file.name)\n",
    "else:\n",
    "    print(f\"The FOM folder does not exist or is not a directory: {folder_path.resolve()}\")\n",
    "\n",
    "# List and print all files in the ROM folder\n",
    "if rom_folder_path.exists() and rom_folder_path.is_dir():\n",
    "    rom_files = list(rom_folder_path.iterdir())\n",
    "    print(\"Files present in the ROM folder:\")\n",
    "    for file in rom_files:\n",
    "        print(file.name)\n",
    "else:\n",
    "    print(f\"The ROM folder does not exist or is not a directory: {rom_folder_path.resolve()}\")\n",
    "\n",
    "# Call the function\n",
    "# plot_node_comparison(mdpa_file, node_ids_to_analyze, folder_path, Path(\"ROM_constructed\"))\n",
    "plot_node_comparison(mdpa_file, node_ids_to_analyze, folder_path, rom_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def create_displacement_gif(folder_path, mdpa_file, scale_factor=1e6, step_interval=100):\n",
    "    \"\"\"\n",
    "    Create a displacement GIF for a specific case.\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    output_file = folder_path / 'displacement_animation.gif'\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"🎯 Processing folder: {folder_path.resolve()}\")\n",
    "\n",
    "    # Load solution data\n",
    "    time_file = folder_path / 'time.npy'\n",
    "    displacement_file = folder_path / 'displacement.npy'\n",
    "    print(f\"📥 Reading displacement data from:\")\n",
    "    print(f\"   ⏱️  Time data       : {time_file.resolve()}\")\n",
    "    print(f\"   📌 Displacement data: {displacement_file.resolve()}\")\n",
    "\n",
    "    time = np.load(time_file)\n",
    "    displacement = np.load(displacement_file)\n",
    "\n",
    "    # Read node coordinates and elements from the .mdpa file\n",
    "    print(f\"📄 Reading mesh connectivity from: {mdpa_file.resolve()}\")\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    x, y = float(parts[1]), float(parts[2])\n",
    "                    node_coords.append([x, y])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "                    elements.append([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 15))\n",
    "\n",
    "    # Base triangulation\n",
    "    x = node_coords[:, 0]\n",
    "    y = node_coords[:, 1]\n",
    "    triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "\n",
    "    # Global displacement limits\n",
    "    disp_magnitudes = []\n",
    "    for step in range(len(time)):\n",
    "        disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "        disp_magnitudes.append(disp_mag)\n",
    "\n",
    "    global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "    global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "    print(f\"📊 Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "        disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "        deformed_coords = node_coords + disp\n",
    "\n",
    "        # Undeformed\n",
    "        ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "\n",
    "        # Deformed mesh\n",
    "        triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "        tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                           vmin=global_min, vmax=global_max)\n",
    "        ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "        ax.grid(True)\n",
    "        ax.axis('equal')\n",
    "        ax.legend()\n",
    "\n",
    "        if frame == 0:\n",
    "            plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    print(\"🛠️  Creating animation frames...\")\n",
    "    anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "\n",
    "    # Save animation\n",
    "    print(f\"💾 Saving animation to: {output_file.resolve()}\")\n",
    "    writer = PillowWriter(fps=1000 / step_interval)\n",
    "    anim.save(output_file, writer=writer)\n",
    "    plt.close()\n",
    "    print(\"✅ Animation complete!\\n\")\n",
    "\n",
    "# Run for all results\n",
    "for case in results:\n",
    "    folder_path = f\"Dynamic_solution/case_{case['case']}_magnitude_({', '.join(map(str, case['magnitude']))})/ROM_constructed\"\n",
    "    mdpa_file = next(Path(os.getcwd()).glob(\"*.mdpa\"))\n",
    "    create_displacement_gif(folder_path, mdpa_file, scale_factor=1e6)\n",
    "    print(f\"✅ GIF created for case {case['case']}!\\n\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
