{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This script simulates a simple harmonic oscillator with a constrained mass and spring system.\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define the values\n",
    "# M_constrained = np.array([[1000]])  # Mass (kg)\n",
    "# K_constrained = np.array([[1e11]])  # Spring constant (N/m)\n",
    "# f_constrained = np.array([[9810]])  # Force (N)\n",
    "\n",
    "\n",
    "# dt = 3.14e-6               # Time step = T/200\n",
    "# total_time = 0.01          # Total simulation time\n",
    "\n",
    "# # Calculate number of steps\n",
    "# n_steps = int(total_time / dt)+1\n",
    "\n",
    "# magnitudes = ((1.0, 2.0, 3.0),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To perform test on the 2x2 system with constrained DOF (Spring-Mass system)\n",
    "# # This code is a simplified version of the original code provided in the prompt.\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define the values for a 2x2 system\n",
    "# M_constrained = np.array([[1000, 0], [0, 1000]])  # Mass matrix (kg)\n",
    "# K_constrained = np.array([[1e11, 0], [0, 1e11]])  # Stiffness matrix (N/m)\n",
    "# f_constrained = np.array([[9810], [9810]])       # Force vector (N)\n",
    "\n",
    "# # Time step and total simulation time\n",
    "# dt = 3.14e-6               # Time step = T/200\n",
    "# total_time = 0.01          # Total simulation time\n",
    "\n",
    "# magnitudes = ((1.0, 2.0, 3.0),)\n",
    "\n",
    "# n_dof = M_constrained.shape[0]  # Number of degrees of freedom\n",
    "# x0 = np.zeros((n_dof)) # Displacement (m) as a 1x1 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def process_displacement_vector(displacement_matrix):\n",
    "    \"\"\"Process displacement matrix for 2D analysis (remove z-component).\"\"\"\n",
    "    flattened = displacement_matrix.flatten()\n",
    "    displacement_2d = flattened[np.where(np.arange(len(flattened)) % 3 != 2)]\n",
    "    return displacement_2d\n",
    "\n",
    "def analyze_matrix(matrix, name, magnitude):\n",
    "    \"\"\"Analyze a matrix and return results in a tabular format.\"\"\"\n",
    "    nonzeros = np.count_nonzero(matrix)\n",
    "    density = nonzeros / matrix.size\n",
    "    is_symmetric = np.allclose(matrix, matrix.T, rtol=1e-8, atol=1e-8)\n",
    "    max_asymmetry = np.max(np.abs(matrix - matrix.T)) if is_symmetric else 0.0\n",
    "\n",
    "    # Eigenvalue analysis\n",
    "    try:\n",
    "        eigvals = np.linalg.eigvals(matrix)\n",
    "        min_eigval = np.min(np.real(eigvals))\n",
    "        max_eigval = np.max(np.real(eigvals))\n",
    "        is_spd_eigen = True if min_eigval > 0 else False\n",
    "    except np.linalg.LinAlgError:\n",
    "        min_eigval = max_eigval = np.nan\n",
    "        is_spd_eigen = False\n",
    "\n",
    "    # Cholesky decomposition for SPD check\n",
    "    try:\n",
    "        np.linalg.cholesky(matrix)\n",
    "        is_spd_cholesky = True\n",
    "    except np.linalg.LinAlgError:\n",
    "        is_spd_cholesky = False\n",
    "\n",
    "    # Prepare table row\n",
    "    return [\n",
    "        magnitude,\n",
    "        matrix.shape,\n",
    "        matrix.dtype,\n",
    "        f\"{matrix.nbytes / 1024:.2f} KB\",\n",
    "        nonzeros,\n",
    "        f\"{density:.2%}\",\n",
    "        matrix.size - nonzeros,\n",
    "        is_symmetric,\n",
    "        f\"{max_asymmetry:.2e}\",\n",
    "        f\"{np.min(matrix):.2e}\",\n",
    "        f\"{np.max(matrix):.2e}\",\n",
    "        f\"{np.mean(matrix):.2e}\",\n",
    "        f\"{np.std(matrix):.2e}\",\n",
    "        f\"{min_eigval:.2e}\",\n",
    "        f\"{max_eigval:.2e}\",\n",
    "        is_spd_eigen,\n",
    "        is_spd_cholesky,\n",
    "    ]\n",
    "\n",
    "def analyze_vector(vector, name, magnitude):\n",
    "    \"\"\"Analyze a vector and return results in a tabular format.\"\"\"\n",
    "    nonzeros = np.count_nonzero(vector)\n",
    "    density = nonzeros / vector.size\n",
    "    return [\n",
    "        magnitude,\n",
    "        vector.shape,\n",
    "        vector.dtype,\n",
    "        f\"{vector.nbytes / 1024:.2f} KB\",\n",
    "        nonzeros,\n",
    "        f\"{density:.2%}\",\n",
    "        vector.size - nonzeros,\n",
    "        \"-\", \"-\",  # Symmetry checks (N/A for vectors)\n",
    "        f\"{np.min(vector):.2e}\",\n",
    "        f\"{np.max(vector):.2e}\",\n",
    "        f\"{np.mean(vector):.2e}\",\n",
    "        f\"{np.std(vector):.2e}\",\n",
    "        \"-\", \"-\",  # Eigenvalue analysis (N/A for vectors)\n",
    "        \"-\", \"-\",  # Symmetry checks (N/A for vectors)\n",
    "    ]\n",
    "\n",
    "def extract_magnitude(filename):\n",
    "    \"\"\"Extract the magnitude from the filename.\"\"\"\n",
    "    start = filename.find('[')\n",
    "    end = filename.find(']')\n",
    "    if start == -1 or end == -1:\n",
    "        return None\n",
    "    magnitude_str = filename[start + 1:end]\n",
    "    return tuple(map(float, magnitude_str.split(',')))\n",
    "\n",
    "def load_and_analyze_components(folder, component_name, analysis_function):\n",
    "    \"\"\"Load and analyze components (matrices or vectors) from a folder.\"\"\"\n",
    "    files = sorted(glob.glob(os.path.join(folder, \"*.npy\")))\n",
    "    table_data = []\n",
    "    magnitudes = []\n",
    "\n",
    "    if not files:\n",
    "        print(f\"No files found in {component_name} folder.\")\n",
    "        return None, None\n",
    "\n",
    "    for file in files:\n",
    "        component = np.load(file)\n",
    "        magnitude = extract_magnitude(os.path.basename(file))\n",
    "        magnitudes.append(magnitude)\n",
    "        table_data.append(analysis_function(component, component_name, magnitude))\n",
    "\n",
    "    headers = [\n",
    "        \"Magnitude\", \"Shape\", \"Data Type\", \"Memory Size\", \"Non-Zero Elements\", \"Density\",\n",
    "        \"Zero Elements\", \"Symmetry Check\", \"Max Asymmetry\", \"Min Value\", \"Max Value\",\n",
    "        \"Mean Value\", \"Std Dev\", \"Min Eig Value\", \"Max Eig Value\", \"SPD (Eigen)\", \"Symmetric PD\"\n",
    "    ]\n",
    "    print(f\"\\nDetailed Analysis of {component_name}:\")\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "    return files, magnitudes\n",
    "\n",
    "def load_and_analyze_displacement_vectors(folder):\n",
    "    \"\"\"Load and analyze displacement vectors, including processed data.\"\"\"\n",
    "    files = sorted(glob.glob(os.path.join(folder, \"*.npy\")))\n",
    "    original_table_data = []\n",
    "    processed_table_data = []\n",
    "    magnitudes = []\n",
    "\n",
    "    if not files:\n",
    "        print(\"No files found in Displacement Vector folder.\")\n",
    "        return None, None\n",
    "\n",
    "    for file in files:\n",
    "        original_vector = np.load(file)\n",
    "        processed_vector = process_displacement_vector(original_vector)\n",
    "        magnitude = extract_magnitude(os.path.basename(file))\n",
    "        magnitudes.append(magnitude)\n",
    "\n",
    "        # Analyze both original and processed vectors\n",
    "        original_table_data.append(analyze_vector(original_vector, \"Original Displacement Vector\", magnitude))\n",
    "        processed_table_data.append(analyze_vector(processed_vector, \"Processed Displacement Vector\", magnitude))\n",
    "\n",
    "    headers = [\n",
    "        \"Magnitude\", \"Shape\", \"Data Type\", \"Memory Size\", \"Non-Zero Elements\", \"Density\",\n",
    "        \"Zero Elements\", \"Symmetry Check\", \"Max Asymmetry\", \"Min Value\", \"Max Value\",\n",
    "        \"Mean Value\", \"Std Dev\", \"Min Eig Value\", \"Max Eig Value\", \"SPD (Eigen)\", \"Symmetric PD\"\n",
    "    ]\n",
    "\n",
    "    # Print tables\n",
    "    print(\"\\nDetailed Analysis of Original Displacement Vectors:\")\n",
    "    print(tabulate(original_table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "    print(\"\\nDetailed Analysis of Processed Displacement Vectors:\")\n",
    "    print(tabulate(processed_table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "    return files, magnitudes\n",
    "\n",
    "def check_missing_files(mass_mags, stiffness_mags, disp_mags, force_mags):\n",
    "    \"\"\"Check for missing magnitudes across components and report.\"\"\"\n",
    "    all_magnitudes = set(mass_mags) & set(stiffness_mags) & set(disp_mags) & set(force_mags)\n",
    "    missing = {\n",
    "        \"Mass Matrix\": set(mass_mags) - all_magnitudes,\n",
    "        \"Stiffness Matrix\": set(stiffness_mags) - all_magnitudes,\n",
    "        \"Displacement Vector\": set(disp_mags) - all_magnitudes,\n",
    "        \"Force Vector\": set(force_mags) - all_magnitudes,\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== Missing Files Report ===\")\n",
    "    for component, missing_mags in missing.items():\n",
    "        if missing_mags:\n",
    "            print(f\" - Missing in {component}: {missing_mags}\")\n",
    "        else:\n",
    "            print(f\" - All magnitudes present in {component}.\")\n",
    "\n",
    "def final_compatibility_check(M, K, x, f):\n",
    "    \"\"\"Perform final compatibility check for dimensions.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"FINAL COMPATIBILITY CHECK\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    print(f\"Mass matrix shape: {M.shape}\")\n",
    "    print(f\"Stiffness matrix shape: {K.shape}\")\n",
    "    print(f\"2D Displacement vector shape: {x[0].shape}\")\n",
    "    print(f\"Force vector shape: {f[0].shape}\")\n",
    "\n",
    "    incompatible = []\n",
    "    if M.shape != K.shape:\n",
    "        incompatible.append(\"Mass and Stiffness matrices have different dimensions.\")\n",
    "    if M.shape[1] != x[0].shape[0]:\n",
    "        incompatible.append(\"Matrix and displacement vector dimensions don't match.\")\n",
    "    if M.shape[1] != f[0].shape[0]:\n",
    "        incompatible.append(\"Matrix and force vector dimensions don't match.\")\n",
    "\n",
    "    if incompatible:\n",
    "        print(\"\\nWARNING: Found incompatibilities:\")\n",
    "        for issue in incompatible:\n",
    "            print(f\" - {issue}\")\n",
    "    else:\n",
    "        print(\"\\nAll components have compatible dimensions!\")\n",
    "        print(\"\\nAvailable components:\")\n",
    "        print(f\"M: Shape {M.shape}\")\n",
    "        print(f\"K: Shape {K.shape}\")\n",
    "        print(f\"x_original: {len(x)} vectors\")\n",
    "        print(f\"x: {x[0].shape} (Processed)\")\n",
    "        print(f\"f: {len(f)} vectors\")\n",
    "        print(\"is_compatible: True\")\n",
    "        print(\"loaded_successfully: True\")\n",
    "        print(\"compatibility_checked: True\")\n",
    "\n",
    "def load_structural_matrices():\n",
    "    \"\"\"Load and analyze all structural matrices and vectors.\"\"\"\n",
    "    current_path = os.getcwd()\n",
    "    kratos_results_path = os.path.join(current_path, \"Kratos_Results\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"LOADING MASS MATRIX\")\n",
    "    print(\"=\" * 50)\n",
    "    mass_folder = os.path.join(kratos_results_path, \"mass_results\")\n",
    "    M_files, mass_magnitudes = load_and_analyze_components(mass_folder, \"Mass Matrix\", analyze_matrix)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"LOADING STIFFNESS MATRIX\")\n",
    "    print(\"=\" * 50)\n",
    "    stiffness_folder = os.path.join(kratos_results_path, \"stiffness_results\")\n",
    "    K_files, stiffness_magnitudes = load_and_analyze_components(stiffness_folder, \"Stiffness Matrix\", analyze_matrix)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"LOADING DISPLACEMENT VECTOR\")\n",
    "    print(\"=\" * 50)\n",
    "    displacement_folder = os.path.join(kratos_results_path, \"displacement_results\")\n",
    "    x_files, disp_magnitudes = load_and_analyze_displacement_vectors(displacement_folder)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"LOADING FORCE VECTOR\")\n",
    "    print(\"=\" * 50)\n",
    "    force_folder = os.path.join(kratos_results_path, \"loading_results\")\n",
    "    f_files, force_magnitudes = load_and_analyze_components(force_folder, \"Force Vector\", analyze_vector)\n",
    "\n",
    "    # Check if all magnitudes are identical\n",
    "    if (\n",
    "        mass_magnitudes == stiffness_magnitudes == disp_magnitudes == force_magnitudes\n",
    "    ):\n",
    "        magnitudes = mass_magnitudes  # Use any of the lists as they are identical\n",
    "        print(\"\\nAll magnitudes are identical and saved under 'magnitudes'.\")\n",
    "    else:\n",
    "        print(\"\\nWarning: Magnitudes are not identical across components.\")\n",
    "        print(f\"Mass Magnitudes: {mass_magnitudes}\")\n",
    "        print(f\"Stiffness Magnitudes: {stiffness_magnitudes}\")\n",
    "        print(f\"Displacement Magnitudes: {disp_magnitudes}\")\n",
    "        print(f\"Force Magnitudes: {force_magnitudes}\")\n",
    "        magnitudes = None\n",
    "\n",
    "    # Perform compatibility check if all components are loaded\n",
    "    if M_files and K_files and x_files and f_files:\n",
    "        # Load matrices\n",
    "        M = np.load(M_files[0])\n",
    "        K = np.load(K_files[0])\n",
    "\n",
    "        # Load displacement and force vectors as 2D arrays (612 rows, columns = number of files)\n",
    "        x_original = np.column_stack([np.load(file) for file in x_files])\n",
    "        x = np.column_stack([process_displacement_vector(np.load(file)) for file in x_files])\n",
    "        f = np.column_stack([np.load(file) for file in f_files])\n",
    "\n",
    "        final_compatibility_check(M, K, x, f)\n",
    "        print(\"\\nMatrices successfully loaded and compatibility checked!\")\n",
    "\n",
    "        return M, K, x_original, x, f, magnitudes\n",
    "    else:\n",
    "        print(\"Error: One or more required components are missing.\")\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "\n",
    "def final_compatibility_check(M, K, x, f):\n",
    "    \"\"\"Perform final compatibility check for dimensions.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"FINAL COMPATIBILITY CHECK\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    print(f\"Mass matrix shape: {M.shape}\")\n",
    "    print(f\"Stiffness matrix shape: {K.shape}\")\n",
    "    print(f\"2D Displacement vector shape: {x.shape}\")\n",
    "    print(f\"Force vector shape: {f.shape}\")\n",
    "\n",
    "    incompatible = []\n",
    "\n",
    "    # Ensure matrix row sizes match vector row sizes\n",
    "    if M.shape[0] != x.shape[0]:\n",
    "        incompatible.append(\"Mass matrix row count and displacement vector row count don't match.\")\n",
    "    if M.shape[0] != f.shape[0]:\n",
    "        incompatible.append(\"Mass matrix row count and force vector row count don't match.\")\n",
    "    if K.shape != M.shape:\n",
    "        incompatible.append(\"Mass matrix and stiffness matrix dimensions don't match.\")\n",
    "\n",
    "    # Display compatibility results\n",
    "    if incompatible:\n",
    "        print(\"\\nWARNING: Found incompatibilities:\")\n",
    "        for issue in incompatible:\n",
    "            print(f\" - {issue}\")\n",
    "    else:\n",
    "        print(\"\\nAll components have compatible dimensions!\")\n",
    "\n",
    "    # Summary of components\n",
    "    print(\"\\nAvailable components:\")\n",
    "    print(f\"M: Shape {M.shape}\")\n",
    "    print(f\"K: Shape {K.shape}\")\n",
    "    print(f\"x_original: Shape {x.shape}\")\n",
    "    print(f\"x: Shape {x.shape} (Processed)\")\n",
    "    print(f\"f: Shape {f.shape}\")\n",
    "    print(\"is_compatible:\", not incompatible)\n",
    "    print(\"loaded_successfully: True\")\n",
    "    print(\"compatibility_checked: True\")\n",
    "\n",
    "\n",
    "# Run the function\n",
    "M, K, x_original, x, f, magnitudes = load_structural_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if matrices are already loaded\n",
    "if 'M' in globals() and 'K' in globals() and 'x' in globals() and 'f' in globals():\n",
    "    print(\"Matrices are already loaded and ready for boundary condition application.\")\n",
    "else:\n",
    "    print(\"Error: Matrices are not loaded. Please run `load_structural_matrices()` first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_boundary_conditions_multiple_components_with_nodes(M, K, f, magnitudes):\n",
    "    \"\"\"\n",
    "    Apply boundary conditions to the Mass matrix, Stiffness matrix, and Force vectors\n",
    "    for multiple cases. Provides a tabulated summary of the constrained DOFs and Nodes for each file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Locate .mdpa file\n",
    "        base_path = Path.cwd()\n",
    "        mdpa_file = next(base_path.glob('*.mdpa'), None)\n",
    "        if not mdpa_file:\n",
    "            raise FileNotFoundError(\"No .mdpa file found in the current directory.\")\n",
    "        print(f\"Using .mdpa file: {mdpa_file.name}\")\n",
    "\n",
    "        # Parse .mdpa file to identify fixed nodes\n",
    "        nodes = {}\n",
    "        fixed_nodes = set()\n",
    "        with open(mdpa_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        reading_nodes = False\n",
    "        reading_fixed = False\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif \"Begin SubModelPart DISPLACEMENT_fixed\" in line or \"Begin SubModelPart DISPLACEMENT_Fixed\" in line:\n",
    "                reading_fixed = True\n",
    "                continue\n",
    "            elif \"End SubModelPart\" in line:\n",
    "                reading_fixed = False\n",
    "                continue\n",
    "\n",
    "            if reading_nodes:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    node_id = int(parts[0])\n",
    "                    x_coord, y_coord, z_coord = map(float, parts[1:4])\n",
    "                    nodes[node_id] = (x_coord, y_coord, z_coord)\n",
    "\n",
    "            if reading_fixed:\n",
    "                try:\n",
    "                    node_id = int(line)\n",
    "                    print(f\"Found fixed node: {node_id}\")\n",
    "                    fixed_nodes.add(node_id)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        # Apply penalty method for boundary conditions\n",
    "        penalty_factor = 1e12\n",
    "        max_stiffness = np.max(np.abs(K))\n",
    "        penalty = penalty_factor * max_stiffness\n",
    "\n",
    "        print(\"\\nApplying boundary conditions to Mass, Stiffness, and Force for multiple cases...\")\n",
    "        summary_data = []\n",
    "        headers = [\"File Index\", \"Magnitude\", \"Node Numbers\", \"Constrained DOFs (Applied Nodes)\"]\n",
    "\n",
    "        # Initialize constrained matrices\n",
    "        M_constrained = np.copy(M)\n",
    "        K_constrained = np.copy(K)\n",
    "        f_constrained = np.copy(f)\n",
    "\n",
    "        for file_index in range(f.shape[1]):  # Loop through each case\n",
    "            applied_dofs = []\n",
    "            applied_nodes = []\n",
    "            for node_id in fixed_nodes:\n",
    "                x_dof = (node_id - 1) * 2\n",
    "                y_dof = x_dof + 1\n",
    "\n",
    "                # Apply penalties to M, K, and f for this file\n",
    "                M_constrained[x_dof, x_dof] = penalty\n",
    "                M_constrained[y_dof, y_dof] = penalty\n",
    "                K_constrained[x_dof, x_dof] = penalty\n",
    "                K_constrained[y_dof, y_dof] = penalty\n",
    "                f_constrained[x_dof, file_index] = 0.0\n",
    "                f_constrained[y_dof, file_index] = 0.0\n",
    "\n",
    "                applied_dofs.append(f\"{x_dof} (X), {y_dof} (Y)\")\n",
    "                applied_nodes.append(node_id)\n",
    "\n",
    "            # Append to summary table\n",
    "            summary_data.append(\n",
    "                [file_index + 1, magnitudes[file_index], \", \".join(map(str, applied_nodes)), \", \".join(applied_dofs)]\n",
    "            )\n",
    "\n",
    "        # Print summary table\n",
    "        print(\"\\nBoundary Condition Application Summary for Mass, Stiffness, and Force:\")\n",
    "        print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "        print(\"\\nBoundary conditions applied successfully!\")\n",
    "        print(f\"Number of constrained DOFs: {len(fixed_nodes) * 2}\")\n",
    "\n",
    "        return M_constrained, K_constrained, f_constrained, fixed_nodes\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying boundary conditions: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "\n",
    "# Main Execution\n",
    "try:\n",
    "    # Ensure matrices and vectors are loaded\n",
    "    if 'M' in globals() and 'K' in globals() and 'f' in globals() and 'magnitudes' in globals():\n",
    "        print(\"Matrices are already loaded and ready for boundary condition application.\")\n",
    "    else:\n",
    "        print(\"Error: Matrices are not loaded. Please load them using the proper function.\")\n",
    "\n",
    "    # Apply boundary conditions\n",
    "    print(\"\\nApplying boundary conditions for Mass, Stiffness, and Force across multiple cases...\")\n",
    "    M_constrained, K_constrained, f_constrained, fixed_nodes = apply_boundary_conditions_multiple_components_with_nodes(M, K, f, magnitudes)\n",
    "\n",
    "    if M_constrained is not None:\n",
    "        print(\"\\nVerification of constrained system:\")\n",
    "        print(f\"Original Mass Matrix Shape: {M.shape}\")\n",
    "        print(f\"Constrained Mass Matrix Shape: {M_constrained.shape}\")\n",
    "        print(f\"Original Stiffness Matrix Shape: {K.shape}\")\n",
    "        print(f\"Constrained Stiffness Matrix Shape: {K_constrained.shape}\")\n",
    "        print(f\"Original Force Vector Shape: {f.shape}\")\n",
    "        print(f\"Constrained Force Vector Shape: {f_constrained.shape}\")\n",
    "        print(f\"Number of constrained DOFs: {len(fixed_nodes) * 2}\")\n",
    "    else:\n",
    "        print(\"Boundary conditions could not be applied.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during boundary condition application: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_force_vectors_multiple(f_list, f_constrained_list, magnitudes):\n",
    "    \"\"\"\n",
    "    Compare multiple sets of original and constrained force vectors.\n",
    "    Display differences in a tabular format with magnitude headings.\n",
    "    \"\"\"\n",
    "    # Ensure inputs are NumPy arrays and have correct dimensions\n",
    "    if not isinstance(f_list, np.ndarray) or not isinstance(f_constrained_list, np.ndarray):\n",
    "        raise ValueError(\"f_list and f_constrained_list must be NumPy arrays.\")\n",
    "\n",
    "    # Check the shapes of the input arrays\n",
    "    if f_list.shape != f_constrained_list.shape:\n",
    "        raise ValueError(\"f_list and f_constrained_list must have the same shape.\")\n",
    "    if f_list.shape[1] != len(magnitudes):\n",
    "        raise ValueError(\"The number of magnitudes does not match the number of force vector files.\")\n",
    "\n",
    "    # Prepare summary table\n",
    "    summary_data = []\n",
    "    headers = [\"File Index\", \"Magnitude\", \"Total DOFs\", \"Non-Zero DOFs (Original)\", \"Non-Zero DOFs (Constrained)\", \"Differences Found\"]\n",
    "\n",
    "    # Iterate over each file (column)\n",
    "    for i, magnitude in enumerate(magnitudes):\n",
    "        f = f_list[:, i]\n",
    "        f_constrained = f_constrained_list[:, i]\n",
    "\n",
    "        # Check if the force vectors are identical within a tolerance\n",
    "        are_equal = np.allclose(f, f_constrained, rtol=1e-10)\n",
    "\n",
    "        # Compute differences\n",
    "        diff = np.abs(f - f_constrained)\n",
    "        different_dofs = np.where(diff > 1e-10)[0]  # Identify DOFs with significant differences\n",
    "        num_diff_dofs = len(different_dofs)\n",
    "\n",
    "        # Count non-zero elements\n",
    "        non_zero_original = np.count_nonzero(f)\n",
    "        non_zero_constrained = np.count_nonzero(f_constrained)\n",
    "\n",
    "        # Append results to the summary table\n",
    "        summary_data.append([\n",
    "            i + 1,\n",
    "            magnitude,\n",
    "            f.shape[0],\n",
    "            non_zero_original,\n",
    "            non_zero_constrained,\n",
    "            num_diff_dofs,\n",
    "        ])\n",
    "\n",
    "    # Print summary table\n",
    "    print(\"\\nForce Vector Comparison Summary:\")\n",
    "    print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "    # Detailed differences for each file\n",
    "    for i, magnitude in enumerate(magnitudes):\n",
    "        f = f_list[:, i]\n",
    "        f_constrained = f_constrained_list[:, i]\n",
    "\n",
    "        # Compute differences\n",
    "        diff = np.abs(f - f_constrained)\n",
    "        different_dofs = np.where(diff > 1e-10)[0]  # Identify DOFs with significant differences\n",
    "\n",
    "        if len(different_dofs) > 0:\n",
    "            print(f\"\\nDetailed Differences for File {i + 1} (Magnitude: {magnitude}):\")\n",
    "            headers = [\"DOF\", \"Node\", \"Original Value\", \"Constrained Value\", \"Difference\"]\n",
    "            table_data = []\n",
    "\n",
    "            for dof in different_dofs:\n",
    "                # Determine the corresponding node and DOF (assuming 2 DOFs per node)\n",
    "                node = dof // 2 + 1\n",
    "                dof_label = \"X\" if dof % 2 == 0 else \"Y\"\n",
    "                table_data.append([dof_label, node, f[dof], f_constrained[dof], diff[dof]])\n",
    "\n",
    "            print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "        else:\n",
    "            print(f\"\\nNo significant differences found for File {i + 1} (Magnitude: {magnitude}).\")\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    print(\"\\nComparing force vectors for multiple files...\")\n",
    "    # Assuming `f` is a NumPy array of shape (DOFs, Files)\n",
    "    # `f_constrained` is a NumPy array of shape (DOFs, Files)\n",
    "    # `magnitudes` is a list of magnitudes corresponding to the force vector files\n",
    "    compare_force_vectors_multiple(f, f_constrained, magnitudes)\n",
    "except Exception as e:\n",
    "    print(f\"Error during force vector comparison: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bc_applied_to_force(f_constrained, magnitudes, threshold=1e-7):\n",
    "    \"\"\"\n",
    "    Check whether boundary conditions (BC) have been applied to the constrained force vectors.\n",
    "    Display results in a tabular format with magnitude headings.\n",
    "    \"\"\"\n",
    "    # Convert 2D `f_constrained` to a list of vectors if necessary\n",
    "    if isinstance(f_constrained, np.ndarray) and len(f_constrained.shape) == 2:\n",
    "        print(\"Converting 2D array `f_constrained` to a list of vectors.\")\n",
    "        f_constrained = [f_constrained[:, i] for i in range(f_constrained.shape[1])]\n",
    "\n",
    "    # Ensure lengths match\n",
    "    if len(f_constrained) != len(magnitudes):\n",
    "        print(f\"Error: The number of constrained force vectors ({len(f_constrained)}) \"\n",
    "              f\"does not match the number of magnitudes ({len(magnitudes)}).\")\n",
    "        return\n",
    "\n",
    "    # Prepare table headers\n",
    "    headers = [\"File Index\", \"Magnitude\", \"DOF\", \"Node\", \"Direction\", \"Value\"]\n",
    "    summary_data = []\n",
    "\n",
    "    for file_idx, (f_cons, magnitude) in enumerate(zip(f_constrained, magnitudes)):\n",
    "        # Find non-zero DOFs\n",
    "        non_zero_indices = np.where(abs(f_cons) > threshold)[0]\n",
    "        if len(non_zero_indices) == 0:\n",
    "            print(f\"All DOFs are zero for Magnitude {magnitude}.\")\n",
    "            continue\n",
    "\n",
    "        # Collect data for the table\n",
    "        for dof in non_zero_indices:\n",
    "            node = dof // 2 + 1  # Calculate node ID\n",
    "            direction = \"X\" if dof % 2 == 0 else \"Y\"\n",
    "            value = f_cons[dof]\n",
    "            summary_data.append([file_idx + 1, magnitude, dof, node, direction, value])\n",
    "\n",
    "    # Print the table\n",
    "    if summary_data:\n",
    "        print(\"\\nBoundary Conditions Applied - Detailed Report:\")\n",
    "        print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "    else:\n",
    "        print(\"No non-zero entries found in the constrained force vectors.\")\n",
    "\n",
    "# Example Usage\n",
    "try:\n",
    "    print(\"\\nChecking if boundary conditions are applied to constrained force vectors...\")\n",
    "    # Pass `f_constrained` and `magnitudes` to the function\n",
    "    check_bc_applied_to_force(f_constrained, magnitudes)\n",
    "except Exception as e:\n",
    "    print(f\"Error during boundary condition check: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bc_applied_to_force(f_constrained, magnitudes, threshold=1e-7):\n",
    "    \"\"\"\n",
    "    Check whether boundary conditions (BC) have been applied to the constrained force vectors.\n",
    "    Display results in a tabular format with magnitude headings.\n",
    "    \"\"\"\n",
    "    # Convert 2D f_constrained to a list of vectors if necessary\n",
    "    if isinstance(f_constrained, np.ndarray) and len(f_constrained.shape) == 2:\n",
    "        print(\"Converting 2D array f_constrained to a list of vectors.\")\n",
    "        f_constrained = [f_constrained[:, i] for i in range(f_constrained.shape[1])]\n",
    "\n",
    "    # Ensure lengths match\n",
    "    if len(f_constrained) != len(magnitudes):\n",
    "        print(f\"Error: The number of constrained force vectors ({len(f_constrained)}) \"\n",
    "              f\"does not match the number of magnitudes ({len(magnitudes)}).\")\n",
    "        return\n",
    "\n",
    "    # Prepare table headers\n",
    "    summary_headers = [\"File Index\", \"Magnitude\", \"Non-Zero DOFs\"]\n",
    "    details_headers = [\"File Index\", \"Magnitude\", \"DOF\", \"Node\", \"Direction\", \"Value\"]\n",
    "\n",
    "    summary_data = []\n",
    "    details_data = []\n",
    "\n",
    "    for file_idx, (f_cons, magnitude) in enumerate(zip(f_constrained, magnitudes)):\n",
    "        # Find non-zero DOFs\n",
    "        non_zero_indices = np.where(abs(f_cons) > threshold)[0]\n",
    "\n",
    "        # Add summary information\n",
    "        summary_data.append([\n",
    "            file_idx + 1,\n",
    "            magnitude,\n",
    "            len(non_zero_indices),\n",
    "        ])\n",
    "\n",
    "        # Add details for non-zero DOFs\n",
    "        for dof in non_zero_indices:\n",
    "            node = dof // 2 + 1  # Calculate node ID\n",
    "            direction = \"X\" if dof % 2 == 0 else \"Y\"\n",
    "            details_data.append([\n",
    "                file_idx + 1,\n",
    "                magnitude,\n",
    "                dof,\n",
    "                node,\n",
    "                direction,\n",
    "                f_cons[dof],\n",
    "            ])\n",
    "\n",
    "    # Print the summary table\n",
    "    print(\"\\nBoundary Conditions Summary:\")\n",
    "    print(tabulate(summary_data, headers=summary_headers, tablefmt=\"grid\"))\n",
    "\n",
    "    # Print the detailed table if there are non-zero DOFs\n",
    "    if details_data:\n",
    "        print(\"\\nNon-Zero DOFs Details:\")\n",
    "        print(tabulate(details_data, headers=details_headers, tablefmt=\"grid\"))\n",
    "    else:\n",
    "        print(\"\\nAll DOFs are zero across all cases.\")\n",
    "\n",
    "# Example Usage\n",
    "try:\n",
    "    print(\"\\nChecking if boundary conditions are applied to constrained force vectors...\")\n",
    "    # Pass f_constrained and magnitudes to the function\n",
    "    check_bc_applied_to_force(f_constrained, magnitudes)\n",
    "except Exception as e:\n",
    "    print(f\"Error during boundary condition check: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_loads_to_force_vector_multiple_cases(f, f_constrained, fixed_dofs, magnitudes, mdpa_file):\n",
    "    \"\"\"\n",
    "    Apply loads to force vectors for multiple cases using a single `.mdpa` file and magnitude values.\n",
    "    Display the results in a well-structured tabular format with the specified format.\n",
    "    \"\"\"\n",
    "    # Extract load nodes from the `.mdpa` file\n",
    "    load_nodes = {'LinePressure2D_Load_1': [], 'LinePressure2D_Load_2': [], 'LinePressure2D_Load_3': []}\n",
    "    current_load = None\n",
    "    reading_nodes = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin SubModelPart LinePressure2D_Load_1\" in line or \"Begin SubModelPart PointLoad2D_Load_1\" in line:\n",
    "                current_load = 'LinePressure2D_Load_1'\n",
    "            elif \"Begin SubModelPart LinePressure2D_Load_2\" in line or \"Begin SubModelPart PointLoad2D_Load_2\" in line:\n",
    "                current_load = 'LinePressure2D_Load_2'\n",
    "            elif \"Begin SubModelPart LinePressure2D_Load_3\" in line or \"Begin SubModelPart PointLoad2D_Load_3\" in line:\n",
    "                current_load = 'LinePressure2D_Load_3'\n",
    "            elif \"End SubModelPart\" in line:\n",
    "                current_load = None\n",
    "                reading_nodes = False\n",
    "            elif current_load and \"Begin SubModelPartNodes\" in line:\n",
    "                reading_nodes = True\n",
    "            elif current_load and \"End SubModelPartNodes\" in line:\n",
    "                reading_nodes = False\n",
    "            elif reading_nodes and current_load and line:\n",
    "                try:\n",
    "                    node = int(line)\n",
    "                    load_nodes[current_load].append(node)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "    # Prepare results for tabular output\n",
    "    headers = [\"File Index\", \"Magnitude\", \"Load 1 (Value, Direction)\", \"Nodes (DOF)\", \n",
    "               \"Load 2 (Value, Direction)\", \"Nodes (DOF)\", \"Load 3 (Value, Direction)\", \"Nodes (DOF)\"]\n",
    "    table_data = []\n",
    "\n",
    "    print(\"\\nApplying loads to constrained force vectors for multiple cases...\")\n",
    "    for i, magnitude in enumerate(magnitudes):\n",
    "        load_1_details = []\n",
    "        load_2_details = []\n",
    "        load_3_details = []\n",
    "\n",
    "        # Apply loads and collect node/DOF information\n",
    "        for load_name, nodes in load_nodes.items():\n",
    "            if load_name == 'LinePressure2D_Load_1':  # Use the first value of magnitude for vertical load\n",
    "                value = magnitude[0]\n",
    "                for node in nodes:\n",
    "                    dof_y = (node - 1) * 2 + 1\n",
    "                    f_constrained[dof_y, i] = value\n",
    "                    load_1_details.append(f\"{node} (Y-DOF {dof_y})\")\n",
    "            elif load_name == 'LinePressure2D_Load_2':  # Use the second value of magnitude for horizontal load\n",
    "                value = magnitude[1]\n",
    "                for node in nodes:\n",
    "                    dof_x = (node - 1) * 2\n",
    "                    f_constrained[dof_x, i] = value\n",
    "                    load_2_details.append(f\"{node} (X-DOF {dof_x})\")\n",
    "            elif load_name == 'LinePressure2D_Load_3':  # Use the third value of magnitude for horizontal load\n",
    "                value = magnitude[2]\n",
    "                for node in nodes:\n",
    "                    dof_x = (node - 1) * 2\n",
    "                    f_constrained[dof_x, i] = value\n",
    "                    load_3_details.append(f\"{node} (X-DOF {dof_x})\")\n",
    "\n",
    "        # Zero out forces at constrained DOFs\n",
    "        for dof in fixed_dofs:\n",
    "            f_constrained[dof, i] = 0.0\n",
    "\n",
    "        # Add to the summary table\n",
    "        table_data.append([\n",
    "            i + 1,\n",
    "            magnitude,\n",
    "            f\"{magnitude[0]} (Y)\",\n",
    "            \", \".join(load_1_details),\n",
    "            f\"{magnitude[1]} (X)\",\n",
    "            \", \".join(load_2_details),\n",
    "            f\"{magnitude[2]} (X)\",\n",
    "            \", \".join(load_3_details)\n",
    "        ])\n",
    "\n",
    "    # Display summary table\n",
    "    print(\"\\nLoad Application Summary:\")\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "    print(\"\\nLoads successfully applied to all cases.\")\n",
    "    return f_constrained\n",
    "\n",
    "# Example Usage\n",
    "try:\n",
    "    print(\"\\nApplying loads to constrained force vectors for multiple cases...\")\n",
    "    # Dynamic file reading\n",
    "    folder_path = Path.cwd()\n",
    "    mdpa_file = next(folder_path.glob(\"*.mdpa\"), None)\n",
    "\n",
    "    if mdpa_file:\n",
    "        print(f\"Using MDPA file: {mdpa_file.name}\")\n",
    "\n",
    "        # Assuming `f`, `f_constrained`, `fixed_nodes`, and `magnitudes` are already defined\n",
    "        f_constrained = apply_loads_to_force_vector_multiple_cases(\n",
    "            f=f,\n",
    "            f_constrained=f_constrained,\n",
    "            fixed_dofs=list(fixed_nodes),\n",
    "            magnitudes=magnitudes,  # Magnitudes is a list of tuples (e.g., [(-213.96, -286.3, 284.39), ...])\n",
    "            mdpa_file=mdpa_file\n",
    "        )\n",
    "    else:\n",
    "        print(\"Error: MDPA file not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy import linalg\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define system matrices\n",
    "# M = np.array([[2.0, 0.0], [0.0, 1.0]])  # Mass matrix\n",
    "# K = np.array([[10.0, -2.0], [-2.0, 5.0]])  # Stiffness matrix\n",
    "\n",
    "# # Define force vector for each time step (zero force in this case)\n",
    "# total_time = 100.0\n",
    "# dt = 0.02\n",
    "# n_steps = int(total_time / dt) + 1\n",
    "# F = np.zeros((n_steps, 2))  # Two DOFs, force applied is zero\n",
    "\n",
    "# # Initial conditions\n",
    "# initial_displacement = np.array([1.0, 0.5])\n",
    "\n",
    "# # Define structural components dictionary\n",
    "# structural_components = {\n",
    "#     'M_constrained': M,\n",
    "#     'K_constrained': K,\n",
    "#     'f_constrained': F\n",
    "# }\n",
    "\n",
    "# # Newmark parameters\n",
    "# beta = 0.25\n",
    "# gamma = 0.5\n",
    "# tol = 1e-6\n",
    "# max_iter = 100\n",
    "\n",
    "# # Run the solver\n",
    "# results = solve_newmark_dynamic_single_case(structural_components, initial_displacement, total_time, dt,\n",
    "#                                             beta, gamma, tol, max_iter)\n",
    "\n",
    "# # Plotting results\n",
    "# time = results['time']\n",
    "# displacement = results['displacement']\n",
    "# velocity = results['velocity']\n",
    "# acceleration = results['acceleration']\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# # Plot Displacement for each DOF\n",
    "# plt.subplot(3, 1, 1)\n",
    "# plt.plot(time, displacement[:, 0], label='DOF 1')\n",
    "# plt.plot(time, displacement[:, 1], label='DOF 2')\n",
    "# plt.title('Displacement')\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot Velocity for each DOF\n",
    "# plt.subplot(3, 1, 2)\n",
    "# plt.plot(time, velocity[:, 0], label='DOF 1')\n",
    "# plt.plot(time, velocity[:, 1], label='DOF 2')\n",
    "# plt.title('Velocity')\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot Acceleration for each DOF\n",
    "# plt.subplot(3, 1, 3)\n",
    "# plt.plot(time, acceleration[:, 0], label='DOF 1')\n",
    "# plt.plot(time, acceleration[:, 1], label='DOF 2')\n",
    "# plt.title('Acceleration')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy import linalg\n",
    "# import os\n",
    "# import shutil\n",
    "# from pathlib import Path\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# from tabulate import tabulate\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import linalg\n",
    "\n",
    "# def solve_newmark_dynamic_single_case(structural_components, initial_displacement, total_time, dt, \n",
    "#                                      beta, gamma, tol, max_iter):\n",
    "#     \"\"\"\n",
    "#     Solve dynamic system for a single case using Newmark-β method with Newton-Raphson iteration\n",
    "\n",
    "#     Args:\n",
    "#         structural_components (dict): Contains system matrices (M, K, F)\n",
    "#         initial_displacement (np.array): Initial displacement vector for this case (1D array)\n",
    "#         total_time (float): Total simulation time\n",
    "#         dt (float): Time step size\n",
    "#         beta (float): Newmark-β parameter\n",
    "#         gamma (float): Newmark-γ parameter\n",
    "#         tol (float): Convergence tolerance\n",
    "#         max_iter (int): Maximum iterations per time step\n",
    "\n",
    "#     Returns:\n",
    "#         dict: Results including displacements, velocities, accelerations, etc.\n",
    "#     \"\"\"\n",
    "#     M = structural_components['M_constrained']\n",
    "#     K = structural_components['K_constrained']\n",
    "#     F = structural_components['f_constrained']\n",
    "#     n = M.shape[0]\n",
    "\n",
    "#     # Time integration setup\n",
    "#     n_steps = int(total_time / dt) + 1\n",
    "#     t = np.linspace(0, total_time, n_steps)\n",
    "\n",
    "#     # Initialize variables\n",
    "#     x = np.zeros((n_steps, n))\n",
    "#     xdot = np.zeros((n_steps, n))\n",
    "#     xddot = np.zeros((n_steps, n))\n",
    "#     x[0, :] = initial_displacement\n",
    "\n",
    "#     # Effective stiffness matrix\n",
    "#     c1 = 1 / (beta * dt**2)\n",
    "#     c2 = gamma / (beta * dt)\n",
    "#     c3 = 1 / (beta * dt)\n",
    "#     c5 = (1 - 2 * beta) / (2 * beta)\n",
    "#     K_eff = K + c1 * M\n",
    "\n",
    "#     iterations_per_step = []\n",
    "#     residuals_per_step = []\n",
    "#     convergence_status = []\n",
    "#     converged_steps = 0\n",
    "#     non_converged_steps = []\n",
    "\n",
    "#     for i in range(1, n_steps):\n",
    "#         F_ext = F  # constant force vector\n",
    "#         x_pred = x[i - 1, :]\n",
    "#         xdot_pred = xdot[i - 1, :]\n",
    "#         xddot_pred = xddot[i - 1, :]\n",
    "#         x_new = x_pred.copy()\n",
    "\n",
    "#         converged = False\n",
    "#         for iteration in range(max_iter):\n",
    "#             acc_term = x_pred * c1 + xdot_pred * c3 + xddot_pred * c5\n",
    "#             F_eff = F_ext + M @ acc_term\n",
    "#             # R = K_eff @ x_new - F_eff\n",
    "#             R = F_eff - K_eff @ x_new\n",
    "#             # delta_x = np.linalg.solve(K_eff, -R)\n",
    "#             delta_x = np.linalg.solve(K_eff, R)\n",
    "#             x_new += delta_x\n",
    "\n",
    "#             residual_norm = np.linalg.norm(R)\n",
    "#             residuals_per_step.append(residual_norm)\n",
    "\n",
    "#             if np.linalg.norm(delta_x) < tol:\n",
    "#                 converged = True\n",
    "#                 converged_steps += 1\n",
    "#                 break\n",
    "\n",
    "#         iterations_per_step.append(iteration + 1)\n",
    "#         convergence_status.append(converged)\n",
    "\n",
    "#         if not converged:\n",
    "#             non_converged_steps.append((i, iteration + 1))\n",
    "#             print(f\"[Warning] Time step {i} did not converge within {max_iter} iterations. Final residual norm: {residual_norm:.2e}\")\n",
    "\n",
    "#         # Update state variables\n",
    "#         xddot[i, :] = (x_new - x_pred) / (beta * dt**2) - xdot_pred / (beta * dt) - ((1 / (2 * beta)) - 1) * xddot_pred\n",
    "#         xdot[i, :] = xdot_pred + dt * ((1 - gamma) * xddot_pred + gamma * xddot[i, :])\n",
    "#         x[i, :] = x_new\n",
    "\n",
    "#     if non_converged_steps:\n",
    "#         print(\"\\n\\u26a0\\ufe0f Non-Converged Time Steps Summary:\")\n",
    "#         for step_id, iters in non_converged_steps:\n",
    "#             print(f\"  - Time step {step_id} failed to converge in {iters} iterations.\")\n",
    "#     else:\n",
    "#         print(\"\\u2705 All time steps converged successfully.\")\n",
    "\n",
    "#     return {\n",
    "#         'time': t,\n",
    "#         'displacement': x,\n",
    "#         'velocity': xdot,\n",
    "#         'acceleration': xddot,\n",
    "#         'iterations_per_step': np.array(iterations_per_step),\n",
    "#         'residuals_per_step': residuals_per_step,\n",
    "#         'converged_steps': converged_steps,\n",
    "#         'convergence_status': np.array(convergence_status),\n",
    "#         'non_converged_steps': non_converged_steps,\n",
    "#         'scales': {'M_scale': 1, 'K_scale': 1, 'F_scale': 1}\n",
    "#     }\n",
    "\n",
    "\n",
    "# def analyze_and_print_results(case_results, case_times, magnitudes):\n",
    "#     \"\"\"\n",
    "#     Analyze results from all cases and print detailed tabulated information\n",
    "#     \"\"\"\n",
    "#     n_cases = len(case_results)\n",
    "    \n",
    "#     # Prepare data for summary table\n",
    "#     summary_data = []\n",
    "#     convergence_data = []\n",
    "#     performance_data = []\n",
    "    \n",
    "#     for idx, (results, solve_time, magnitude) in enumerate(zip(case_results, case_times, magnitudes)):\n",
    "#         iterations = results['iterations_per_step']\n",
    "#         residuals = results['residuals_per_step']\n",
    "#         conv_status = results['convergence_status']\n",
    "#         n_steps = len(results['time'])\n",
    "        \n",
    "#         # Summary statistics\n",
    "#         converged_steps = np.sum(conv_status)\n",
    "#         non_converged = n_steps - converged_steps\n",
    "#         max_disp = np.max(np.abs(results['displacement']))\n",
    "#         max_vel = np.max(np.abs(results['velocity']))\n",
    "#         max_acc = np.max(np.abs(results['acceleration']))\n",
    "        \n",
    "#         # Iteration statistics\n",
    "#         converged_iters = iterations[conv_status]\n",
    "#         avg_iters = np.mean(converged_iters) if len(converged_iters) > 0 else 0\n",
    "#         max_iters = np.max(iterations)\n",
    "#         min_iters = np.min(converged_iters) if len(converged_iters) > 0 else 0\n",
    "        \n",
    "#         # Add to summary table\n",
    "#         summary_data.append([\n",
    "#             idx + 1,\n",
    "#             str(magnitude),\n",
    "#             f\"{max_disp:.2e}\",\n",
    "#             f\"{max_vel:.2e}\",\n",
    "#             f\"{max_acc:.2e}\",\n",
    "#             f\"{solve_time:.2f}\"\n",
    "#         ])\n",
    "        \n",
    "#         # Add to convergence table\n",
    "#         convergence_data.append([\n",
    "#             idx + 1,\n",
    "#             str(magnitude),\n",
    "#             converged_steps,\n",
    "#             non_converged,\n",
    "#             f\"{(converged_steps/n_steps)*100:.1f}%\",\n",
    "#             f\"{min_iters:.1f}\",\n",
    "#             f\"{avg_iters:.1f}\",\n",
    "#             max_iters\n",
    "#         ])\n",
    "        \n",
    "#         # Collect iteration distribution\n",
    "#         iter_dist = {}\n",
    "#         for i in range(1, max_iters + 1):\n",
    "#             count = np.sum(iterations == i)\n",
    "#             if count > 0:\n",
    "#                 iter_dist[i] = count\n",
    "        \n",
    "#         # Add to performance table\n",
    "#         performance_data.append([\n",
    "#             idx + 1,\n",
    "#             str(magnitude),\n",
    "#             f\"{np.min(residuals):.2e}\",\n",
    "#             f\"{np.mean(residuals):.2e}\",\n",
    "#             f\"{np.max(residuals):.2e}\",\n",
    "#             f\"{solve_time/n_steps:.4f}\",\n",
    "#             str(iter_dist)\n",
    "#         ])\n",
    "    \n",
    "#     # Print Summary Table\n",
    "#     print(\"\\nResults Summary:\")\n",
    "#     print(\"=\" * 80)\n",
    "#     headers = [\"Case\", \"Magnitude\", \"Max Displacement\", \"Max Velocity\", \"Max Acceleration\", \"Solve Time (s)\"]\n",
    "#     print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "#     # Print Convergence Table\n",
    "#     print(\"\\nConvergence Analysis:\")\n",
    "#     print(\"=\" * 80)\n",
    "#     headers = [\"Case\", \"Magnitude\", \"Converged Steps\", \"Non-converged\", \"Success Rate\", \n",
    "#               \"Min Iters\", \"Avg Iters\", \"Max Iters\"]\n",
    "#     print(tabulate(convergence_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "#     # Print Performance Table\n",
    "#     print(\"\\nPerformance Analysis:\")\n",
    "#     print(\"=\" * 80)\n",
    "#     headers = [\"Case\", \"Magnitude\", \"Min Residual\", \"Avg Residual\", \"Max Residual\", \n",
    "#               \"Time per Step (s)\", \"Iteration Distribution\"]\n",
    "#     print(tabulate(performance_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "#     # Print Overall Statistics\n",
    "#     print(\"\\nOverall Statistics:\")\n",
    "#     print(\"=\" * 80)\n",
    "#     total_time = np.sum(case_times)\n",
    "#     print(f\"Total computation time: {total_time:.2f} seconds\")\n",
    "#     print(f\"Average time per case: {total_time/n_cases:.2f} seconds\")\n",
    "#     print(f\"Number of cases: {n_cases}\")\n",
    "#     print(f\"Fastest case: {np.min(case_times):.2f} seconds (Case {np.argmin(case_times)+1})\")\n",
    "#     print(f\"Slowest case: {np.max(case_times):.2f} seconds (Case {np.argmax(case_times)+1})\")\n",
    "\n",
    "# def save_case_results(results, case_dir):\n",
    "#     \"\"\"\n",
    "#     Save results for a single case with comprehensive solution storage\n",
    "#     \"\"\"\n",
    "#     # Create solution directory\n",
    "#     solution_dir = case_dir / 'solution'\n",
    "#     solution_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "#     # Save raw solution arrays as .npy files\n",
    "#     np.save(solution_dir / 'time.npy', results['time'])\n",
    "#     np.save(solution_dir / 'displacement.npy', results['displacement'])\n",
    "#     np.save(solution_dir / 'velocity.npy', results['velocity'])\n",
    "#     np.save(solution_dir / 'acceleration.npy', results['acceleration'])\n",
    "    \n",
    "#     # Save time history data in compressed format\n",
    "#     np.savez(case_dir / 'time_history.npz',\n",
    "#              time=results['time'],\n",
    "#              displacement=results['displacement'],\n",
    "#              velocity=results['velocity'],\n",
    "#              acceleration=results['acceleration'])\n",
    "    \n",
    "#     # Save convergence data\n",
    "#     np.savez(case_dir / 'convergence_data.npz',\n",
    "#              iterations=results['iterations_per_step'],\n",
    "#              residuals=results['residuals_per_step'],\n",
    "#              convergence_status=results['convergence_status'])\n",
    "    \n",
    "#     # Save scaling factors\n",
    "#     np.savez(case_dir / 'scaling_factors.npz', **results['scales'])\n",
    "    \n",
    "#     # Save summary statistics\n",
    "#     with open(case_dir / 'summary.txt', 'w') as f:\n",
    "#         f.write(\"Results Summary:\\n\")\n",
    "#         f.write(\"=\" * 50 + \"\\n\")\n",
    "#         f.write(f\"Time steps completed: {len(results['time'])}\\n\")\n",
    "#         f.write(f\"Maximum displacement: {np.max(np.abs(results['displacement'])):.2e}\\n\")\n",
    "#         f.write(f\"Maximum velocity: {np.max(np.abs(results['velocity'])):.2e}\\n\")\n",
    "#         f.write(f\"Maximum acceleration: {np.max(np.abs(results['acceleration'])):.2e}\\n\")\n",
    "#         f.write(f\"Converged steps: {np.sum(results['convergence_status'])}\\n\")\n",
    "#         f.write(f\"Non-converged steps: {np.sum(~results['convergence_status'])}\\n\")\n",
    "#         f.write(\"\\nFile Locations:\\n\")\n",
    "#         f.write(\"-\" * 30 + \"\\n\")\n",
    "#         f.write(f\"Solution arrays (.npy files): {solution_dir}\\n\")\n",
    "#         f.write(f\"Time history: {case_dir/'time_history.npz'}\\n\")\n",
    "#         f.write(f\"Convergence data: {case_dir/'convergence_data.npz'}\\n\")\n",
    "#         f.write(f\"Scaling factors: {case_dir/'scaling_factors.npz'}\\n\")\n",
    "\n",
    "\n",
    "# def solve_newmark_dynamic_multi_case(M, K, f, magnitudes, x, total_time=1.0, dt=0.01, beta=0.25, gamma=0.5, tol=1e-6, max_iter=50):\n",
    "#     print(\"Function called with:\")\n",
    "#     print(f\"M: {M.shape}, K: {K.shape}, f: {f.shape}, magnitudes: {magnitudes}, x: {x.shape}\")\n",
    "#     # Rest of the function implementation\n",
    "#     \"\"\"\n",
    "#     Solve dynamic system for multiple cases using Newmark-β method\n",
    "\n",
    "#     Args:\n",
    "#         M (np.array): Mass matrix\n",
    "#         K (np.array): Stiffness matrix\n",
    "#         f (np.array): Force matrix (each column corresponds to a case)\n",
    "#         magnitudes (list): List of magnitudes for each case\n",
    "#         x (np.array): Initial displacement matrix (each column corresponds to a case)\n",
    "#         total_time (float): Total simulation time\n",
    "#         dt (float): Time step size\n",
    "#         beta (float): Newmark-β parameter\n",
    "#         gamma (float): Newmark-γ parameter\n",
    "#         tol (float): Convergence tolerance\n",
    "#         max_iter (int): Maximum iterations per time step\n",
    "\n",
    "#     Returns:\n",
    "#         output_dir (Path): Directory where results are saved\n",
    "#         case_results (list): List of results for each case\n",
    "#         case_times (list): List of computation times for each case\n",
    "#     \"\"\"\n",
    "#     output_dir = Path(\"Dynamic_solution\")\n",
    "#     if output_dir.exists():\n",
    "#         shutil.rmtree(output_dir)\n",
    "#     output_dir.mkdir()\n",
    "    \n",
    "#     n_dof = M.shape[0]\n",
    "#     n_cases = f.shape[1]\n",
    "    \n",
    "#     print(f\"\\nStarting multi-case dynamic analysis...\")\n",
    "#     print(f\"Number of DOFs: {n_dof}\")\n",
    "#     print(f\"Number of cases: {n_cases}\")\n",
    "    \n",
    "#     # Track results and timing for each case\n",
    "#     case_results = []\n",
    "#     case_times = []\n",
    "    \n",
    "#     for case_idx in tqdm(range(n_cases), desc=\"Processing cases\"):\n",
    "#         case_dir = output_dir / f\"case_{case_idx+1}_magnitude_{magnitudes[case_idx]}\" / \"Numerical_Solution\"\n",
    "#         case_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "#         structural_components = {\n",
    "#             'M_constrained': M,\n",
    "#             'K_constrained': K,\n",
    "#             'f_constrained': f[:, case_idx]\n",
    "#         }\n",
    "        \n",
    "#         print(f\"\\nSolving case {case_idx+1}/{n_cases}\")\n",
    "#         print(f\"Magnitude: {magnitudes[case_idx]}\")\n",
    "        \n",
    "#         try:\n",
    "#             # Time the solution\n",
    "#             start_time = time.time()\n",
    "#             results = solve_newmark_dynamic_single_case(\n",
    "#                 structural_components,\n",
    "#                 initial_displacement=x[:, case_idx],  # Pass initial displacement for this case\n",
    "#                 total_time=total_time,\n",
    "#                 dt=dt,\n",
    "#                 beta=beta,\n",
    "#                 gamma=gamma,\n",
    "#                 tol=tol,\n",
    "#                 max_iter=max_iter\n",
    "#             )\n",
    "#             solve_time = time.time() - start_time\n",
    "            \n",
    "#             # Store results and timing\n",
    "#             case_results.append(results)\n",
    "#             case_times.append(solve_time)\n",
    "            \n",
    "#             # Save results\n",
    "#             save_case_results(results, case_dir)\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error in case {case_idx+1}: {str(e)}\")\n",
    "#             continue\n",
    "    \n",
    "#     # Analyze and print detailed results\n",
    "#     analyze_and_print_results(case_results, case_times, magnitudes)\n",
    "    \n",
    "#     return output_dir, case_results, case_times\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         print(\"Starting multi-case dynamic analysis...\")\n",
    "        \n",
    "#         output_dir, case_results, case_times = solve_newmark_dynamic_multi_case(\n",
    "#             M=M_constrained,\n",
    "#             K=K_constrained,\n",
    "#             f=f_constrained,\n",
    "#             magnitudes=magnitudes,\n",
    "#             x=x,  \n",
    "#             total_time=1.0,\n",
    "#             dt=1e-3,\n",
    "#             beta=0.25,\n",
    "#             gamma=0.5,\n",
    "#             tol=1e-8,\n",
    "#             max_iter=50\n",
    "#         )\n",
    "        \n",
    "#         print(f\"\\nAnalysis complete. Results saved in: {output_dir}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in dynamic analysis: {str(e)}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "# def solve_newmark_dynamic_single_case(structural_components, initial_displacement, total_time, dt, \n",
    "#                                      beta, gamma, tol, max_iter):\n",
    "#     \"\"\"\n",
    "#     Solve dynamic system for a single case using Newmark-β method\n",
    "\n",
    "#     Args:\n",
    "#         structural_components (dict): Contains system matrices (M, K, F)\n",
    "#         initial_displacement (np.array): Initial displacement vector for this case (1D array)\n",
    "#         total_time (float): Total simulation time\n",
    "#         dt (float): Time step size\n",
    "#         beta (float): Newmark-β parameter\n",
    "#         gamma (float): Newmark-γ parameter\n",
    "#         tol (float): Convergence tolerance\n",
    "#         max_iter (int): Maximum iterations per time step\n",
    "\n",
    "#     Returns:\n",
    "#         dict: Results including displacements, velocities, accelerations, etc.\n",
    "#     \"\"\"\n",
    "#     # Get system matrices and force vector\n",
    "#     M = structural_components['M_constrained']\n",
    "#     K = structural_components['K_constrained']\n",
    "#     F = structural_components['f_constrained']\n",
    "#     n = M.shape[0]\n",
    "\n",
    "#     # Scale matrices to improve conditioning\n",
    "#     M_scale = 1.0 \n",
    "#     K_scale = 1.0 \n",
    "#     F_scale = 1.0 \n",
    "\n",
    "#     M_scaled = M / M_scale\n",
    "#     K_scaled = K / K_scale\n",
    "#     F_scaled = F / F_scale\n",
    "    \n",
    "#     print(\"\\nMatrix scaling factors:\")\n",
    "#     print(f\"Mass matrix scale: {M_scale:.2e}\")\n",
    "#     print(f\"Stiffness matrix scale: {K_scale:.2e}\")\n",
    "#     print(f\"Force vector scale: {F_scale:.2e}\")\n",
    "\n",
    "#     # Setup time integration\n",
    "#     n_steps = int(total_time / dt) + 1\n",
    "#     t = np.linspace(0, total_time, n_steps)\n",
    "\n",
    "#     # Initialize solution arrays\n",
    "#     d = np.zeros((n_steps, n))  # Displacement\n",
    "#     v = np.zeros((n_steps, n))  # Velocity\n",
    "#     a = np.zeros((n_steps, n))  # Acceleration\n",
    "\n",
    "#     # Set initial displacement for this case\n",
    "#     d[0] = initial_displacement  # Correctly set the initial displacement\n",
    "\n",
    "#     # Initial acceleration\n",
    "#     a[0] = linalg.solve(M_scaled, F_scaled[0] - K_scaled @ d[0])\n",
    "\n",
    "#     # Newmark constants (pre-calculate for efficiency)\n",
    "#     c1 = 1 / (beta * dt**2)\n",
    "#     c2 = gamma / (beta * dt)\n",
    "#     c3 = 1 / (beta * dt)\n",
    "#     c5 = (1 - 2 * beta) / (2 * beta)\n",
    "\n",
    "#     # Effective stiffness matrix (K_tan^dyn), pre-factor for efficiency\n",
    "#     K_eff = K_scaled + c1 * M_scaled\n",
    "#     K_eff_factor = linalg.lu_factor(K_eff)\n",
    "\n",
    "#     # Convergence tracking arrays\n",
    "#     iterations_per_step = np.zeros(n_steps, dtype=int)\n",
    "#     residuals_per_step = np.zeros(n_steps)\n",
    "#     convergence_status = np.ones(n_steps, dtype=bool)\n",
    "\n",
    "#     # Time stepping\n",
    "#     for i in range(1, n_steps):\n",
    "#         a_pred = a[i-1].copy()  # Initial guess for a_i\n",
    "#         d_pred = d[i - 1] + dt * v[i - 1] + (dt**2) * ((1 - 2 * beta) / 2 * a[i - 1] + beta * a_pred)\n",
    "#         v_pred = v[i - 1] + dt * ((1 - gamma) * a[i - 1] + gamma * a_pred)\n",
    "\n",
    "#         # Newton-Raphson iteration\n",
    "#         d[i] = d_pred.copy()  # Initial guess for displacement at i\n",
    "#         v[i] = v_pred.copy()  # Initial guess for velocity at i\n",
    "#         converged = False\n",
    "\n",
    "#         for j in range(max_iter):\n",
    "#             # Calculate accelerations and velocities based on x_{n+1} (Eqs. 2.17 & 2.18)\n",
    "#             a_i = c1 * (d[i] - d[i - 1]) - c3 * v[i - 1] - c5 * a[i - 1]\n",
    "#             v_i = c2 * (d[i] - d[i - 1]) - (gamma/beta - 1) * v[i-1] - (dt/2) * (gamma/beta - 2) * a[i - 1]\n",
    "\n",
    "#             # Calculate the residual force (Eq 2.19):\n",
    "#             R = F[i] - M @ a_i - K @ d[i]\n",
    "\n",
    "#             residual_norm = np.linalg.norm(R)\n",
    "\n",
    "#             # Check for Convergence\n",
    "#             if residual_norm < tol:\n",
    "#                 converged = True\n",
    "#                 iterations_per_step[i] = j + 1\n",
    "#                 residuals_per_step[i] = residual_norm\n",
    "#                 a[i] = a_i\n",
    "#                 v[i] = v_i\n",
    "#                 break\n",
    "\n",
    "#             # Solve for the displacement increment (delta_d)\n",
    "#             try:\n",
    "#                 delta_d = linalg.lu_solve(K_eff_factor, R)\n",
    "#                 d[i] += delta_d\n",
    "#             except np.linalg.LinAlgError:\n",
    "#                 break\n",
    "\n",
    "#         if not converged:\n",
    "#             convergence_status[i] = False\n",
    "#             iterations_per_step[i] = max_iter\n",
    "#             residuals_per_step[i] = residual_norm\n",
    "#             a[i] = a_i\n",
    "#             v[i] = v_i\n",
    "    \n",
    "#     return {\n",
    "#         'time': t,\n",
    "#         'displacement': d,\n",
    "#         'velocity': v,\n",
    "#         'acceleration': a,\n",
    "#         'iterations_per_step': iterations_per_step,\n",
    "#         'residuals_per_step': residuals_per_step,\n",
    "#         'convergence_status': convergence_status,\n",
    "#         'scales': {'M_scale': M_scale, 'K_scale': K_scale, 'F_scale': F_scale}\n",
    "#     }\n",
    "\n",
    "def solve_newmark_dynamic_single_case(structural_components, initial_displacement, total_time, dt, \n",
    "                                     beta, gamma, tol, max_iter):\n",
    "    M = structural_components['M_constrained']\n",
    "    K = structural_components['K_constrained']\n",
    "    F = structural_components['f_constrained']\n",
    "    n = M.shape[0]\n",
    "\n",
    "    n_steps = int(total_time / dt) + 1\n",
    "    t = np.linspace(0, total_time, n_steps)\n",
    "\n",
    "    x = np.zeros((n_steps, n))\n",
    "    xdot = np.zeros((n_steps, n))\n",
    "    xddot = np.zeros((n_steps, n))\n",
    "    x[0, :] = initial_displacement\n",
    "\n",
    "    c1 = 1 / (beta * dt**2)\n",
    "    c2 = gamma / (beta * dt)\n",
    "    c3 = 1 / (beta * dt)\n",
    "    c5 = (1 - 2 * beta) / (2 * beta)\n",
    "    K_eff = K + c1 * M\n",
    "\n",
    "    iterations_per_step = []\n",
    "    residuals_per_step = []\n",
    "    convergence_status = []\n",
    "    converged_steps = 0\n",
    "    non_converged_steps = []\n",
    "\n",
    "    for i in range(1, n_steps):\n",
    "        F_ext = F\n",
    "        x_pred = x[i - 1, :]\n",
    "        xdot_pred = xdot[i - 1, :]\n",
    "        xddot_pred = xddot[i - 1, :]\n",
    "        x_new = x_pred.copy()\n",
    "\n",
    "        converged = False\n",
    "        for iteration in range(max_iter):\n",
    "            acc_term = x_pred * c1 + xdot_pred * c3 + xddot_pred * c5\n",
    "            F_eff = F_ext + M @ acc_term\n",
    "            R = F_eff - K_eff @ x_new\n",
    "            delta_x = np.linalg.solve(K_eff, R)\n",
    "            x_new += delta_x\n",
    "\n",
    "            residual_norm = np.linalg.norm(R)\n",
    "            residuals_per_step.append(residual_norm)\n",
    "\n",
    "            if np.linalg.norm(delta_x) < tol:\n",
    "                converged = True\n",
    "                converged_steps += 1\n",
    "                break\n",
    "\n",
    "        iterations_per_step.append(iteration + 1)\n",
    "        convergence_status.append(converged)\n",
    "\n",
    "        if not converged:\n",
    "            non_converged_steps.append((i, iteration + 1))\n",
    "            print(f\"[Warning] Time step {i} did not converge within {max_iter} iterations. Final residual norm: {residual_norm:.2e}\")\n",
    "\n",
    "        xddot[i, :] = (x_new - x_pred) / (beta * dt**2) - xdot_pred / (beta * dt) - ((1 / (2 * beta)) - 1) * xddot_pred\n",
    "        xdot[i, :] = xdot_pred + dt * ((1 - gamma) * xddot_pred + gamma * xddot[i, :])\n",
    "        x[i, :] = x_new\n",
    "\n",
    "    # Compute internal force F = M*a + K*u\n",
    "    force = np.zeros_like(x)\n",
    "    for i in range(n_steps):\n",
    "        force[i, :] = M @ xddot[i, :] + K @ x[i, :]\n",
    "\n",
    "    if non_converged_steps:\n",
    "        print(\"\\n⚠️ Non-Converged Time Steps Summary:\")\n",
    "        for step_id, iters in non_converged_steps:\n",
    "            print(f\"  - Time step {step_id} failed to converge in {iters} iterations.\")\n",
    "    else:\n",
    "        print(\"✅ All time steps converged successfully.\")\n",
    "\n",
    "    return {\n",
    "        'time': t,\n",
    "        'displacement': x,\n",
    "        'velocity': xdot,\n",
    "        'acceleration': xddot,\n",
    "        'force': force,\n",
    "        'iterations_per_step': np.array(iterations_per_step),\n",
    "        'residuals_per_step': residuals_per_step,\n",
    "        'converged_steps': converged_steps,\n",
    "        'convergence_status': np.array(convergence_status),\n",
    "        'non_converged_steps': non_converged_steps,\n",
    "        'scales': {'M_scale': 1, 'K_scale': 1, 'F_scale': 1}\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_and_print_results(case_results, case_times, magnitudes):\n",
    "    \"\"\"\n",
    "    Analyze results from all cases and print detailed tabulated information\n",
    "    \"\"\"\n",
    "    n_cases = len(case_results)\n",
    "    \n",
    "    # Prepare data for summary table\n",
    "    summary_data = []\n",
    "    convergence_data = []\n",
    "    performance_data = []\n",
    "    \n",
    "    for idx, (results, solve_time, magnitude) in enumerate(zip(case_results, case_times, magnitudes)):\n",
    "        iterations = results['iterations_per_step']\n",
    "        residuals = results['residuals_per_step']\n",
    "        conv_status = results['convergence_status']\n",
    "        n_steps = len(results['time'])\n",
    "        \n",
    "        # Summary statistics\n",
    "        converged_steps = np.sum(conv_status)\n",
    "        non_converged = n_steps - converged_steps\n",
    "        max_disp = np.max(np.abs(results['displacement']))\n",
    "        max_vel = np.max(np.abs(results['velocity']))\n",
    "        max_acc = np.max(np.abs(results['acceleration']))\n",
    "        \n",
    "        # Iteration statistics\n",
    "        converged_iters = iterations[conv_status]\n",
    "        avg_iters = np.mean(converged_iters) if len(converged_iters) > 0 else 0\n",
    "        max_iters = np.max(iterations)\n",
    "        min_iters = np.min(converged_iters) if len(converged_iters) > 0 else 0\n",
    "        \n",
    "        # Add to summary table\n",
    "        summary_data.append([\n",
    "            idx + 1,\n",
    "            str(magnitude),\n",
    "            f\"{max_disp:.2e}\",\n",
    "            f\"{max_vel:.2e}\",\n",
    "            f\"{max_acc:.2e}\",\n",
    "            f\"{solve_time:.2f}\"\n",
    "        ])\n",
    "        \n",
    "        # Add to convergence table\n",
    "        convergence_data.append([\n",
    "            idx + 1,\n",
    "            str(magnitude),\n",
    "            converged_steps,\n",
    "            non_converged,\n",
    "            f\"{(converged_steps/n_steps)*100:.1f}%\",\n",
    "            f\"{min_iters:.1f}\",\n",
    "            f\"{avg_iters:.1f}\",\n",
    "            max_iters\n",
    "        ])\n",
    "        \n",
    "        # Collect iteration distribution\n",
    "        iter_dist = {}\n",
    "        for i in range(1, max_iters + 1):\n",
    "            count = np.sum(iterations == i)\n",
    "            if count > 0:\n",
    "                iter_dist[i] = count\n",
    "        \n",
    "        # Add to performance table\n",
    "        performance_data.append([\n",
    "            idx + 1,\n",
    "            str(magnitude),\n",
    "            f\"{np.min(residuals):.2e}\",\n",
    "            f\"{np.mean(residuals):.2e}\",\n",
    "            f\"{np.max(residuals):.2e}\",\n",
    "            f\"{solve_time/n_steps:.4f}\",\n",
    "            str(iter_dist)\n",
    "        ])\n",
    "    \n",
    "    # Print Summary Table\n",
    "    print(\"\\nResults Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    headers = [\"Case\", \"Magnitude\", \"Max Displacement\", \"Max Velocity\", \"Max Acceleration\", \"Solve Time (s)\"]\n",
    "    print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "    # Print Convergence Table\n",
    "    print(\"\\nConvergence Analysis:\")\n",
    "    print(\"=\" * 80)\n",
    "    headers = [\"Case\", \"Magnitude\", \"Converged Steps\", \"Non-converged\", \"Success Rate\", \n",
    "              \"Min Iters\", \"Avg Iters\", \"Max Iters\"]\n",
    "    print(tabulate(convergence_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "    # Print Performance Table\n",
    "    print(\"\\nPerformance Analysis:\")\n",
    "    print(\"=\" * 80)\n",
    "    headers = [\"Case\", \"Magnitude\", \"Min Residual\", \"Avg Residual\", \"Max Residual\", \n",
    "              \"Time per Step (s)\", \"Iteration Distribution\"]\n",
    "    print(tabulate(performance_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "    # Print Overall Statistics\n",
    "    print(\"\\nOverall Statistics:\")\n",
    "    print(\"=\" * 80)\n",
    "    total_time = np.sum(case_times)\n",
    "    print(f\"Total computation time: {total_time:.2f} seconds\")\n",
    "    print(f\"Average time per case: {total_time/n_cases:.2f} seconds\")\n",
    "    print(f\"Number of cases: {n_cases}\")\n",
    "    print(f\"Fastest case: {np.min(case_times):.2f} seconds (Case {np.argmin(case_times)+1})\")\n",
    "    print(f\"Slowest case: {np.max(case_times):.2f} seconds (Case {np.argmax(case_times)+1})\")\n",
    "\n",
    "def save_case_results(results, case_dir):\n",
    "    solution_dir = case_dir / 'solution'\n",
    "    solution_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    np.save(solution_dir / 'time.npy', results['time'])\n",
    "    np.save(solution_dir / 'displacement.npy', results['displacement'])\n",
    "    np.save(solution_dir / 'velocity.npy', results['velocity'])\n",
    "    np.save(solution_dir / 'acceleration.npy', results['acceleration'])\n",
    "    np.save(solution_dir / 'force.npy', results['force'])\n",
    "\n",
    "    np.savez(case_dir / 'time_history.npz',\n",
    "             time=results['time'],\n",
    "             displacement=results['displacement'],\n",
    "             velocity=results['velocity'],\n",
    "             acceleration=results['acceleration'])\n",
    "\n",
    "    np.savez(case_dir / 'convergence_data.npz',\n",
    "             iterations=results['iterations_per_step'],\n",
    "             residuals=results['residuals_per_step'],\n",
    "             convergence_status=results['convergence_status'])\n",
    "\n",
    "    np.savez(case_dir / 'scaling_factors.npz', **results['scales'])\n",
    "\n",
    "    with open(case_dir / 'summary.txt', 'w') as f:\n",
    "        f.write(\"Results Summary:\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(f\"Time steps completed: {len(results['time'])}\\n\")\n",
    "        f.write(f\"Maximum displacement: {np.max(np.abs(results['displacement'])):.2e}\\n\")\n",
    "        f.write(f\"Maximum velocity: {np.max(np.abs(results['velocity'])):.2e}\\n\")\n",
    "        f.write(f\"Maximum acceleration: {np.max(np.abs(results['acceleration'])):.2e}\\n\")\n",
    "        f.write(f\"Converged steps: {np.sum(results['convergence_status'])}\\n\")\n",
    "        f.write(f\"Non-converged steps: {np.sum(~results['convergence_status'])}\\n\")\n",
    "        f.write(\"\\nFile Locations:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(f\"Solution arrays (.npy files): {solution_dir}\\n\")\n",
    "        f.write(f\"Time history: {case_dir/'time_history.npz'}\\n\")\n",
    "        f.write(f\"Convergence data: {case_dir/'convergence_data.npz'}\\n\")\n",
    "        f.write(f\"Scaling factors: {case_dir/'scaling_factors.npz'}\\n\")\n",
    "        f.write(f\"Force data: {solution_dir/'force.npy'}\\n\")\n",
    "\n",
    "\n",
    "def solve_newmark_dynamic_multi_case(M, K, f, magnitudes, x, total_time=1.0, dt=0.01, beta=0.25, gamma=0.5, tol=1e-6, max_iter=50):\n",
    "    print(\"Function called with:\")\n",
    "    print(f\"M: {M.shape}, K: {K.shape}, f: {f.shape}, magnitudes: {magnitudes}, x: {x.shape}\")\n",
    "    # Rest of the function implementation\n",
    "    \"\"\"\n",
    "    Solve dynamic system for multiple cases using Newmark-β method\n",
    "\n",
    "    Args:\n",
    "        M (np.array): Mass matrix\n",
    "        K (np.array): Stiffness matrix\n",
    "        f (np.array): Force matrix (each column corresponds to a case)\n",
    "        magnitudes (list): List of magnitudes for each case\n",
    "        x (np.array): Initial displacement matrix (each column corresponds to a case)\n",
    "        total_time (float): Total simulation time\n",
    "        dt (float): Time step size\n",
    "        beta (float): Newmark-β parameter\n",
    "        gamma (float): Newmark-γ parameter\n",
    "        tol (float): Convergence tolerance\n",
    "        max_iter (int): Maximum iterations per time step\n",
    "\n",
    "    Returns:\n",
    "        output_dir (Path): Directory where results are saved\n",
    "        case_results (list): List of results for each case\n",
    "        case_times (list): List of computation times for each case\n",
    "    \"\"\"\n",
    "    output_dir = Path(\"Dynamic_solution\")\n",
    "    if output_dir.exists():\n",
    "        shutil.rmtree(output_dir)\n",
    "    output_dir.mkdir()\n",
    "    \n",
    "    n_dof = M.shape[0]\n",
    "    n_cases = f.shape[1]\n",
    "    \n",
    "    print(f\"\\nStarting multi-case dynamic analysis...\")\n",
    "    print(f\"Number of DOFs: {n_dof}\")\n",
    "    print(f\"Number of cases: {n_cases}\")\n",
    "    \n",
    "    # Track results and timing for each case\n",
    "    case_results = []\n",
    "    case_times = []\n",
    "    \n",
    "    for case_idx in tqdm(range(n_cases), desc=\"Processing cases\"):\n",
    "        case_dir = output_dir / f\"case_{case_idx+1}_magnitude_{magnitudes[case_idx]}\" / \"Numerical_Solution\"\n",
    "        case_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        structural_components = {\n",
    "            'M_constrained': M,\n",
    "            'K_constrained': K,\n",
    "            'f_constrained': f[:, case_idx]\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nSolving case {case_idx+1}/{n_cases}\")\n",
    "        print(f\"Magnitude: {magnitudes[case_idx]}\")\n",
    "        \n",
    "        try:\n",
    "            # Time the solution\n",
    "            start_time = time.time()\n",
    "            results = solve_newmark_dynamic_single_case(\n",
    "                structural_components,\n",
    "                initial_displacement=x[:, case_idx],  # Pass initial displacement for this case\n",
    "                total_time=total_time,\n",
    "                dt=dt,\n",
    "                beta=beta,\n",
    "                gamma=gamma,\n",
    "                tol=tol,\n",
    "                max_iter=max_iter\n",
    "            )\n",
    "            solve_time = time.time() - start_time\n",
    "            \n",
    "            # Store results and timing\n",
    "            case_results.append(results)\n",
    "            case_times.append(solve_time)\n",
    "            \n",
    "            # Save results\n",
    "            save_case_results(results, case_dir)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in case {case_idx+1}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Analyze and print detailed results\n",
    "    analyze_and_print_results(case_results, case_times, magnitudes)\n",
    "    \n",
    "    return output_dir, case_results, case_times\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"Starting multi-case dynamic analysis...\")\n",
    "        \n",
    "        output_dir, case_results, case_times = solve_newmark_dynamic_multi_case(\n",
    "            M=M_constrained,\n",
    "            K=K_constrained,\n",
    "            f=f_constrained,\n",
    "            magnitudes=magnitudes,\n",
    "            x=x,  \n",
    "            total_time=1.0,\n",
    "            dt=1e-4,\n",
    "            beta=0.25,\n",
    "            gamma=0.5,\n",
    "            tol=1e-8,\n",
    "            max_iter=50\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nAnalysis complete. Results saved in: {output_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in dynamic analysis: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def read_mdpa_and_select_boundary_nodes(mdpa_file):\n",
    "    \"\"\"\n",
    "    Reads the mdpa file and identifies boundary nodes.\n",
    "    Returns the node coordinates and boundary nodes.\n",
    "    \"\"\"\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    boundary_nodes = set()\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    node_coords.append([int(parts[0]), float(parts[1]), float(parts[2])])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]), int(parts[3]), int(parts[4])\n",
    "                    elements.append([n1, n2, n3])\n",
    "                    boundary_nodes.update([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "    return node_coords, elements, boundary_nodes\n",
    "\n",
    "def select_boundary_points(node_coords, boundary_nodes):\n",
    "    \"\"\"\n",
    "    Selects 3 boundary points: one at the bottom, one in the middle, and one at the top.\n",
    "    \"\"\"\n",
    "    boundary_coords = node_coords[np.isin(node_coords[:, 0], list(boundary_nodes))]\n",
    "    sorted_coords = boundary_coords[np.argsort(boundary_coords[:, 2])]  # Sort by Y-coordinate\n",
    "\n",
    "    bottom_node = sorted_coords[0]\n",
    "    top_node = sorted_coords[-1]\n",
    "    middle_node = sorted_coords[len(sorted_coords) // 2]\n",
    "\n",
    "    return bottom_node, middle_node, top_node\n",
    "\n",
    "def plot_node_representation(mdpa_file, node_id):\n",
    "    \"\"\"\n",
    "    Highlights the selected node on the mesh by drawing a circle around it.\n",
    "    \"\"\"\n",
    "    node_coords, elements, _ = read_mdpa_and_select_boundary_nodes(mdpa_file)\n",
    "    x = node_coords[:, 1]\n",
    "    y = node_coords[:, 2]\n",
    "\n",
    "    triangulation = tri.Triangulation(x, y, elements - 1)\n",
    "\n",
    "    selected_node = node_coords[node_coords[:, 0] == node_id][0]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.triplot(triangulation, 'k-', lw=0.5, alpha=0.5)\n",
    "    plt.scatter(selected_node[1], selected_node[2], color='red', label=f'Selected Node {node_id}')\n",
    "    plt.gca().add_artist(plt.Circle((selected_node[1], selected_node[2]), radius=0.1, color='red', fill=False))\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title(f'Mesh with Highlighted Node {node_id}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_displacement(time_newmark, displacement_newmark, time_ivp, displacement_ivp, node_id, node_x, node_y):\n",
    "    \"\"\"\n",
    "    Plots displacement vs time for the selected node.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time_newmark, displacement_newmark, label='Newmark Method', color='blue')\n",
    "    # plt.plot(time_ivp, displacement_ivp, label='Solve IVP Method', color='red', linestyle='--')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Displacement (m)')\n",
    "    plt.title(f'Displacement vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_velocity(time_newmark, velocity_newmark, time_ivp, velocity_ivp, node_id, node_x, node_y):\n",
    "    \"\"\"\n",
    "    Plots velocity vs time for the selected node.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time_newmark, velocity_newmark, label='Newmark Method', color='blue')\n",
    "    # plt.plot(time_ivp, velocity_ivp, label='Solve IVP Method', color='red', linestyle='--')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Velocity (m/s)')\n",
    "    plt.title(f'Velocity vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_acceleration(time_newmark, acceleration_newmark, time_ivp, acceleration_ivp, node_id, node_x, node_y):\n",
    "    \"\"\"\n",
    "    Plots acceleration vs time for the selected node.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time_newmark, acceleration_newmark, label='Newmark Method', color='blue')\n",
    "    # plt.plot(time_ivp, acceleration_ivp, label='Solve IVP Method', color='red', linestyle='--')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Acceleration (m/s²)')\n",
    "    plt.title(f'Acceleration vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "node_coords, elements, boundary_nodes = read_mdpa_and_select_boundary_nodes(mdpa_file)\n",
    "bottom_node, middle_node, top_node = select_boundary_points(node_coords, boundary_nodes)\n",
    "\n",
    "selected_nodes = [bottom_node, middle_node, top_node]\n",
    "\n",
    "\n",
    "\n",
    "# Plot displacement, velocity, and acceleration for each selected node\n",
    "for node in selected_nodes:\n",
    "    node_id = int(node[0])\n",
    "    node_x, node_y = node[1], node[2]\n",
    "\n",
    "    # Plot node representation\n",
    "    plot_node_representation(mdpa_file, node_id)\n",
    "\n",
    "    idx = np.where(node_coords[:, 0] == node_id)[0][0]\n",
    "    displacement_newmark = case_results[0]['displacement'][:, idx]\n",
    "    # displacement_ivp = u[:, idx]  \n",
    "    velocity_newmark = case_results[0]['velocity'][:, idx]\n",
    "    # velocity_ivp = v[:, idx]\n",
    "    acceleration_newmark = case_results[0]['acceleration'][:, idx]\n",
    "    # acceleration_ivp = a[:, idx]\n",
    "\n",
    "    plot_displacement(case_results[0]['time'], displacement_newmark, case_results[0]['time'], displacement_newmark, node_id, node_x, node_y)\n",
    "    plot_velocity(case_results[0]['time'], velocity_newmark, case_results[0]['time'], velocity_newmark, node_id, node_x, node_y)\n",
    "    plot_acceleration(case_results[0]['time'], acceleration_newmark, case_results[0]['time'], acceleration_newmark, node_id, node_x, node_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(case_results[0]['force'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot convergence for each case\n",
    "plt.figure(figsize=(10, 6))\n",
    "for idx, case in enumerate(case_results):\n",
    "    iterations = case['iterations_per_step']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(len(iterations)), iterations, label=f'Case {idx + 1} (Magnitude: {magnitudes[idx]})')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Number of Iterations')\n",
    "    plt.title(f'Convergence Plot for Case {idx + 1}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === EXAMPLE USAGE ===\n",
    "# # Define system\n",
    "# M = np.diag([1000.0, 1000.0])\n",
    "# K = np.diag([1e5, 1e5])\n",
    "# f = np.array([[9810.0], [9810.0]])  # Constant force on both DOFs\n",
    "\n",
    "# structural_components = {\n",
    "#     'M_constrained': M,\n",
    "#     'K_constrained': K,\n",
    "#     'f_constrained': f.flatten()  # Shape: (n_dof,)\n",
    "# }\n",
    "\n",
    "# initial_displacement = np.array([0.1, 0.0])  # 2 DOF initial displacement\n",
    "\n",
    "# # Solve\n",
    "# result = solve_newmark_dynamic_single_case(\n",
    "#     structural_components,\n",
    "#     initial_displacement=initial_displacement,\n",
    "#     total_time=10.0,\n",
    "#     dt=0.01,\n",
    "#     beta=0.25,\n",
    "#     gamma=0.5,\n",
    "#     tol=1e-6,\n",
    "#     max_iter=50\n",
    "# )\n",
    "\n",
    "# # === PLOT DISPLACEMENT ===\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for i in range(result['displacement'].shape[1]):\n",
    "#     plt.plot(result['time'], result['displacement'][:, i], label=f'DOF {i + 1}')\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.ylabel('Displacement (m)')\n",
    "# plt.title('n DOF Displacement - Newmark with Newton-Raphson')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # === PRINT ITERATIONS ===\n",
    "# print(f\"\\nConverged steps: {result['converged_steps']} / {len(result['time']) - 1}\")\n",
    "# print(\"Iterations per time step:\")\n",
    "# for i, it in enumerate(result['iterations_per_step']):\n",
    "#     print(f\"Step {i + 1}: {it} iterations\")\n",
    "\n",
    "# # === OPTIONAL: Plot iteration count ===\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.plot(result['iterations_per_step'], marker='o', linestyle='--')\n",
    "# plt.xlabel('Time Step')\n",
    "# plt.ylabel('Number of Iterations')\n",
    "# plt.title('Newton-Raphson Iterations per Time Step')\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy import linalg\n",
    "# import os\n",
    "# import shutil\n",
    "# from pathlib import Path\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# from tabulate import tabulate\n",
    "\n",
    "# def solve_newmark_dynamic_single_case(structural_components, initial_displacement, total_time, dt, \n",
    "#                                      beta, gamma, tol, max_iter):\n",
    "#     \"\"\"\n",
    "#     Solve dynamic system for a single case using Newmark-β method\n",
    "\n",
    "#     Args:\n",
    "#         structural_components (dict): Contains system matrices (M, K, F)\n",
    "#         initial_displacement (np.array): Initial displacement vector for this case (1D array)\n",
    "#         total_time (float): Total simulation time\n",
    "#         dt (float): Time step size\n",
    "#         beta (float): Newmark-β parameter\n",
    "#         gamma (float): Newmark-γ parameter\n",
    "#         tol (float): Convergence tolerance\n",
    "#         max_iter (int): Maximum iterations per time step\n",
    "\n",
    "#     Returns:\n",
    "#         dict: Results including displacements, velocities, accelerations, etc.\n",
    "#     \"\"\"\n",
    "#     # Get system matrices and force vector\n",
    "#     M = structural_components['M_constrained']\n",
    "#     K = structural_components['K_constrained']\n",
    "#     F = structural_components['f_constrained']\n",
    "#     n = M.shape[0]\n",
    "\n",
    "#     # Scale matrices to improve conditioning\n",
    "#     M_scale = 1.0 \n",
    "#     K_scale = 1.0 \n",
    "#     F_scale = 1.0 \n",
    "\n",
    "#     M_scaled = M / M_scale\n",
    "#     K_scaled = K / K_scale\n",
    "#     F_scaled = F / F_scale\n",
    "    \n",
    "#     print(\"\\nMatrix scaling factors:\")\n",
    "#     print(f\"Mass matrix scale: {M_scale:.2e}\")\n",
    "#     print(f\"Stiffness matrix scale: {K_scale:.2e}\")\n",
    "#     print(f\"Force vector scale: {F_scale:.2e}\")\n",
    "\n",
    "#     # Setup time integration\n",
    "#     n_steps = int(total_time / dt) + 1\n",
    "#     t = np.linspace(0, total_time, n_steps)\n",
    "\n",
    "#     # Initialize solution arrays\n",
    "#     d = np.zeros((n_steps, n))  # Displacement\n",
    "#     v = np.zeros((n_steps, n))  # Velocity\n",
    "#     a = np.zeros((n_steps, n))  # Acceleration\n",
    "\n",
    "#     # Set initial displacement for this case\n",
    "#     d[0] = initial_displacement  # Correctly set the initial displacement\n",
    "\n",
    "#     # Initial acceleration\n",
    "#     # a[0] = linalg.solve(M_scaled, F_scaled[0] - K_scaled @ d[0])\n",
    "#     a[0] = np.linalg.solve(M_scaled, F_scaled.flatten() - (K_scaled @ d[0])) # Acceleration\n",
    "\n",
    "#     flattened_shape = F_scaled.flatten()\n",
    "#     print(flattened_shape.shape)\n",
    "#     print(F_scaled.shape)\n",
    "\n",
    "#     # Newmark constants (pre-calculate for efficiency)\n",
    "#     c1 = 1 / (beta * dt**2)\n",
    "#     c2 = gamma / (beta * dt)\n",
    "#     c3 = 1 / (beta * dt)\n",
    "#     c5 = (1 - 2 * beta) / (2 * beta)\n",
    "\n",
    "#     # Effective stiffness matrix (K_tan^dyn), pre-factor for efficiency\n",
    "#     K_eff = K_scaled + c1 * M_scaled\n",
    "#     K_eff_factor = linalg.lu_factor(K_eff)\n",
    "\n",
    "#     # Convergence tracking arrays\n",
    "#     iterations_per_step = np.zeros(n_steps, dtype=int)\n",
    "#     residuals_per_step = np.zeros(n_steps)\n",
    "#     convergence_status = np.ones(n_steps, dtype=bool)\n",
    "\n",
    "#     # Time stepping\n",
    "#     for i in range(1, n_steps):\n",
    "#         # a_pred = a[i-1].copy()  # Initial guess for a_i\n",
    "#         # d_pred = d[i - 1] + dt * v[i - 1] + (dt**2) * ((1 - 2 * beta) / 2 * a[i - 1] + beta * a_pred)\n",
    "#         # v_pred = v[i - 1] + dt * ((1 - gamma) * a[i - 1] + gamma * a_pred)\n",
    "#         d_pred = d[i-1] + dt*v[i-1] + (0.5-beta)*dt**2*a[i-1]\n",
    "#         v_pred = v[i-1] + (1-gamma)*dt*a[i-1]\n",
    "\n",
    "#         # Newton-Raphson iteration\n",
    "#         d[i] = d_pred.copy()  # Initial guess for displacement at i\n",
    "#         v[i] = v_pred.copy()  # Initial guess for velocity at i\n",
    "#         converged = False\n",
    "\n",
    "#         for j in range(max_iter):\n",
    "#             # Calculate accelerations and velocities based on x_{n+1} (Eqs. 2.17 & 2.18)\n",
    "#             a_i = c1 * (d[i] - d[i - 1]) - c3 * v[i - 1] - c5 * a[i - 1]\n",
    "#             v_i = c2 * (d[i] - d[i - 1]) - (gamma/beta - 1) * v[i-1] - (dt/2) * (gamma/beta - 2) * a[i - 1]\n",
    "\n",
    "#             # Calculate the residual force (Eq 2.19):\n",
    "#             R = F - M @ a_i - K @ d[i]\n",
    "\n",
    "#             residual_norm = np.linalg.norm(R)\n",
    "\n",
    "#             # Check for Convergence\n",
    "#             if residual_norm < tol:\n",
    "#                 converged = True\n",
    "#                 iterations_per_step[i] = j + 1\n",
    "#                 residuals_per_step[i] = residual_norm\n",
    "#                 a[i] = a_i\n",
    "#                 v[i] = v_i\n",
    "#                 break\n",
    "\n",
    "#             # Solve for the displacement increment (delta_d)\n",
    "#             try:\n",
    "#                 delta_d = linalg.lu_solve(K_eff_factor, R)\n",
    "#                 d[i] += delta_d\n",
    "#                 a[i] = a_i\n",
    "#                 v[i] = v_i\n",
    "#             except np.linalg.LinAlgError:\n",
    "#                 break\n",
    "\n",
    "#         if not converged:\n",
    "#             convergence_status[i] = False\n",
    "#             iterations_per_step[i] = max_iter\n",
    "#             residuals_per_step[i] = residual_norm\n",
    "#             a[i] = a_i\n",
    "#             v[i] = v_i\n",
    "    \n",
    "#     return {\n",
    "#         'time': t,\n",
    "#         'displacement': d,\n",
    "#         'velocity': v,\n",
    "#         'acceleration': a,\n",
    "#         'iterations_per_step': iterations_per_step,\n",
    "#         'residuals_per_step': residuals_per_step,\n",
    "#         'convergence_status': convergence_status,\n",
    "#         'scales': {'M_scale': M_scale, 'K_scale': K_scale, 'F_scale': F_scale}\n",
    "#     }\n",
    "\n",
    "\n",
    "\n",
    "# def analyze_and_print_results(case_results, case_times, magnitudes):\n",
    "#     \"\"\"\n",
    "#     Analyze results from all cases and print detailed tabulated information\n",
    "#     \"\"\"\n",
    "#     n_cases = len(case_results)\n",
    "    \n",
    "#     # Prepare data for summary table\n",
    "#     summary_data = []\n",
    "#     convergence_data = []\n",
    "#     performance_data = []\n",
    "    \n",
    "#     for idx, (results, solve_time, magnitude) in enumerate(zip(case_results, case_times, magnitudes)):\n",
    "#         iterations = results['iterations_per_step']\n",
    "#         residuals = results['residuals_per_step']\n",
    "#         conv_status = results['convergence_status']\n",
    "#         n_steps = len(results['time'])\n",
    "        \n",
    "#         # Summary statistics\n",
    "#         converged_steps = np.sum(conv_status)\n",
    "#         non_converged = n_steps - converged_steps\n",
    "#         max_disp = np.max(np.abs(results['displacement']))\n",
    "#         max_vel = np.max(np.abs(results['velocity']))\n",
    "#         max_acc = np.max(np.abs(results['acceleration']))\n",
    "        \n",
    "#         # Iteration statistics\n",
    "#         converged_iters = iterations[conv_status]\n",
    "#         avg_iters = np.mean(converged_iters) if len(converged_iters) > 0 else 0\n",
    "#         max_iters = np.max(iterations)\n",
    "#         min_iters = np.min(converged_iters) if len(converged_iters) > 0 else 0\n",
    "        \n",
    "#         # Add to summary table\n",
    "#         summary_data.append([\n",
    "#             idx + 1,\n",
    "#             str(magnitude),\n",
    "#             f\"{max_disp:.2e}\",\n",
    "#             f\"{max_vel:.2e}\",\n",
    "#             f\"{max_acc:.2e}\",\n",
    "#             f\"{solve_time:.2f}\"\n",
    "#         ])\n",
    "        \n",
    "#         # Add to convergence table\n",
    "#         convergence_data.append([\n",
    "#             idx + 1,\n",
    "#             str(magnitude),\n",
    "#             converged_steps,\n",
    "#             non_converged,\n",
    "#             f\"{(converged_steps/n_steps)*100:.1f}%\",\n",
    "#             f\"{min_iters:.1f}\",\n",
    "#             f\"{avg_iters:.1f}\",\n",
    "#             max_iters\n",
    "#         ])\n",
    "        \n",
    "#         # Collect iteration distribution\n",
    "#         iter_dist = {}\n",
    "#         for i in range(1, max_iters + 1):\n",
    "#             count = np.sum(iterations == i)\n",
    "#             if count > 0:\n",
    "#                 iter_dist[i] = count\n",
    "        \n",
    "#         # Add to performance table\n",
    "#         performance_data.append([\n",
    "#             idx + 1,\n",
    "#             str(magnitude),\n",
    "#             f\"{np.min(residuals):.2e}\",\n",
    "#             f\"{np.mean(residuals):.2e}\",\n",
    "#             f\"{np.max(residuals):.2e}\",\n",
    "#             f\"{solve_time/n_steps:.4f}\",\n",
    "#             str(iter_dist)\n",
    "#         ])\n",
    "    \n",
    "#     # Print Summary Table\n",
    "#     print(\"\\nResults Summary:\")\n",
    "#     print(\"=\" * 80)\n",
    "#     headers = [\"Case\", \"Magnitude\", \"Max Displacement\", \"Max Velocity\", \"Max Acceleration\", \"Solve Time (s)\"]\n",
    "#     print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "#     # Print Convergence Table\n",
    "#     print(\"\\nConvergence Analysis:\")\n",
    "#     print(\"=\" * 80)\n",
    "#     headers = [\"Case\", \"Magnitude\", \"Converged Steps\", \"Non-converged\", \"Success Rate\", \n",
    "#               \"Min Iters\", \"Avg Iters\", \"Max Iters\"]\n",
    "#     print(tabulate(convergence_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "#     # Print Performance Table\n",
    "#     print(\"\\nPerformance Analysis:\")\n",
    "#     print(\"=\" * 80)\n",
    "#     headers = [\"Case\", \"Magnitude\", \"Min Residual\", \"Avg Residual\", \"Max Residual\", \n",
    "#               \"Time per Step (s)\", \"Iteration Distribution\"]\n",
    "#     print(tabulate(performance_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "#     # Print Overall Statistics\n",
    "#     print(\"\\nOverall Statistics:\")\n",
    "#     print(\"=\" * 80)\n",
    "#     total_time = np.sum(case_times)\n",
    "#     print(f\"Total computation time: {total_time:.2f} seconds\")\n",
    "#     print(f\"Average time per case: {total_time/n_cases:.2f} seconds\")\n",
    "#     print(f\"Number of cases: {n_cases}\")\n",
    "#     print(f\"Fastest case: {np.min(case_times):.2f} seconds (Case {np.argmin(case_times)+1})\")\n",
    "#     print(f\"Slowest case: {np.max(case_times):.2f} seconds (Case {np.argmax(case_times)+1})\")\n",
    "\n",
    "# def save_case_results(results, case_dir):\n",
    "#     \"\"\"\n",
    "#     Save results for a single case with comprehensive solution storage\n",
    "#     \"\"\"\n",
    "#     # Create solution directory\n",
    "#     solution_dir = case_dir / 'solution'\n",
    "#     solution_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "#     # Save raw solution arrays as .npy files\n",
    "#     np.save(solution_dir / 'time.npy', results['time'])\n",
    "#     np.save(solution_dir / 'displacement.npy', results['displacement'])\n",
    "#     np.save(solution_dir / 'velocity.npy', results['velocity'])\n",
    "#     np.save(solution_dir / 'acceleration.npy', results['acceleration'])\n",
    "    \n",
    "#     # Save time history data in compressed format\n",
    "#     np.savez(case_dir / 'time_history.npz',\n",
    "#              time=results['time'],\n",
    "#              displacement=results['displacement'],\n",
    "#              velocity=results['velocity'],\n",
    "#              acceleration=results['acceleration'])\n",
    "    \n",
    "#     # Save convergence data\n",
    "#     np.savez(case_dir / 'convergence_data.npz',\n",
    "#              iterations=results['iterations_per_step'],\n",
    "#              residuals=results['residuals_per_step'],\n",
    "#              convergence_status=results['convergence_status'])\n",
    "    \n",
    "#     # Save scaling factors\n",
    "#     np.savez(case_dir / 'scaling_factors.npz', **results['scales'])\n",
    "    \n",
    "#     # Save summary statistics\n",
    "#     with open(case_dir / 'summary.txt', 'w') as f:\n",
    "#         f.write(\"Results Summary:\\n\")\n",
    "#         f.write(\"=\" * 50 + \"\\n\")\n",
    "#         f.write(f\"Time steps completed: {len(results['time'])}\\n\")\n",
    "#         f.write(f\"Maximum displacement: {np.max(np.abs(results['displacement'])):.2e}\\n\")\n",
    "#         f.write(f\"Maximum velocity: {np.max(np.abs(results['velocity'])):.2e}\\n\")\n",
    "#         f.write(f\"Maximum acceleration: {np.max(np.abs(results['acceleration'])):.2e}\\n\")\n",
    "#         f.write(f\"Converged steps: {np.sum(results['convergence_status'])}\\n\")\n",
    "#         f.write(f\"Non-converged steps: {np.sum(~results['convergence_status'])}\\n\")\n",
    "#         f.write(\"\\nFile Locations:\\n\")\n",
    "#         f.write(\"-\" * 30 + \"\\n\")\n",
    "#         f.write(f\"Solution arrays (.npy files): {solution_dir}\\n\")\n",
    "#         f.write(f\"Time history: {case_dir/'time_history.npz'}\\n\")\n",
    "#         f.write(f\"Convergence data: {case_dir/'convergence_data.npz'}\\n\")\n",
    "#         f.write(f\"Scaling factors: {case_dir/'scaling_factors.npz'}\\n\")\n",
    "\n",
    "\n",
    "# def solve_newmark_dynamic_multi_case(M, K, f, magnitudes, x, total_time=1.0, dt=0.01, beta=0.25, gamma=0.5, tol=1e-6, max_iter=50):\n",
    "#     print(\"Function called with:\")\n",
    "#     print(f\"M: {M.shape}, K: {K.shape}, f: {f.shape}, magnitudes: {magnitudes}, x: {x.shape}\")\n",
    "#     # Rest of the function implementation\n",
    "#     \"\"\"\n",
    "#     Solve dynamic system for multiple cases using Newmark-β method\n",
    "\n",
    "#     Args:\n",
    "#         M (np.array): Mass matrix\n",
    "#         K (np.array): Stiffness matrix\n",
    "#         f (np.array): Force matrix (each column corresponds to a case)\n",
    "#         magnitudes (list): List of magnitudes for each case\n",
    "#         x (np.array): Initial displacement matrix (each column corresponds to a case)\n",
    "#         total_time (float): Total simulation time\n",
    "#         dt (float): Time step size\n",
    "#         beta (float): Newmark-β parameter\n",
    "#         gamma (float): Newmark-γ parameter\n",
    "#         tol (float): Convergence tolerance\n",
    "#         max_iter (int): Maximum iterations per time step\n",
    "\n",
    "#     Returns:\n",
    "#         output_dir (Path): Directory where results are saved\n",
    "#         case_results (list): List of results for each case\n",
    "#         case_times (list): List of computation times for each case\n",
    "#     \"\"\"\n",
    "#     output_dir = Path(\"Dynamic_solution\")\n",
    "#     if output_dir.exists():\n",
    "#         shutil.rmtree(output_dir)\n",
    "#     output_dir.mkdir()\n",
    "    \n",
    "#     n_dof = M.shape[0]\n",
    "#     n_cases = f.shape[1]\n",
    "    \n",
    "#     print(f\"\\nStarting multi-case dynamic analysis...\")\n",
    "#     print(f\"Number of DOFs: {n_dof}\")\n",
    "#     print(f\"Number of cases: {n_cases}\")\n",
    "    \n",
    "#     # Track results and timing for each case\n",
    "#     case_results = []\n",
    "#     case_times = []\n",
    "    \n",
    "#     for case_idx in tqdm(range(n_cases), desc=\"Processing cases\"):\n",
    "#         case_dir = output_dir / f\"case_{case_idx+1}_magnitude_{magnitudes[case_idx]}\" / \"Numerical_Solution\"\n",
    "#         case_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "#         structural_components = {\n",
    "#             'M_constrained': M,\n",
    "#             'K_constrained': K,\n",
    "#             'f_constrained': f[:, case_idx]\n",
    "#         }\n",
    "#         # x0 = x[:, case_idx]  # Initial displacement for this case\n",
    "#         print(f\"\\nInitial displacement shape: {x0.shape}\")\n",
    "        \n",
    "#         print(f\"\\nSolving case {case_idx+1}/{n_cases}\")\n",
    "#         print(f\"Magnitude: {magnitudes[case_idx]}\")\n",
    "        \n",
    "#         try:\n",
    "#             # Time the solution\n",
    "#             start_time = time.time()\n",
    "#             results = solve_newmark_dynamic_single_case(\n",
    "#                 structural_components,\n",
    "#                 initial_displacement=x0[case_idx],  # Pass initial displacement for this case\n",
    "#                 total_time=total_time,\n",
    "#                 dt=dt,\n",
    "#                 beta=beta,\n",
    "#                 gamma=gamma,\n",
    "#                 tol=tol,\n",
    "#                 max_iter=max_iter\n",
    "#             )\n",
    "#             solve_time = time.time() - start_time\n",
    "            \n",
    "#             # Store results and timing\n",
    "#             case_results.append(results)\n",
    "#             case_times.append(solve_time)\n",
    "            \n",
    "#             # Save results\n",
    "#             save_case_results(results, case_dir)\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error in case {case_idx+1}: {str(e)}\")\n",
    "#             continue\n",
    "    \n",
    "#     # Analyze and print detailed results\n",
    "#     analyze_and_print_results(case_results, case_times, magnitudes)\n",
    "    \n",
    "#     return output_dir, case_results, case_times\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         print(\"Starting multi-case dynamic analysis...\")\n",
    "\n",
    "#         x0 = x [:, 1]  # Initial displacement for the first case\n",
    "#         # print(x0.shape)\n",
    "        \n",
    "#         output_dir, case_results, case_times = solve_newmark_dynamic_multi_case(\n",
    "#             M=M_constrained,\n",
    "#             K=K_constrained,\n",
    "#             f=f_constrained,\n",
    "#             magnitudes=magnitudes,\n",
    "#             x=x0,  \n",
    "#             total_time=0.01,\n",
    "#             dt=3.14e-6,\n",
    "#             beta=0.25,\n",
    "#             gamma=0.5,\n",
    "#             tol=1e-8,\n",
    "#             max_iter=50\n",
    "#         )\n",
    "        \n",
    "#         print(f\"\\nAnalysis complete. Results saved in: {output_dir}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in dynamic analysis: {str(e)}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot displacement, velocity, and acceleration for each mode separately\n",
    "# for mode in range(n_dof):\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "\n",
    "#     # Displacement plot\n",
    "#     plt.subplot(3, 1, 1)\n",
    "#     plt.plot(t, case_results[0]['displacement'][:, mode], label=f'Displacement (Mode {mode + 1})', color=colors[mode % len(colors)])\n",
    "#     plt.ylabel('Displacement (m)')\n",
    "#     plt.title(f'Displacement vs Time (Mode {mode + 1})')\n",
    "#     plt.grid(True)\n",
    "#     plt.legend()\n",
    "\n",
    "#     # Velocity plot\n",
    "#     plt.subplot(3, 1, 2)\n",
    "#     plt.plot(t, case_results[0]['velocity'][:, mode], label=f'Velocity (Mode {mode + 1})', color=colors[mode % len(colors)])\n",
    "#     plt.ylabel('Velocity (m/s)')\n",
    "#     plt.title(f'Velocity vs Time (Mode {mode + 1})')\n",
    "#     plt.grid(True)\n",
    "#     plt.legend()\n",
    "\n",
    "#     # Acceleration plot\n",
    "#     plt.subplot(3, 1, 3)\n",
    "#     plt.plot(t, case_results[0]['acceleration'][:, mode], label=f'Acceleration (Mode {mode + 1})', color=colors[mode % len(colors)])\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Acceleration (m/s²)')\n",
    "#     plt.title(f'Acceleration vs Time (Mode {mode + 1})')\n",
    "#     plt.grid(True)\n",
    "#     plt.legend()\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def plot_displacement_timestep(x_data, time_step, mdpa_file, scale_factor=1e7):\n",
    "    \"\"\"\n",
    "    Plot displacement field for a single time step.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x_data: ndarray of shape (612, 5), displacement data\n",
    "    time_step: int, which time step to plot\n",
    "    mdpa_file: str, path to mdpa file\n",
    "    scale_factor: float, scaling factor for displacements\n",
    "    \"\"\"\n",
    "    # Read node coordinates and elements\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "    \n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    x, y = float(parts[1]), float(parts[2])\n",
    "                    node_coords.append([x, y])\n",
    "                    \n",
    "            if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif reading_elements and \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "                    elements.append([n1, n2, n3])\n",
    "    \n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "    \n",
    "    # Get displacements for the specified time step\n",
    "    displacements = x_data[:, time_step].reshape(-1, 2) * scale_factor\n",
    "    disp_mag = np.sqrt(displacements[:, 0]**2 + displacements[:, 1]**2)\n",
    "    \n",
    "    # Calculate deformed coordinates\n",
    "    deformed_coords = node_coords + displacements\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 15))\n",
    "    \n",
    "    # Create triangulations\n",
    "    triangulation_orig = tri.Triangulation(node_coords[:, 0], node_coords[:, 1], elements)\n",
    "    triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "    \n",
    "    # Plot undeformed mesh\n",
    "    ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "    \n",
    "    # Plot deformed mesh with displacement magnitude coloring\n",
    "    tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm')\n",
    "    ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(f'Displacement Field at Time Step {time_step}')\n",
    "    ax.grid(True)\n",
    "    ax.axis('equal')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print displacement statistics\n",
    "    print(\"\\nDisplacement Statistics:\")\n",
    "    print(f\"Maximum displacement magnitude: {np.max(disp_mag):.2e}\")\n",
    "    print(f\"Minimum displacement magnitude: {np.min(disp_mag):.2e}\")\n",
    "    print(f\"Mean displacement magnitude: {np.mean(disp_mag):.2e}\")\n",
    "\n",
    "try:\n",
    "    # Plot displacement for time step 0 (or change to any desired time step)\n",
    "    plot_displacement_timestep(\n",
    "        x_data=x,  # Your displacement data\n",
    "        time_step=0,  # Change this to see different time steps\n",
    "        mdpa_file=[file for file in os.listdir() if file.endswith('.mdpa')][0],\n",
    "        scale_factor=1e6  # Adjust this to make displacements more visible\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error plotting displacement: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.tri as tri\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "\n",
    "# def plot_displacement_at_timesteps(case_folder, mdpa_file, output_folder_name=\"displacement_plots\", scale_factor=1e7):\n",
    "#     \"\"\"Plot displacement at each timestep and save plots as images in a new folder.\"\"\"\n",
    "#     try:\n",
    "#         # Construct path for the new folder\n",
    "#         output_folder = case_folder / output_folder_name\n",
    "\n",
    "#         # Create the output folder if it doesn't exist\n",
    "#         output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         print(f\"\\nProcessing: {case_folder.name}\")\n",
    "\n",
    "#         # Load solution data\n",
    "#         time = np.load(case_folder / \"Numerical_Solution\" / \"solution\" / \"time.npy\")\n",
    "#         displacement = np.load(case_folder / \"Numerical_Solution\" / \"solution\" / \"displacement.npy\")\n",
    "\n",
    "#         print(f\"Loaded displacement data shape: {displacement.shape}\")\n",
    "#         print(f\"Time steps available: {len(time)}\")\n",
    "\n",
    "#         # Read node coordinates and elements\n",
    "#         node_coords = []\n",
    "#         elements = []\n",
    "#         reading_nodes = False\n",
    "#         reading_elements = False\n",
    "\n",
    "#         with open(mdpa_file, 'r') as file:\n",
    "#             for line in file:\n",
    "#                 line = line.strip()\n",
    "\n",
    "#                 if \"Begin Nodes\" in line:\n",
    "#                     reading_nodes = True\n",
    "#                     continue\n",
    "#                 elif \"End Nodes\" in line:\n",
    "#                     reading_nodes = False\n",
    "#                     continue\n",
    "#                 elif reading_nodes and line:\n",
    "#                     parts = line.split()\n",
    "#                     if len(parts) >= 4:\n",
    "#                         x, y = float(parts[1]), float(parts[2])\n",
    "#                         node_coords.append([x, y])\n",
    "\n",
    "#                 if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "#                     reading_elements = True\n",
    "#                     continue\n",
    "#                 elif reading_elements and \"End Elements\" in line:\n",
    "#                     reading_elements = False\n",
    "#                     continue\n",
    "#                 elif reading_elements and line:\n",
    "#                     parts = line.split()\n",
    "#                     if len(parts) >= 5:\n",
    "#                         n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "#                         elements.append([n1, n2, n3])\n",
    "\n",
    "#         node_coords = np.array(node_coords)\n",
    "#         elements = np.array(elements)\n",
    "\n",
    "#         # Create triangulation for undeformed mesh\n",
    "#         x = node_coords[:, 0]\n",
    "#         y = node_coords[:, 1]\n",
    "#         triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "\n",
    "#         # Find global displacement limits for consistent colorbar\n",
    "#         disp_magnitudes = []\n",
    "#         for step in range(len(time)):\n",
    "#             disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "#             disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "#             disp_magnitudes.append(disp_mag)\n",
    "\n",
    "#         global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "#         global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "\n",
    "#         print(f\"Plotting Information:\")\n",
    "#         print(f\"Total plots: {len(time)}\")\n",
    "#         print(f\"Time range: [{time[0]:.3f}, {time[-1]:.3f}] seconds\")\n",
    "#         print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "#         # Loop through timesteps and plot\n",
    "#         for frame in range(len(time)):\n",
    "#             # Get displacements for current frame\n",
    "#             disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "#             disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "\n",
    "#             # Calculate deformed coordinates\n",
    "#             deformed_coords = node_coords + disp\n",
    "\n",
    "#             # Create figure and axis for each plot\n",
    "#             fig, ax = plt.subplots(figsize=(10, 15))\n",
    "\n",
    "#             # Plot undeformed mesh\n",
    "#             ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "\n",
    "#             # Plot deformed mesh with displacement magnitude coloring\n",
    "#             triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "#             tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "#                                vmin=global_min, vmax=global_max)\n",
    "#             ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "#             # Set labels and title\n",
    "#             ax.set_xlabel('X')\n",
    "#             ax.set_ylabel('Y')\n",
    "#             ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time) - 1})')\n",
    "\n",
    "#             ax.grid(True)\n",
    "#             ax.axis('equal')\n",
    "#             ax.legend()\n",
    "\n",
    "#             # Add colorbar only once\n",
    "#             if frame == 0:\n",
    "#                 plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "\n",
    "#             plt.tight_layout()\n",
    "\n",
    "#             # Save plot as image\n",
    "#             output_file = output_folder / f\"displacement_frame_{frame:04d}.png\"\n",
    "#             plt.savefig(output_file)\n",
    "#             plt.close(fig)\n",
    "\n",
    "#             # Print progress\n",
    "#             if frame % 10 == 0:\n",
    "#                 print(f\"Processed and saved plot for frame {frame}/{len(time) - 1}\")\n",
    "\n",
    "#         print(\"All plots completed and saved!\")\n",
    "#         return True\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {case_folder.name}: {str(e)}\")\n",
    "#         return False\n",
    "\n",
    "# def process_all_cases(base_dir=\"Dynamic_solution\", mdpa_file=\"2D_beam_udl_loading.mdpa\", scale_factor=1e7):\n",
    "#     \"\"\"Process all cases in the Dynamic_solution directory.\"\"\"\n",
    "#     base_path = Path(base_dir)\n",
    "\n",
    "#     # Find all case folders dynamically\n",
    "#     case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "\n",
    "#     # Sort case folders by case number\n",
    "#     def extract_case_number(folder_name):\n",
    "#         # Extract the case number from the folder name (e.g., \"case_1_magnitude_0.1\" -> 1)\n",
    "#         return int(folder_name.name.split(\"_\")[1])\n",
    "\n",
    "#     case_folders.sort(key=extract_case_number)\n",
    "\n",
    "#     print(f\"Found {len(case_folders)} cases to process\")\n",
    "#     print(\"\\nProcessing order:\")\n",
    "#     for folder in case_folders:\n",
    "#         print(f\"  {folder.name}\")\n",
    "\n",
    "#     # Process each case\n",
    "#     successful = 0\n",
    "#     failed = 0\n",
    "\n",
    "#     for folder in case_folders:\n",
    "#         print(\"\\n\" + \"=\" * 50)\n",
    "#         print(f\"Processing {folder.name}\")\n",
    "#         print(\"=\" * 50)\n",
    "\n",
    "#         if plot_displacement_at_timesteps(folder, mdpa_file, scale_factor=scale_factor):\n",
    "#             successful += 1\n",
    "#         else:\n",
    "#             failed += 1\n",
    "\n",
    "#     print(\"\\n\" + \"=\" * 50)\n",
    "#     print(\"Processing Complete!\")\n",
    "#     print(f\"Successfully processed: {successful} cases\")\n",
    "#     print(f\"Failed to process: {failed} cases\")\n",
    "#     print(\"=\" * 50)\n",
    "\n",
    "# # Run the processing\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         process_all_cases(\n",
    "#             base_dir=\"Dynamic_solution\",\n",
    "#             mdpa_file=\"2D_beam_udl_loading.mdpa\",\n",
    "#             scale_factor=1e6  # Adjust this if needed\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in main execution: {str(e)}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_displacement_animation(case_folder, mdpa_file, scale_factor=1e7, step_interval=100):\n",
    "    \"\"\"\n",
    "    Create an animated GIF of displacement field for a specific case.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    case_folder: Path object, full path to case folder\n",
    "    mdpa_file: str, path to mdpa file\n",
    "    scale_factor: float, scaling factor for displacements\n",
    "    step_interval: int, time in milliseconds between frames\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output filename from case folder name\n",
    "        output_file = case_folder / 'displacement_animation_scaled.gif'\n",
    "        \n",
    "        print(f\"\\nProcessing: {case_folder.name}\")\n",
    "        \n",
    "        # Load solution data\n",
    "        time = np.load(case_folder / \"solution\" / \"time.npy\")\n",
    "        displacement = np.load(case_folder / \"solution\" / \"displacement.npy\")\n",
    "        \n",
    "        print(f\"Loaded displacement data shape: {displacement.shape}\")\n",
    "        print(f\"Time steps available: {len(time)}\")\n",
    "        \n",
    "        # Read node coordinates and elements\n",
    "        node_coords = []\n",
    "        elements = []\n",
    "        reading_nodes = False\n",
    "        reading_elements = False\n",
    "        \n",
    "        with open(mdpa_file, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                \n",
    "                if \"Begin Nodes\" in line:\n",
    "                    reading_nodes = True\n",
    "                    continue\n",
    "                elif \"End Nodes\" in line:\n",
    "                    reading_nodes = False\n",
    "                    continue\n",
    "                elif reading_nodes and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4:\n",
    "                        x, y = float(parts[1]), float(parts[2])\n",
    "                        node_coords.append([x, y])\n",
    "                        \n",
    "                if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                    reading_elements = True\n",
    "                    continue\n",
    "                elif reading_elements and \"End Elements\" in line:\n",
    "                    reading_elements = False\n",
    "                    continue\n",
    "                elif reading_elements and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 5:\n",
    "                        n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "                        elements.append([n1, n2, n3])\n",
    "        \n",
    "        node_coords = np.array(node_coords)\n",
    "        elements = np.array(elements)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=(10, 15))\n",
    "        \n",
    "        # Create base triangulation for undeformed mesh\n",
    "        x = node_coords[:, 0]\n",
    "        y = node_coords[:, 1]\n",
    "        triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "        \n",
    "        # Find global displacement limits for consistent colorbar\n",
    "        disp_magnitudes = []\n",
    "        for step in range(len(time)):\n",
    "            disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            disp_magnitudes.append(disp_mag)\n",
    "        \n",
    "        global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "        global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "        \n",
    "        print(f\"Animation Information:\")\n",
    "        print(f\"Total frames: {len(time)}\")\n",
    "        print(f\"Time range: [{time[0]:.3f}, {time[-1]:.3f}] seconds\")\n",
    "        print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "        \n",
    "        def update(frame):\n",
    "            ax.clear()\n",
    "            \n",
    "            # Get displacements for current frame\n",
    "            disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            \n",
    "            # Calculate deformed coordinates\n",
    "            deformed_coords = node_coords + disp\n",
    "            \n",
    "            # Plot undeformed mesh\n",
    "            ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "            \n",
    "            # Plot deformed mesh with displacement magnitude coloring\n",
    "            triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "            tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                             vmin=global_min, vmax=global_max)\n",
    "            ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "            \n",
    "            # Set labels and title\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "            \n",
    "            ax.grid(True)\n",
    "            ax.axis('equal')\n",
    "            ax.legend()\n",
    "            \n",
    "            # Add colorbar only once\n",
    "            if frame == 0:\n",
    "                plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Print progress\n",
    "            if frame % 10 == 0:\n",
    "                print(f\"Processing frame {frame}/{len(time)-1}\")\n",
    "        \n",
    "        # Create animation\n",
    "        print(\"Creating animation...\")\n",
    "        anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "        \n",
    "        # Save animation\n",
    "        print(f\"Saving animation to {output_file}\")\n",
    "        writer = PillowWriter(fps=1000/step_interval)\n",
    "        anim.save(output_file, writer=writer)\n",
    "        \n",
    "        plt.close()\n",
    "        print(\"Animation completed!\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {case_folder.name}: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "def process_all_cases(base_dir=\"Dynamic_solution\", mdpa_file=\"2D_beam_udl_loading.mdpa\", scale_factor=1e7):\n",
    "    \"\"\"Process all cases in the Dynamic_solution directory.\"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    \n",
    "    # Find all case folders dynamically\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "    \n",
    "    # Sort case folders by case number\n",
    "    def extract_case_number(folder_name):\n",
    "        # Extract the case number from the folder name (e.g., \"case_1_magnitude_0.1\" -> 1)\n",
    "        return int(folder_name.name.split(\"_\")[1])\n",
    "    \n",
    "    case_folders.sort(key=extract_case_number)\n",
    "    \n",
    "    print(f\"Found {len(case_folders)} cases to process\")\n",
    "    print(\"\\nProcessing order:\")\n",
    "    for folder in case_folders:\n",
    "        print(f\"  {folder.name}\")\n",
    "    \n",
    "    # Process each case\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for folder in case_folders:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {folder.name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Adjust path to include Numerical_Solution subfolder\n",
    "        solution_folder = folder / \"Numerical_Solution\"\n",
    "        \n",
    "        if solution_folder.exists():\n",
    "            if create_displacement_animation(solution_folder, mdpa_file, scale_factor):\n",
    "                successful += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "        else:\n",
    "            print(f\"Error: Numerical_Solution folder not found in {folder.name}\")\n",
    "            failed += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Processing Complete!\")\n",
    "    print(f\"Successfully processed: {successful} cases\")\n",
    "    print(f\"Failed to process: {failed} cases\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Run the processing\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        process_all_cases(\n",
    "            base_dir=\"Dynamic_solution\",\n",
    "            mdpa_file=[file for file in os.listdir() if file.endswith('.mdpa')][0],\n",
    "            scale_factor=1e6  # Adjust this if needed\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_displacement_animation(case_folder, mdpa_file, scale_factor=1e7, step_interval=100):\n",
    "    \"\"\"\n",
    "    Create an animated GIF of displacement field for a specific case.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    case_folder: Path object, full path to case folder\n",
    "    mdpa_file: str, path to mdpa file\n",
    "    scale_factor: float, scaling factor for displacements\n",
    "    step_interval: int, time in milliseconds between frames\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output filename from case folder name\n",
    "        output_file = case_folder / 'displacement_animation.gif'\n",
    "        \n",
    "        print(f\"\\nProcessing: {case_folder.name}\")\n",
    "        \n",
    "        # Load solution data\n",
    "        time = np.load(case_folder / \"solution\" / \"time.npy\")\n",
    "        displacement = np.load(case_folder / \"solution\" / \"displacement.npy\")\n",
    "        \n",
    "        print(f\"Loaded displacement data shape: {displacement.shape}\")\n",
    "        print(f\"Time steps available: {len(time)}\")\n",
    "        \n",
    "        # Read node coordinates and elements\n",
    "        node_coords = []\n",
    "        elements = []\n",
    "        reading_nodes = False\n",
    "        reading_elements = False\n",
    "        \n",
    "        with open(mdpa_file, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                \n",
    "                if \"Begin Nodes\" in line:\n",
    "                    reading_nodes = True\n",
    "                    continue\n",
    "                elif \"End Nodes\" in line:\n",
    "                    reading_nodes = False\n",
    "                    continue\n",
    "                elif reading_nodes and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4:\n",
    "                        x, y = float(parts[1]), float(parts[2])\n",
    "                        node_coords.append([x, y])\n",
    "                        \n",
    "                if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                    reading_elements = True\n",
    "                    continue\n",
    "                elif reading_elements and \"End Elements\" in line:\n",
    "                    reading_elements = False\n",
    "                    continue\n",
    "                elif reading_elements and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 5:\n",
    "                        n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "                        elements.append([n1, n2, n3])\n",
    "        \n",
    "        node_coords = np.array(node_coords)\n",
    "        elements = np.array(elements)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=(10, 15))\n",
    "        \n",
    "        # Create base triangulation for undeformed mesh\n",
    "        x = node_coords[:, 0]\n",
    "        y = node_coords[:, 1]\n",
    "        triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "        \n",
    "        # Find global displacement limits for consistent colorbar\n",
    "        disp_magnitudes = []\n",
    "        for step in range(len(time)):\n",
    "            disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            disp_magnitudes.append(disp_mag)\n",
    "        \n",
    "        global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "        global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "        \n",
    "        print(f\"Animation Information:\")\n",
    "        print(f\"Total frames: {len(time)}\")\n",
    "        print(f\"Time range: [{time[0]:.3f}, {time[-1]:.3f}] seconds\")\n",
    "        print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "        \n",
    "        def update(frame):\n",
    "            ax.clear()\n",
    "            \n",
    "            # Get displacements for current frame\n",
    "            disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            \n",
    "            # Calculate deformed coordinates\n",
    "            deformed_coords = node_coords + disp\n",
    "            \n",
    "            # Plot undeformed mesh\n",
    "            ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "            \n",
    "            # Plot deformed mesh with displacement magnitude coloring\n",
    "            triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "            tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                             vmin=global_min, vmax=global_max)\n",
    "            ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "            \n",
    "            # Set labels and title\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "            \n",
    "            ax.grid(True)\n",
    "            ax.axis('equal')\n",
    "            ax.legend()\n",
    "            \n",
    "            # Add colorbar only once\n",
    "            if frame == 0:\n",
    "                plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Print progress\n",
    "            if frame % 10 == 0:\n",
    "                print(f\"Processing frame {frame}/{len(time)-1}\")\n",
    "        \n",
    "        # Create animation\n",
    "        print(\"Creating animation...\")\n",
    "        anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "        \n",
    "        # Save animation\n",
    "        print(f\"Saving animation to {output_file}\")\n",
    "        writer = PillowWriter(fps=1000/step_interval)\n",
    "        anim.save(output_file, writer=writer)\n",
    "        \n",
    "        plt.close()\n",
    "        print(\"Animation completed!\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {case_folder.name}: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "def process_all_cases(base_dir=\"Dynamic_solution\", mdpa_file=\"2D_beam_udl_loading.mdpa\", scale_factor=1e7):\n",
    "    \"\"\"Process all cases in the Dynamic_solution directory.\"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    \n",
    "    # Find all case folders dynamically\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "    \n",
    "    # Sort case folders by case number\n",
    "    def extract_case_number(folder_name):\n",
    "        # Extract the case number from the folder name (e.g., \"case_1_magnitude_0.1\" -> 1)\n",
    "        return int(folder_name.name.split(\"_\")[1])\n",
    "    \n",
    "    case_folders.sort(key=extract_case_number)\n",
    "    \n",
    "    print(f\"Found {len(case_folders)} cases to process\")\n",
    "    print(\"\\nProcessing order:\")\n",
    "    for folder in case_folders:\n",
    "        print(f\"  {folder.name}\")\n",
    "    \n",
    "    # Process each case\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for folder in case_folders:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {folder.name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Adjust path to include Numerical_Solution subfolder\n",
    "        solution_folder = folder / \"Numerical_Solution\"\n",
    "        \n",
    "        if solution_folder.exists():\n",
    "            if create_displacement_animation(solution_folder, mdpa_file, scale_factor):\n",
    "                successful += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "        else:\n",
    "            print(f\"Error: Numerical_Solution folder not found in {folder.name}\")\n",
    "            failed += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Processing Complete!\")\n",
    "    print(f\"Successfully processed: {successful} cases\")\n",
    "    print(f\"Failed to process: {failed} cases\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Run the processing\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        process_all_cases(\n",
    "            base_dir=\"Dynamic_solution\",\n",
    "            mdpa_file=[file for file in os.listdir() if file.endswith('.mdpa')][0],\n",
    "            scale_factor=1  # Adjust this if needed\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def save_displacement_frames(case_folder, mdpa_file, scale_factor=1e7):\n",
    "    \"\"\"\n",
    "    Save displacement screenshots for each time step as .png images.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    case_folder: Path object, full path to case folder\n",
    "    mdpa_file: str, path to mdpa file\n",
    "    scale_factor: float, scaling factor for displacements\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\n📂 Processing: {case_folder.name}\")\n",
    "        \n",
    "        # Load solution data\n",
    "        time_file = case_folder / \"solution\" / \"time.npy\"\n",
    "        displacement_file = case_folder / \"solution\" / \"displacement.npy\"\n",
    "        time = np.load(time_file)\n",
    "        displacement = np.load(displacement_file)\n",
    "\n",
    "        print(f\"📥 Loaded:\")\n",
    "        print(f\"   Time file        : {time_file.resolve()}\")\n",
    "        print(f\"   Displacement file: {displacement_file.resolve()}\")\n",
    "        print(f\"   Shape of displacement data: {displacement.shape}\")\n",
    "        print(f\"   Number of time steps: {len(time)}\")\n",
    "        \n",
    "        # Read mesh\n",
    "        node_coords = []\n",
    "        elements = []\n",
    "        reading_nodes = False\n",
    "        reading_elements = False\n",
    "        \n",
    "        print(f\"📄 Reading mesh from: {Path(mdpa_file).resolve()}\")\n",
    "        with open(mdpa_file, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                \n",
    "                if \"Begin Nodes\" in line:\n",
    "                    reading_nodes = True\n",
    "                    continue\n",
    "                elif \"End Nodes\" in line:\n",
    "                    reading_nodes = False\n",
    "                    continue\n",
    "                elif reading_nodes and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4:\n",
    "                        x, y = float(parts[1]), float(parts[2])\n",
    "                        node_coords.append([x, y])\n",
    "                        \n",
    "                if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                    reading_elements = True\n",
    "                    continue\n",
    "                elif reading_elements and \"End Elements\" in line:\n",
    "                    reading_elements = False\n",
    "                    continue\n",
    "                elif reading_elements and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 5:\n",
    "                        n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "                        elements.append([n1, n2, n3])\n",
    "        \n",
    "        node_coords = np.array(node_coords)\n",
    "        elements = np.array(elements)\n",
    "        \n",
    "        # Create triangulation\n",
    "        triangulation_orig = tri.Triangulation(node_coords[:, 0], node_coords[:, 1], elements)\n",
    "\n",
    "        # Output folder for images\n",
    "        output_dir = case_folder / \"solution\" / \"displacement_frames\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        print(f\"🖼️  Saving displacement plots to: {output_dir.resolve()}\")\n",
    "        \n",
    "        # Global color scale\n",
    "        disp_magnitudes = []\n",
    "        for step in range(len(time)):\n",
    "            disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            disp_magnitudes.append(disp_mag)\n",
    "\n",
    "        global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "        global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "        print(f\"📊 Displacement magnitude range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "        # Plot and save each frame\n",
    "        for frame in range(len(time)):\n",
    "            fig, ax = plt.subplots(figsize=(10, 15))\n",
    "            disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            deformed_coords = node_coords + disp\n",
    "\n",
    "            triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "\n",
    "            ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "            tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                               vmin=global_min, vmax=global_max)\n",
    "            ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "            ax.grid(True)\n",
    "            ax.axis('equal')\n",
    "            ax.legend()\n",
    "            plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "            plt.tight_layout()\n",
    "\n",
    "            frame_path = output_dir / f\"frame_{frame:04d}.png\"\n",
    "            plt.savefig(frame_path)\n",
    "            plt.close()\n",
    "            print(f\"✅ Saved: {frame_path.name}\")\n",
    "\n",
    "        print(f\"🎉 All displacement frames saved for: {case_folder.name}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {case_folder.name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def process_all_cases(base_dir=\"Dynamic_solution\", mdpa_file=\"2D_beam_udl_loading.mdpa\", scale_factor=1e7):\n",
    "    \"\"\"Process all cases in the Dynamic_solution directory by saving PNG frames instead of GIFs.\"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "\n",
    "    # Sort folders\n",
    "    def extract_case_number(folder_name):\n",
    "        return int(folder_name.name.split(\"_\")[1])\n",
    "\n",
    "    case_folders.sort(key=extract_case_number)\n",
    "\n",
    "    print(f\"🔍 Found {len(case_folders)} cases to process\")\n",
    "    print(\"📦 Processing order:\")\n",
    "    for folder in case_folders:\n",
    "        print(f\"  - {folder.name}\")\n",
    "\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "\n",
    "    for folder in case_folders:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"🚀 Processing {folder.name}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        solution_folder = folder / \"Numerical_Solution\"\n",
    "\n",
    "        if solution_folder.exists():\n",
    "            if save_displacement_frames(solution_folder, mdpa_file, scale_factor):\n",
    "                successful += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "        else:\n",
    "            print(f\"❌ Error: Numerical_Solution folder not found in {folder.name}\")\n",
    "            failed += 1\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✅ Processing Complete!\")\n",
    "    print(f\"✅ Successfully processed: {successful}\")\n",
    "    print(f\"❌ Failed to process: {failed}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# Run the processing\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        process_all_cases(\n",
    "            base_dir=\"Dynamic_solution\",\n",
    "            mdpa_file=[file for file in os.listdir() if file.endswith('.mdpa')][0],\n",
    "            scale_factor=1e6\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in main execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.integrate import solve_ivp\n",
    "# import matplotlib.pyplot as plt\n",
    "# import time\n",
    "# from tqdm import tqdm\n",
    "# from pathlib import Path\n",
    "# from tabulate import tabulate\n",
    "\n",
    "# s = f_constrained.shape[0]\n",
    "# # Initialize initial velocity as zero vector\n",
    "# v0 = np.zeros((s, f_constrained.shape[1]))\n",
    "\n",
    "# # Assemble the matrices M* and K*\n",
    "# I = np.eye(s)  # Identity matrix (s x s)\n",
    "# Z = np.zeros((s, s))  # Zero matrix (s x s)\n",
    "\n",
    "# # M* = [M 0; 0 I] (2s x 2s)\n",
    "# M_star = np.block([[M_constrained, Z], [Z, I]])\n",
    "\n",
    "# # K* = [0 K; -I 0] (2s x 2s)\n",
    "# K_star = np.block([[Z, K_constrained], [-I, Z]])\n",
    "\n",
    "# # Precompute the inverse of M*\n",
    "# M_star_inv = np.linalg.inv(M_star)\n",
    "\n",
    "# # Time span\n",
    "# t_span = (0, 1)  # From t=0 to t=1\n",
    "\n",
    "# # Define the ODE function\n",
    "# def dUdt(t, U, M_star_inv, K_star, F_star):\n",
    "#     \"\"\"Compute dU*/dt = M*^{-1} F* - (M*^{-1} K*) U*\"\"\"\n",
    "#     return M_star_inv @ (F_star - (K_star @ U))\n",
    "\n",
    "# # Get number of cases and magnitudes\n",
    "# num_cases = f_constrained.shape[1]\n",
    "\n",
    "# # Create the base directory\n",
    "# base_dir = Path(\"Dynamic_solution\")\n",
    "# base_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# # Print initial information\n",
    "# print(\"Starting multi-case dynamic analysis...\")\n",
    "# print(f\"Function called with:\\nM: {M_constrained.shape}, K: {K_constrained.shape}, f: {f_constrained.shape}, magnitudes: {magnitudes}, x: {x.shape}\\n\")\n",
    "# print(f\"Number of cases: {num_cases}\")\n",
    "\n",
    "# # Results storage\n",
    "# results = []\n",
    "# case_times = []\n",
    "\n",
    "# # Solve the system for each case\n",
    "# start_time = time.time()\n",
    "# for case in tqdm(range(num_cases), desc=\"Solving cases\"):\n",
    "#     case_start_time = time.time()\n",
    "#     print(f\"\\nSolving case {case + 1}/{num_cases}\")\n",
    "#     magnitude = magnitudes[case]\n",
    "#     print(f\"Magnitude: {magnitude}\")\n",
    "    \n",
    "#     # Create case folder name\n",
    "#     magnitude_str = \", \".join(str(val) for val in magnitude)\n",
    "#     case_folder = base_dir / f\"case_{case+1}_magnitude_({magnitude_str})\"\n",
    "#     analytical_folder = case_folder / \"Analytical_Solution\"\n",
    "#     analytical_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     # Solve the system\n",
    "#     U0 = np.concatenate((v0[:, case], x[:, case]))  # Initial state vector\n",
    "#     F_star = np.concatenate((f_constrained[:, case], np.zeros(s)))  # Force vector\n",
    "    \n",
    "#     # Solve ODE\n",
    "#     sol = solve_ivp(dUdt, t_span, U0, args=(M_star_inv, K_star, F_star), t_eval=np.linspace(t_span[0], t_span[1], 100),\n",
    "#                     method='Radau', rtol=1e-8)\n",
    "    \n",
    "#     # Extract results\n",
    "#     t = sol.t\n",
    "#     U = sol.y\n",
    "#     v = U[:s]  # Velocity\n",
    "#     u = U[s:]  # Displacement\n",
    "#     a = np.gradient(v, t, axis=1)  # Acceleration\n",
    "    \n",
    "#     # Save results\n",
    "#     np.save(analytical_folder / 'time.npy', t)\n",
    "#     np.save(analytical_folder / 'displacement.npy', u)\n",
    "#     np.save(analytical_folder / 'velocity.npy', v)\n",
    "#     np.save(analytical_folder / 'acceleration.npy', a)\n",
    "    \n",
    "#     # Store summary results\n",
    "#     case_time = time.time() - case_start_time\n",
    "#     case_times.append(case_time)\n",
    "    \n",
    "#     results.append({\n",
    "#         \"case\": case + 1,\n",
    "#         \"magnitude\": magnitude,\n",
    "#         \"max_displacement\": np.max(np.abs(u)),\n",
    "#         \"max_velocity\": np.max(np.abs(v)),\n",
    "#         \"max_acceleration\": np.max(np.abs(a)),\n",
    "#         \"solve_time\": case_time\n",
    "#     })\n",
    "    \n",
    "#     print(f\"Case {case + 1} completed in {case_time:.2f} seconds.\")\n",
    "#     print(f\"Results saved to {analytical_folder}\")\n",
    "\n",
    "# # Print results summary\n",
    "# print(\"\\nResults Summary:\")\n",
    "# print(\"=\" * 80)\n",
    "# summary_data = [[r[\"case\"], \n",
    "#                 str(r[\"magnitude\"]), \n",
    "#                 f\"{r['max_displacement']:.2e}\",\n",
    "#                 f\"{r['max_velocity']:.2e}\", \n",
    "#                 f\"{r['max_acceleration']:.2e}\",\n",
    "#                 f\"{r['solve_time']:.2f}\"] for r in results]\n",
    "\n",
    "# headers = [\"Case\", \"Magnitude\", \"Max Displacement\", \"Max Velocity\", \"Max Acceleration\", \"Solve Time (s)\"]\n",
    "# print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# # Print overall statistics\n",
    "# total_time = sum(case_times)\n",
    "# print(\"\\nOverall Statistics:\")\n",
    "# print(\"=\" * 80)\n",
    "# print(f\"Total computation time: {total_time:.2f} seconds\")\n",
    "# print(f\"Average time per case: {total_time/num_cases:.2f} seconds\")\n",
    "# print(f\"Number of cases: {num_cases}\")\n",
    "# print(f\"Fastest case: {min(case_times):.2f} seconds (Case {np.argmin(case_times)+1})\")\n",
    "# print(f\"Slowest case: {max(case_times):.2f} seconds (Case {np.argmax(case_times)+1})\")\n",
    "\n",
    "# print(f\"\\nAnalysis complete. Results saved in: {base_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "# === Assumed Available Variables ===\n",
    "# M_constrained, K_constrained, f_constrained, magnitudes, x\n",
    "\n",
    "s = f_constrained.shape[0]\n",
    "num_cases = f_constrained.shape[1]\n",
    "\n",
    "def constant_force_factory(F):\n",
    "    return lambda t: F\n",
    "\n",
    "# Initial velocity and identity/zero matrices\n",
    "v0 = np.zeros((s, num_cases))\n",
    "I = np.eye(s)\n",
    "Z = np.zeros((s, s))\n",
    "\n",
    "# Combined matrices for state-space formulation\n",
    "M_star = np.block([[M_constrained, Z], [Z, I]])\n",
    "K_star = np.block([[Z, K_constrained], [-I, Z]])\n",
    "M_star_inv = np.linalg.inv(M_star)\n",
    "\n",
    "# Time settings\n",
    "total_time = 1.0\n",
    "dt = 1e-4\n",
    "t_span = (0, total_time)\n",
    "t_eval = np.arange(t_span[0], t_span[1] + dt, dt)\n",
    "\n",
    "# Define the ODE system\n",
    "\n",
    "def dUdt(t, U, M_star_inv, K_star, F_star):\n",
    "    return M_star_inv @ (F_star - (K_star @ U))\n",
    "\n",
    "# Create results directory\n",
    "base_dir = Path(\"Dynamic_solution\")\n",
    "base_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Starting multi-case dynamic analysis (solve_ivp)...\")\n",
    "print(f\"M: {M_constrained.shape}, K: {K_constrained.shape}, f: {f_constrained.shape}, cases: {num_cases}\\n\")\n",
    "\n",
    "results = []\n",
    "case_times = []\n",
    "\n",
    "# Solve each case\n",
    "for case in tqdm(range(num_cases), desc=\"Solving cases\"):\n",
    "    case_start = time.time()\n",
    "    magnitude = magnitudes[case]\n",
    "    magnitude_str = \", \".join(str(val) for val in magnitude)\n",
    "\n",
    "    case_folder = base_dir / f\"case_{case+1}_magnitude_({magnitude_str})\"\n",
    "    # analytical_folder = case_folder / \"Analytical_Solution\"\n",
    "    # analytical_folder.mkdir(parents=True, exist_ok=True)\n",
    "    analytical_folder = case_folder / \"Analytical_Solution\"\n",
    "    if analytical_folder.exists() and analytical_folder.is_dir():\n",
    "        shutil.rmtree(analytical_folder)\n",
    "    analytical_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Prepare initial state and force vector\n",
    "    U0 = np.concatenate((v0[:, case], x[:, case]))\n",
    "    F_star = np.concatenate((f_constrained[:, case], np.zeros(s)))\n",
    "\n",
    "    # Solve\n",
    "    sol = solve_ivp(dUdt, t_span, U0, args=(M_star_inv, K_star, F_star),\n",
    "                    t_eval=t_eval, method='Radau', rtol=1e-8) # Radau\n",
    "\n",
    "    t = sol.t\n",
    "    U = sol.y\n",
    "    v = U[:s].T\n",
    "    u = U[s:].T\n",
    "    a = np.gradient(v, t, axis=0)\n",
    "    # a = np.zeros_like(v)\n",
    "    # a[1:] = (v[1:] - v[:-1]) / dt\n",
    "    # a[0] = a[1]  # or zero\n",
    "    # Compute internal force F = M * a + K * u\n",
    "    f_internal = np.zeros_like(u)\n",
    "    for i in range(len(t)):\n",
    "        f_internal[i, :] = M_constrained @ a[i, :] + K_constrained @ u[i, :]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # for i in range(len(t)):\n",
    "    #     a[i,:] = (v[i,:] + v[i+1,:]) / dt\n",
    "\n",
    "    # Calculate acceleration using a = M^{-1} (F - K*u)\n",
    "    # a = np.zeros_like(u)\n",
    "    # for i in range(len(t)):\n",
    "    #     F_t = f_constrained[:, case]  # constant force\n",
    "    #     a[i, :] = np.linalg.solve(M_constrained, F_t - K_constrained @ u[i, :])\n",
    "    #  Compute acceleration at each time step (using precomputed MK_product)\n",
    "    # acceleration = np.array([np.linalg.solve(M, F - K @ displacement[:, i]) for i in range(len(time_steps))])\n",
    "\n",
    "\n",
    "    # np.save(analytical_folder / 'time_analytical.npy', t)\n",
    "    # np.save(analytical_folder / 'displacement_analytical.npy', u)\n",
    "    # np.save(analytical_folder / 'velocity_analytical.npy', v)\n",
    "    # np.save(analytical_folder / 'acceleration_analytical.npy', a)\n",
    "\n",
    "    # Save solution\n",
    "    np.save(analytical_folder / 'time_analytical.npy', t)\n",
    "    np.save(analytical_folder / 'displacement_analytical.npy', u)\n",
    "    np.save(analytical_folder / 'velocity_analytical.npy', v)\n",
    "    np.save(analytical_folder / 'acceleration_analytical.npy', a)\n",
    "    np.save(analytical_folder / 'force_analytical.npy', f_internal)\n",
    "\n",
    "    case_time = time.time() - case_start\n",
    "    case_times.append(case_time)\n",
    "\n",
    "    results.append({\n",
    "        \"case\": case + 1,\n",
    "        \"magnitude\": magnitude,\n",
    "        \"max_displacement\": np.max(np.abs(u)),\n",
    "        \"max_velocity\": np.max(np.abs(v)),\n",
    "        \"max_acceleration\": np.max(np.abs(a)),\n",
    "        \"solve_time\": case_time\n",
    "    })\n",
    "\n",
    "# Results summary\n",
    "print(\"\\nResults Summary:\")\n",
    "print(\"=\" * 80)\n",
    "summary_data = [[r[\"case\"], str(r[\"magnitude\"]),\n",
    "                 f\"{r['max_displacement']:.2e}\",\n",
    "                 f\"{r['max_velocity']:.2e}\",\n",
    "                 f\"{r['max_acceleration']:.2e}\",\n",
    "                 f\"{r['solve_time']:.2f}\"] for r in results]\n",
    "headers = [\"Case\", \"Magnitude\", \"Max Displacement\", \"Max Velocity\", \"Max Acceleration\", \"Solve Time (s)\"]\n",
    "print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Overall statistics\n",
    "total_runtime = sum(case_times)\n",
    "print(\"\\nOverall Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total computation time: {total_runtime:.2f} seconds\")\n",
    "print(f\"Average time per case: {total_runtime / num_cases:.2f} seconds\")\n",
    "print(f\"Fastest case: {min(case_times):.2f} seconds (Case {np.argmin(case_times)+1})\")\n",
    "print(f\"Slowest case: {max(case_times):.2f} seconds (Case {np.argmax(case_times)+1})\")\n",
    "\n",
    "print(f\"\\nAnalysis complete. Results saved in: {base_dir.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def plot_node_comparison(mdpa_file, node_ids, case_results, analytical_folder, scale_factor=1e6):\n",
    "    \"\"\"\n",
    "    Plot displacement, velocity, and acceleration vs. time for specified nodes.\n",
    "    Compare Newmark and analytical solutions.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    mdpa_file: str, path to the .mdpa file containing mesh information.\n",
    "    node_ids: list of int, node IDs to analyze.\n",
    "    case_results: dict, results from Newmark method.\n",
    "    analytical_folder: Path, folder containing analytical solution data.\n",
    "    scale_factor: float, scaling factor for displacements.\n",
    "    \"\"\"\n",
    "    # Read mesh information from the .mdpa file\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    node_coords.append([int(parts[0]), float(parts[1]), float(parts[2])])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "                    elements.append([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "\n",
    "    # Load analytical solution data\n",
    "    time_analytical = np.load(analytical_folder / 'time_analytical.npy')\n",
    "    displacement_analytical = np.load(analytical_folder / 'displacement_analytical.npy')\n",
    "    velocity_analytical = np.load(analytical_folder / 'velocity_analytical.npy')\n",
    "    acceleration_analytical = np.load(analytical_folder / 'acceleration_analytical.npy')\n",
    "\n",
    "    # Extract Newmark solution data\n",
    "    time_newmark = case_results['time']\n",
    "    displacement_newmark = case_results['displacement']\n",
    "    velocity_newmark = case_results['velocity']\n",
    "    acceleration_newmark = case_results['acceleration']\n",
    "\n",
    "    # Highlight nodes and plot graphs\n",
    "    for node_id in node_ids:\n",
    "        # Find the node in the mesh\n",
    "        selected_node = node_coords[node_coords[:, 0] == node_id][0]\n",
    "        node_x, node_y = selected_node[1], selected_node[2]\n",
    "        idx = np.where(node_coords[:, 0] == node_id)[0][0]\n",
    "\n",
    "        # Highlight the node on the mesh\n",
    "        triangulation = tri.Triangulation(node_coords[:, 1], node_coords[:, 2], elements)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.triplot(triangulation, 'k-', lw=0.5, alpha=0.5)\n",
    "        plt.scatter(node_x, node_y, color='red', label=f'Selected Node {node_id}')\n",
    "        plt.gca().add_artist(plt.Circle((node_x, node_y), radius=0.1, color='red', fill=False))\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.title(f'Mesh with Highlighted Node {node_id}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.axis('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot displacement vs. time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_newmark, displacement_newmark[:, idx], label='Newmark Method', color='blue')\n",
    "        plt.plot(time_analytical, displacement_analytical[:, idx], label='Analytical Solution', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Displacement (m)')\n",
    "        plt.title(f'Displacement vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot velocity vs. time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_newmark, velocity_newmark[:, idx], label='Newmark Method', color='blue')\n",
    "        plt.plot(time_analytical, velocity_analytical[:, idx], label='Analytical Solution', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Velocity (m/s)')\n",
    "        plt.title(f'Velocity vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot acceleration vs. time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_newmark, acceleration_newmark[:, idx], label='Newmark Method', color='blue')\n",
    "        plt.plot(time_analytical, acceleration_analytical[:, idx], label='Analytical Solution', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Acceleration (m/s²)')\n",
    "        plt.title(f'Acceleration vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "node_ids_to_analyze = [1, 154, 305]  # Replace with desired node IDs\n",
    "plot_node_comparison(mdpa_file, node_ids_to_analyze, case_results[0], Path(\"Dynamic_solution/case_1_magnitude_(194.29, -232.93, 344.83)/Analytical_Solution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "# === Assumed Available Variables ===\n",
    "# M_constrained, K_constrained, f_constrained, magnitudes, x\n",
    "\n",
    "s = f_constrained.shape[0]\n",
    "num_cases = f_constrained.shape[1]\n",
    "\n",
    "def constant_force_factory(F):\n",
    "    return lambda t: F\n",
    "\n",
    "# Initial velocity and identity/zero matrices\n",
    "v0 = np.zeros((s, num_cases))\n",
    "I = np.eye(s)\n",
    "Z = np.zeros((s, s))\n",
    "\n",
    "# Combined matrices for state-space formulation\n",
    "M_star = np.block([[M_constrained, Z], [Z, I]])\n",
    "K_star = np.block([[Z, K_constrained], [-I, Z]])\n",
    "M_star_inv = np.linalg.inv(M_star)\n",
    "\n",
    "# Time settings\n",
    "total_time = 1.0\n",
    "dt = 1e-4\n",
    "t_span = (0, total_time)\n",
    "t_eval = np.arange(t_span[0], t_span[1] + dt, dt)\n",
    "\n",
    "# Define the ODE system\n",
    "\n",
    "def dUdt(t, U, M_star_inv, K_star, F_star):\n",
    "    return M_star_inv @ (F_star - (K_star @ U))\n",
    "\n",
    "# Create results directory\n",
    "base_dir = Path(\"Dynamic_solution\")\n",
    "base_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Starting multi-case dynamic analysis (solve_ivp)...\")\n",
    "print(f\"M: {M_constrained.shape}, K: {K_constrained.shape}, f: {f_constrained.shape}, cases: {num_cases}\\n\")\n",
    "\n",
    "results = []\n",
    "case_times = []\n",
    "\n",
    "# Solve each case\n",
    "for case in tqdm(range(num_cases), desc=\"Solving cases\"):\n",
    "    case_start = time.time()\n",
    "    magnitude = magnitudes[case]\n",
    "    magnitude_str = \", \".join(str(val) for val in magnitude)\n",
    "\n",
    "    case_folder = base_dir / f\"case_{case+1}_magnitude_({magnitude_str})\"\n",
    "    # analytical_folder = case_folder / \"Analytical_Solution\"\n",
    "    # analytical_folder.mkdir(parents=True, exist_ok=True)\n",
    "    analytical_folder = case_folder / \"Analytical_Solution\"\n",
    "    if analytical_folder.exists() and analytical_folder.is_dir():\n",
    "        shutil.rmtree(analytical_folder)\n",
    "    analytical_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Prepare initial state and force vector\n",
    "    U0 = np.concatenate((v0[:, case], x[:, case]))\n",
    "    F_star = np.concatenate((f_constrained[:, case], np.zeros(s)))\n",
    "\n",
    "    # Solve\n",
    "    sol = solve_ivp(dUdt, t_span, U0, args=(M_star_inv, K_star, F_star),\n",
    "                    t_eval=t_eval, method='Radau', rtol=1e-8) # Radau\n",
    "\n",
    "    t = sol.t\n",
    "    U = sol.y\n",
    "    v = U[:s].T\n",
    "    u = U[s:].T\n",
    "    # a = np.gradient(v, t, axis=0)\n",
    "    a = np.zeros_like(v)\n",
    "    a[1:] = (v[1:] - v[:-1]) / dt\n",
    "    a[0] = a[1]  # or zero\n",
    "    # Compute internal force F = M * a + K * u\n",
    "    f_internal = np.zeros_like(u)\n",
    "    for i in range(len(t)):\n",
    "        f_internal[i, :] = M_constrained @ a[i, :] + K_constrained @ u[i, :]\n",
    "\n",
    "\n",
    "    # np.save(analytical_folder / 'time_analytical.npy', t)\n",
    "    # np.save(analytical_folder / 'displacement_analytical.npy', u)\n",
    "    # np.save(analytical_folder / 'velocity_analytical.npy', v)\n",
    "    # np.save(analytical_folder / 'acceleration_analytical.npy', a)\n",
    "    # Save solution\n",
    "    np.save(analytical_folder / 'time_analytical.npy', t)\n",
    "    np.save(analytical_folder / 'displacement_analytical.npy', u)\n",
    "    np.save(analytical_folder / 'velocity_analytical.npy', v)\n",
    "    np.save(analytical_folder / 'acceleration_analytical.npy', a)\n",
    "    np.save(analytical_folder / 'force_analytical.npy', f_internal)\n",
    "\n",
    "    case_time = time.time() - case_start\n",
    "    case_times.append(case_time)\n",
    "\n",
    "    results.append({\n",
    "        \"case\": case + 1,\n",
    "        \"magnitude\": magnitude,\n",
    "        \"max_displacement\": np.max(np.abs(u)),\n",
    "        \"max_velocity\": np.max(np.abs(v)),\n",
    "        \"max_acceleration\": np.max(np.abs(a)),\n",
    "        \"solve_time\": case_time\n",
    "    })\n",
    "\n",
    "# Results summary\n",
    "print(\"\\nResults Summary:\")\n",
    "print(\"=\" * 80)\n",
    "summary_data = [[r[\"case\"], str(r[\"magnitude\"]),\n",
    "                 f\"{r['max_displacement']:.2e}\",\n",
    "                 f\"{r['max_velocity']:.2e}\",\n",
    "                 f\"{r['max_acceleration']:.2e}\",\n",
    "                 f\"{r['solve_time']:.2f}\"] for r in results]\n",
    "headers = [\"Case\", \"Magnitude\", \"Max Displacement\", \"Max Velocity\", \"Max Acceleration\", \"Solve Time (s)\"]\n",
    "print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Overall statistics\n",
    "total_runtime = sum(case_times)\n",
    "print(\"\\nOverall Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total computation time: {total_runtime:.2f} seconds\")\n",
    "print(f\"Average time per case: {total_runtime / num_cases:.2f} seconds\")\n",
    "print(f\"Fastest case: {min(case_times):.2f} seconds (Case {np.argmin(case_times)+1})\")\n",
    "print(f\"Slowest case: {max(case_times):.2f} seconds (Case {np.argmax(case_times)+1})\")\n",
    "\n",
    "print(f\"\\nAnalysis complete. Results saved in: {base_dir.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_values = np.diff(sol.t)\n",
    "dt_avg = np.mean(dt_values)\n",
    "dt_median = np.median(dt_values)\n",
    "print(\"Average time step:\", dt_avg)\n",
    "print(\"Median time step:\", dt_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def plot_node_comparison(mdpa_file, node_ids, case_results, analytical_folder, scale_factor=1e6):\n",
    "    \"\"\"\n",
    "    Plot displacement, velocity, and acceleration vs. time for specified nodes.\n",
    "    Compare Newmark and analytical solutions.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    mdpa_file: str, path to the .mdpa file containing mesh information.\n",
    "    node_ids: list of int, node IDs to analyze.\n",
    "    case_results: dict, results from Newmark method.\n",
    "    analytical_folder: Path, folder containing analytical solution data.\n",
    "    scale_factor: float, scaling factor for displacements.\n",
    "    \"\"\"\n",
    "    # Read mesh information from the .mdpa file\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    node_coords.append([int(parts[0]), float(parts[1]), float(parts[2])])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "                    elements.append([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "\n",
    "    # Load analytical solution data\n",
    "    time_analytical = np.load(analytical_folder / 'time_analytical.npy')\n",
    "    displacement_analytical = np.load(analytical_folder / 'displacement_analytical.npy')\n",
    "    velocity_analytical = np.load(analytical_folder / 'velocity_analytical.npy')\n",
    "    acceleration_analytical = np.load(analytical_folder / 'acceleration_analytical.npy')\n",
    "\n",
    "    # Extract Newmark solution data\n",
    "    time_newmark = case_results['time']\n",
    "    displacement_newmark = case_results['displacement']\n",
    "    velocity_newmark = case_results['velocity']\n",
    "    acceleration_newmark = case_results['acceleration']\n",
    "\n",
    "    # Highlight nodes and plot graphs\n",
    "    for node_id in node_ids:\n",
    "        # Find the node in the mesh\n",
    "        selected_node = node_coords[node_coords[:, 0] == node_id][0]\n",
    "        node_x, node_y = selected_node[1], selected_node[2]\n",
    "        idx = np.where(node_coords[:, 0] == node_id)[0][0]\n",
    "\n",
    "        # Highlight the node on the mesh\n",
    "        triangulation = tri.Triangulation(node_coords[:, 1], node_coords[:, 2], elements)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.triplot(triangulation, 'k-', lw=0.5, alpha=0.5)\n",
    "        plt.scatter(node_x, node_y, color='red', label=f'Selected Node {node_id}')\n",
    "        plt.gca().add_artist(plt.Circle((node_x, node_y), radius=0.1, color='red', fill=False))\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.title(f'Mesh with Highlighted Node {node_id}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.axis('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot displacement vs. time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_newmark, displacement_newmark[:, idx], label='Newmark Method', color='blue')\n",
    "        plt.plot(time_analytical, displacement_analytical[:, idx], label='Analytical Solution', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Displacement (m)')\n",
    "        plt.title(f'Displacement vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot velocity vs. time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_newmark, velocity_newmark[:, idx], label='Newmark Method', color='blue')\n",
    "        plt.plot(time_analytical, velocity_analytical[:, idx], label='Analytical Solution', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Velocity (m/s)')\n",
    "        plt.title(f'Velocity vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot acceleration vs. time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_newmark, acceleration_newmark[:, idx], label='Newmark Method', color='blue')\n",
    "        plt.plot(time_analytical, acceleration_analytical[:, idx], label='Analytical Solution', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Acceleration (m/s²)')\n",
    "        plt.title(f'Acceleration vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "node_ids_to_analyze = [1, 154, 305]  # Replace with desired node IDs\n",
    "plot_node_comparison(mdpa_file, node_ids_to_analyze, case_results[0], Path(\"Dynamic_solution/case_1_magnitude_(194.29, -232.93, 344.83)/Analytical_Solution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def create_displacement_gif(folder_path, mdpa_file, scale_factor=1e6, step_interval=100):\n",
    "    \"\"\"\n",
    "    Create a displacement GIF for a specific case.\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    output_file = folder_path / 'displacement_animation.gif'\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"🎯 Processing folder: {folder_path.resolve()}\")\n",
    "\n",
    "    # Load solution data\n",
    "    time_file = folder_path / 'time_analytical.npy'\n",
    "    displacement_file = folder_path / 'displacement_analytical.npy'\n",
    "    print(f\"📥 Reading displacement data from:\")\n",
    "    print(f\"   ⏱️  Time data       : {time_file.resolve()}\")\n",
    "    print(f\"   📌 Displacement data: {displacement_file.resolve()}\")\n",
    "\n",
    "    time = np.load(time_file)\n",
    "    displacement = np.load(displacement_file)\n",
    "\n",
    "    # Read node coordinates and elements from the .mdpa file\n",
    "    print(f\"📄 Reading mesh connectivity from: {mdpa_file.resolve()}\")\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    x, y = float(parts[1]), float(parts[2])\n",
    "                    node_coords.append([x, y])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "                    elements.append([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 15))\n",
    "\n",
    "    # Base triangulation\n",
    "    x = node_coords[:, 0]\n",
    "    y = node_coords[:, 1]\n",
    "    triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "\n",
    "    # Global displacement limits\n",
    "    disp_magnitudes = []\n",
    "    for step in range(len(time)):\n",
    "        disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "        disp_magnitudes.append(disp_mag)\n",
    "\n",
    "    global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "    global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "    print(f\"📊 Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "        disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "        deformed_coords = node_coords + disp\n",
    "\n",
    "        # Undeformed\n",
    "        ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "\n",
    "        # Deformed mesh\n",
    "        triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "        tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                           vmin=global_min, vmax=global_max)\n",
    "        ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "        ax.grid(True)\n",
    "        ax.axis('equal')\n",
    "        ax.legend()\n",
    "\n",
    "        if frame == 0:\n",
    "            plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    print(\"🛠️  Creating animation frames...\")\n",
    "    anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "\n",
    "    # Save animation\n",
    "    print(f\"💾 Saving animation to: {output_file.resolve()}\")\n",
    "    writer = PillowWriter(fps=1000 / step_interval)\n",
    "    anim.save(output_file, writer=writer)\n",
    "    plt.close()\n",
    "    print(\"✅ Animation complete!\\n\")\n",
    "\n",
    "# Run for all results\n",
    "for case in results:\n",
    "    folder_path = f\"Dynamic_solution/case_{case['case']}_magnitude_({', '.join(map(str, case['magnitude']))})/Analytical_Solution\"\n",
    "    create_displacement_gif(folder_path, mdpa_file, scale_factor=1e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def save_displacement_frames(folder_path, mdpa_file, scale_factor=1e6):\n",
    "    \"\"\"\n",
    "    Save displacement screenshots for each time step as .png images.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    folder_path: str or Path, path to the folder containing displacement and time data.\n",
    "    mdpa_file: Path, path to the .mdpa file with mesh info.\n",
    "    scale_factor: float, scale applied to displacement values.\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    frame_output_dir = folder_path / 'displacement_frames'\n",
    "    frame_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"📂 Processing folder: {folder_path.resolve()}\")\n",
    "\n",
    "    # Load displacement and time data\n",
    "    time_file = folder_path / 'time_analytical.npy'\n",
    "    displacement_file = folder_path / 'displacement_analytical.npy'\n",
    "    print(f\"📥 Loading:\")\n",
    "    print(f\"   ⏱️  Time:        {time_file.resolve()}\")\n",
    "    print(f\"   📌 Displacement: {displacement_file.resolve()}\")\n",
    "\n",
    "    time = np.load(time_file)\n",
    "    displacement = np.load(displacement_file)\n",
    "\n",
    "    # Load mesh from .mdpa file\n",
    "    print(f\"📄 Reading mesh from: {mdpa_file.resolve()}\")\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    x, y = float(parts[1]), float(parts[2])\n",
    "                    node_coords.append([x, y])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "                    elements.append([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "\n",
    "    # Base mesh\n",
    "    triangulation_orig = tri.Triangulation(node_coords[:, 0], node_coords[:, 1], elements)\n",
    "\n",
    "    # Displacement range for consistent colorbar\n",
    "    disp_magnitudes = []\n",
    "    for step in range(len(time)):\n",
    "        disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "        disp_magnitudes.append(disp_mag)\n",
    "\n",
    "    global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "    global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "\n",
    "    print(f\"📊 Displacement magnitude range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "    print(f\"📸 Saving frames to: {frame_output_dir.resolve()}\\n\")\n",
    "\n",
    "    # Plot and save each frame\n",
    "    for frame in range(len(time)):\n",
    "        fig, ax = plt.subplots(figsize=(10, 15))\n",
    "        disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "        deformed_coords = node_coords + disp\n",
    "\n",
    "        triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "\n",
    "        ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "        tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                           vmin=global_min, vmax=global_max)\n",
    "        ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "        ax.axis('equal')\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the figure\n",
    "        frame_path = frame_output_dir / f\"frame_{frame:04d}.png\"\n",
    "        plt.savefig(frame_path)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Saved: {frame_path.name}\")\n",
    "\n",
    "    print(\"\\n🎉 All displacement frames saved successfully!\\n\")\n",
    "\n",
    "# Run for all results\n",
    "for case in results:\n",
    "    folder_path = f\"Dynamic_solution/case_{case['case']}_magnitude_({', '.join(map(str, case['magnitude']))})/Analytical_Solution\"\n",
    "    save_displacement_frames(folder_path, mdpa_file, scale_factor=1e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# First, clean up memory\n",
    "gc.collect()\n",
    "\n",
    "# Then clear all variables\n",
    "locals().clear()\n",
    "\n",
    "print(\"🧼 All variables cleared. Memory fully released.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "\n",
    "# def read_and_organize_displacement(base_dir=\"Dynamic_solution\"):\n",
    "#     \"\"\"\n",
    "#     Read displacement data from the Numerical_Solution folder of each case and organize it for SCD calculation.\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     base_dir: str, path to the base directory containing case folders.\n",
    "\n",
    "#     Returns:\n",
    "#     --------\n",
    "#     organized_data: dict, organized displacement data for each case.\n",
    "#     \"\"\"\n",
    "#     base_path = Path(base_dir)\n",
    "#     case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "\n",
    "#     organized_data = {}\n",
    "\n",
    "#     for case_folder in case_folders:\n",
    "#         try:\n",
    "#             # Extract case number and magnitude from folder name\n",
    "#             case_name = case_folder.name\n",
    "#             case_number = int(case_name.split(\"_\")[1])\n",
    "#             magnitude = tuple(map(float, case_name.split(\"_magnitude_\")[1].strip(\"()\").split(\", \")))\n",
    "\n",
    "#             # Path to displacement file\n",
    "#             displacement_file = case_folder / \"Numerical_Solution\" / \"solution\" / \"displacement.npy\"\n",
    "\n",
    "#             if displacement_file.exists():\n",
    "#                 # Load displacement data\n",
    "#                 displacement_data = np.load(displacement_file)\n",
    "\n",
    "#                 # Organize data\n",
    "#                 organized_data[case_number] = {\n",
    "#                     \"magnitude\": magnitude,\n",
    "#                     \"displacement\": displacement_data\n",
    "#                 }\n",
    "#                 print(f\"✅ Successfully loaded displacement data for Case {case_number}\")\n",
    "#             else:\n",
    "#                 print(f\"❌ Displacement file not found for Case {case_number}\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"❌ Error processing {case_folder.name}: {str(e)}\")\n",
    "\n",
    "#     return organized_data\n",
    "\n",
    "# # Example usage\n",
    "# # Initialize an empty list to store displacement data\n",
    "# displacement_list = []\n",
    "\n",
    "# # Read and concatenate displacement data for all cases\n",
    "# organized_data = read_and_organize_displacement()\n",
    "# for case_number in sorted(organized_data.keys()):\n",
    "#     displacement_list.append(organized_data[case_number]['displacement'].T)  # Transpose to align DOF as rows\n",
    "\n",
    "# # Concatenate along the time axis\n",
    "# organized_displacement_data = np.hstack(displacement_list)\n",
    "\n",
    "# print(\"📂 Displacement data organized successfully.\")\n",
    "# print(f\"📊 Total cases processed: {len(organized_data)}\")\n",
    "# print(f\"📐 Final displacement data shape: {organized_displacement_data.shape}\")\n",
    "# print(\"📂 Displacement data organized successfully.\")\n",
    "# print(f\"📊 Total cases processed: {len(organized_displacement_data)}\")\n",
    "# print(organized_displacement_data.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def read_and_organize_data(base_dir, variable_name):\n",
    "    \"\"\"\n",
    "    Read and organize data (displacement, velocity, acceleration, or force) from the Numerical_Solution folder of each case.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_dir: str, path to the base directory containing case folders.\n",
    "    variable_name: str, name of the variable to read (e.g., 'displacement', 'velocity', 'acceleration', 'force').\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    organized_data: dict, organized data for each case.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "\n",
    "    organized_data = {}\n",
    "\n",
    "    for case_folder in case_folders:\n",
    "        try:\n",
    "            # Extract case number and magnitude from folder name\n",
    "            case_name = case_folder.name\n",
    "            case_number = int(case_name.split(\"_\")[1])\n",
    "            magnitude = tuple(map(float, case_name.split(\"_magnitude_\")[1].strip(\"()\").split(\", \")))\n",
    "\n",
    "            # Path to the variable file\n",
    "            variable_file = case_folder / \"Numerical_Solution\" / \"solution\" / f\"{variable_name}.npy\"\n",
    "\n",
    "            if variable_file.exists():\n",
    "                # Load variable data\n",
    "                variable_data = np.load(variable_file)\n",
    "\n",
    "                # Organize data\n",
    "                organized_data[case_number] = {\n",
    "                    \"magnitude\": magnitude,\n",
    "                    variable_name: variable_data\n",
    "                }\n",
    "                print(f\"✅ Successfully loaded {variable_name} data for Case {case_number}\")\n",
    "            else:\n",
    "                print(f\"❌ {variable_name.capitalize()} file not found for Case {case_number}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {case_folder.name}: {str(e)}\")\n",
    "\n",
    "    return organized_data\n",
    "\n",
    "# Example usage\n",
    "base_dir = \"Dynamic_solution\"\n",
    "\n",
    "# Initialize lists to store data for all cases\n",
    "displacement_list = []\n",
    "velocity_list = []\n",
    "acceleration_list = []\n",
    "force_list = []\n",
    "\n",
    "# Read and concatenate data for all variables\n",
    "for variable_name, data_list in zip(\n",
    "    [\"displacement\", \"velocity\", \"acceleration\", \"force\"],\n",
    "    [displacement_list, velocity_list, acceleration_list, force_list]\n",
    "):\n",
    "    organized_data = read_and_organize_data(base_dir, variable_name)\n",
    "    for case_number in sorted(organized_data.keys()):\n",
    "        data_list.append(organized_data[case_number][variable_name].T)  # Transpose to align DOF as rows\n",
    "\n",
    "    # Concatenate along the time axis if data_list is not empty\n",
    "    if data_list:\n",
    "        globals()[f\"organized_{variable_name}_data\"] = np.hstack(data_list)\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: No data found for variable '{variable_name}'.\")\n",
    "        globals()[f\"organized_{variable_name}_data\"] = np.array([])  # Create an empty array for consistency\n",
    "\n",
    "# Print summary\n",
    "print(\"📂 Data organized successfully.\")\n",
    "print(f\"📊 Total cases processed: {len(organized_data)}\")\n",
    "print(f\"📐 Final displacement data shape: {organized_displacement_data.shape}\")\n",
    "print(f\"📐 Final velocity data shape: {organized_velocity_data.shape}\")\n",
    "print(f\"📐 Final acceleration data shape: {organized_acceleration_data.shape}\")\n",
    "print(f\"📐 Final force data shape: {organized_force_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "def perform_complete_svd_analysis(displacement_matrix, energy_threshold=0.999, sv_threshold=1e-19):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" COMPLETE SVD AND REDUCED BASIS ANALYSIS \".center(80))\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Perform SVD\n",
    "    U, S, VT = np.linalg.svd(displacement_matrix, full_matrices=False)\n",
    "    num_modes = len(S)\n",
    "    cum_energy = np.cumsum(S) / np.sum(S)\n",
    "\n",
    "    # Reduced basis computation\n",
    "    r_energy = np.argmax(cum_energy >= energy_threshold) + 1 if any(cum_energy >= energy_threshold) else num_modes\n",
    "    r_threshold = np.sum(S >= sv_threshold)\n",
    "    final_rank = min(r_energy, r_threshold)\n",
    "    V_r = U[:, :final_rank]\n",
    "\n",
    "    results = {\n",
    "        'U': U,\n",
    "        'S': S,\n",
    "        'VT': VT,\n",
    "        'cumulative_energy': cum_energy,\n",
    "        'matrix_shape': displacement_matrix.shape,\n",
    "        'rank': np.linalg.matrix_rank(displacement_matrix),\n",
    "        'condition_number': np.max(S)/np.min(S) if np.min(S) > 0 else np.inf,\n",
    "        'effective_rank': np.sum(S > 1e-10 * S[0]),\n",
    "        'num_modes': num_modes,\n",
    "        'energy_threshold': energy_threshold,\n",
    "        'sv_threshold': sv_threshold,\n",
    "        'r_energy': r_energy,\n",
    "        'r_threshold': r_threshold,\n",
    "        'final_rank': final_rank,\n",
    "        'V_r': V_r,\n",
    "        'dimensionality_reduction': 100*(1 - final_rank/displacement_matrix.shape[0])\n",
    "    }\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.semilogy(S, 'b-', linewidth=2, marker='o', markersize=5)\n",
    "    plt.title(\"Singular Values (Log Scale)\", fontsize=12)\n",
    "    plt.xlabel(\"Mode Number\")\n",
    "    plt.ylabel(\"Singular Value (\\u03c3)\")\n",
    "    plt.grid(True, which=\"both\", linestyle='--', alpha=0.5)\n",
    "    plt.axhline(y=sv_threshold, color='r', linestyle='--', label=f'Threshold ({sv_threshold:.1e})')\n",
    "    plt.axvline(x=final_rank, color='g', linestyle=':', label=f'Selected rank ({final_rank})')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(cum_energy, 'g-', linewidth=2, marker='s', markersize=5)\n",
    "    plt.title(\"Cumulative Energy\", fontsize=12)\n",
    "    plt.xlabel(\"Mode Number\")\n",
    "    plt.ylabel(\"Fraction of Total Energy\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.axhline(y=energy_threshold, color='r', linestyle='--', label=f'{energy_threshold*100:.1f}% threshold')\n",
    "    plt.axvline(x=final_rank, color='g', linestyle=':', label=f'Selected rank ({final_rank})')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for i in range(min(3, final_rank)):\n",
    "        plt.plot(V_r[:50, i], label=f'Basis {i+1}')\n",
    "    plt.title(\"First 3 Basis Vectors (First 50 elements)\", fontsize=12)\n",
    "    plt.xlabel(\"Degree of Freedom\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Text output\n",
    "    print(f\"\\n{' MATRIX PROPERTIES ':-^80}\")\n",
    "    print(f\"{'Shape:':<25} {displacement_matrix.shape} (DOFs × snapshots)\")\n",
    "    print(f\"{'Numerical rank:':<25} {results['rank']}\")\n",
    "    print(f\"{'Condition number:':<25} {results['condition_number']:.2e}\")\n",
    "    print(f\"{'Effective rank (1e-10):':<25} {results['effective_rank']}\")\n",
    "\n",
    "    print(f\"\\n{' REDUCED BASIS SELECTION ':-^80}\")\n",
    "    print(f\"{'Energy threshold:':<25} {energy_threshold:.3f} ({(energy_threshold*100):.1f}%)\")\n",
    "    print(f\"{'SV threshold:':<25} {sv_threshold:.1e}\")\n",
    "    print(f\"{'Rank by energy:':<25} {r_energy} (captures {cum_energy[r_energy-1]*100:.2f}% energy)\")\n",
    "    print(f\"{'Rank by SV threshold:':<25} {r_threshold}\")\n",
    "    print(f\"{'Final selected rank:':<25} {final_rank}\")\n",
    "    print(f\"{'Dimensionality reduction:':<25} {results['dimensionality_reduction']:.1f}% ({displacement_matrix.shape[0]} → {final_rank})\")\n",
    "\n",
    "    print(f\"\\n{' MODE ANALYSIS ':-^80}\")\n",
    "    print(tabulate([\n",
    "        [\"1\", f\"{S[0]:.3e}\", f\"{cum_energy[0]*100:.2f}%\"],\n",
    "        [\"2\", f\"{S[1]:.3e}\", f\"{cum_energy[1]*100:.2f}%\"],\n",
    "        [\"3\", f\"{S[2]:.3e}\", f\"{cum_energy[2]*100:.2f}%\"],\n",
    "        [\"...\", \"...\", \"...\"],\n",
    "        [str(final_rank), f\"{S[final_rank-1]:.3e}\", f\"{cum_energy[final_rank-1]*100:.2f}%\"],\n",
    "        [\"Full\", f\"{S[-1]:.3e}\", \"100.00%\"]\n",
    "    ], headers=[\"Mode\", \"Singular Value\", \"Cumulative Energy\"], tablefmt=\"grid\"))\n",
    "\n",
    "    print(f\"\\n{' REDUCED BASIS PROPERTIES ':-^80}\")\n",
    "    print(f\"{'Shape:':<25} {V_r.shape} (DOFs × modes)\")\n",
    "    print(f\"{'Orthogonality check:':<25} Max off-diagonal: {np.max(np.abs(V_r.T @ V_r - np.eye(final_rank))):.2e}\")\n",
    "    print(\"\\nFirst 5 elements of first 3 basis vectors:\")\n",
    "    for i in range(min(3, final_rank)):\n",
    "        print(f\"Basis {i+1}: {np.array2string(V_r[:5, i], precision=3, separator=', ')}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "if 'organized_displacement_data' in globals() and organized_displacement_data.size > 0:\n",
    "    analysis_results = perform_complete_svd_analysis(\n",
    "        displacement_matrix=organized_displacement_data,\n",
    "        energy_threshold=0.999,\n",
    "        sv_threshold=1e-19\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nNo displacement data found for SVD analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_r = analysis_results['V_r']\n",
    "print(f\"\\n{' V_r (Reduced Basis) ':-^80}\")\n",
    "print(f\"Shape: {V_r.shape} (DOFs × modes)\")\n",
    "# print(V_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Ensure organized data and V_r from previous SVD are available\n",
    "assert 'organized_displacement_data' in globals()\n",
    "assert 'organized_velocity_data' in globals()\n",
    "assert 'organized_acceleration_data' in globals()\n",
    "assert 'organized_force_data' in globals()\n",
    "assert 'V_r' in globals()\n",
    "\n",
    "print(f\"\\n{' V_r (Reduced Basis) ':-^80}\")\n",
    "print(f\"Shape: {V_r.shape} (DOFs × modes)\")\n",
    "\n",
    "# Function to project and reconstruct a matrix\n",
    "\n",
    "def project_and_reconstruct(matrix, V_r, label=\"\"):\n",
    "    original_shape = matrix.shape\n",
    "    projected = V_r.T @ matrix\n",
    "    reconstructed = V_r @ projected\n",
    "    error = np.linalg.norm(matrix - reconstructed) / np.linalg.norm(matrix)\n",
    "    error_percent = error * 100\n",
    "\n",
    "    print(f\"\\n{' ' + label + ' RECONSTRUCTION DETAILS ':=^80}\")\n",
    "    print(f\"Original shape      : {original_shape}\")\n",
    "    print(f\"Reduced shape       : {projected.shape}\")\n",
    "    print(f\"Reconstructed shape : {reconstructed.shape}\")\n",
    "    print(f\"Reconstruction error: {error:.3e}\")\n",
    "    print(f\"Percentage error    : {error_percent:.3f}%\")\n",
    "\n",
    "    return projected, reconstructed, error\n",
    "\n",
    "# Apply to each variable\n",
    "projected_displacement, reconstructed_displacement, err_disp = project_and_reconstruct(\n",
    "    organized_displacement_data, V_r, label=\"Displacement\"\n",
    ")\n",
    "\n",
    "projected_velocity, reconstructed_velocity, err_vel = project_and_reconstruct(\n",
    "    organized_velocity_data, V_r, label=\"Velocity\"\n",
    ")\n",
    "\n",
    "projected_acceleration, reconstructed_acceleration, err_acc = project_and_reconstruct(\n",
    "    organized_acceleration_data, V_r, label=\"Acceleration\"\n",
    ")\n",
    "\n",
    "projected_force, reconstructed_force, err_force = project_and_reconstruct(\n",
    "    organized_force_data, V_r, label=\"Force\"\n",
    ")\n",
    "\n",
    "# Collect all errors into a dictionary for summary\n",
    "reconstruction_errors = {\n",
    "    \"Displacement\": err_disp,\n",
    "    \"Velocity\": err_vel,\n",
    "    \"Acceleration\": err_acc,\n",
    "    \"Force\": err_force\n",
    "}\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" RECONSTRUCTION ERROR SUMMARY \".center(80))\n",
    "print(\"=\"*80)\n",
    "for var, err in reconstruction_errors.items():\n",
    "    print(f\"{var:<20}: {err:.3e} ({err * 100:.3f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For analytical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def read_and_organize_data(base_dir, variable_name):\n",
    "    \"\"\"\n",
    "    Read and organize data (displacement, velocity, acceleration, or force) from the Numerical_Solution folder of each case.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_dir: str, path to the base directory containing case folders.\n",
    "    variable_name: str, name of the variable to read (e.g., 'displacement', 'velocity', 'acceleration', 'force').\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    organized_data: dict, organized data for each case.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "\n",
    "    organized_data = {}\n",
    "\n",
    "    for case_folder in case_folders:\n",
    "        try:\n",
    "            # Extract case number and magnitude from folder name\n",
    "            case_name = case_folder.name\n",
    "            case_number = int(case_name.split(\"_\")[1])\n",
    "            magnitude = tuple(map(float, case_name.split(\"_magnitude_\")[1].strip(\"()\").split(\", \")))\n",
    "\n",
    "            # Path to the variable file\n",
    "            variable_file = case_folder / \"Analytical_Solution\" / f\"{variable_name}.npy\"\n",
    "\n",
    "            # Print the file being read\n",
    "            print(f\"Reading file: {variable_file}\")\n",
    "\n",
    "            if variable_file.exists():\n",
    "                # Load variable data\n",
    "                variable_data = np.load(variable_file)\n",
    "\n",
    "                # Organize data\n",
    "                organized_data[case_number] = {\n",
    "                    \"magnitude\": magnitude,\n",
    "                    variable_name: variable_data\n",
    "                }\n",
    "                print(f\"✅ Successfully loaded {variable_name} data for Case {case_number}\")\n",
    "            else:\n",
    "                print(f\"❌ {variable_name.capitalize()} file not found for Case {case_number}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {case_folder.name}: {str(e)}\")\n",
    "\n",
    "    return organized_data\n",
    "\n",
    "# Example usage\n",
    "base_dir = \"Dynamic_solution\"\n",
    "\n",
    "# Initialize lists to store data for all cases\n",
    "displacement_list_analytical = []\n",
    "velocity_list_analytical = []\n",
    "acceleration_list_analytical = []\n",
    "force_list_analytical = []\n",
    "\n",
    "# Read and concatenate data for all variables\n",
    "for variable_name, data_list in zip(\n",
    "    [\"displacement_analytical\", \"velocity_analytical\", \"acceleration_analytical\", \"force_analytical\"],\n",
    "    [displacement_list_analytical, velocity_list_analytical, acceleration_list_analytical, force_list_analytical]\n",
    "):\n",
    "    organized_data_analytical = read_and_organize_data(base_dir, variable_name)\n",
    "    for case_number in sorted(organized_data_analytical.keys()):\n",
    "        data_list.append(organized_data_analytical[case_number][variable_name].T)  # Transpose to align DOF as rows\n",
    "\n",
    "    # Concatenate along the time axis if data_list is not empty\n",
    "    if data_list:\n",
    "        globals()[f\"organized_{variable_name}_data\"] = np.hstack(data_list)\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: No data found for variable '{variable_name}'.\")\n",
    "        globals()[f\"organized_{variable_name}_data\"] = np.array([])  # Create an empty array for consistency\n",
    "\n",
    "# Print summary\n",
    "print(\"📂 Data organized successfully.\")\n",
    "print(f\"📊 Total cases processed: {len(organized_data_analytical)}\")\n",
    "print(f\"📐 Final displacement data shape: {organized_displacement_data.shape}\")\n",
    "print(f\"📐 Final velocity data shape: {organized_velocity_data.shape}\")\n",
    "print(f\"📐 Final acceleration data shape: {organized_acceleration_data.shape}\")\n",
    "print(f\"📐 Final force data shape: {organized_force_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ---------------------- STEP 1: Load Analytical Data ----------------------\n",
    "\n",
    "def read_and_organize_data(base_dir, variable_name):\n",
    "    base_path = Path(base_dir)\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*\"))\n",
    "    organized_data = {}\n",
    "\n",
    "    for case_folder in case_folders:\n",
    "        try:\n",
    "            case_name = case_folder.name\n",
    "            case_number = int(case_name.split(\"_\")[1])\n",
    "            magnitude = tuple(map(float, case_name.split(\"_magnitude_\")[1].strip(\"()\").split(\", \")))\n",
    "            variable_file = case_folder / \"Analytical_Solution\" / f\"{variable_name}.npy\"\n",
    "            print(f\"📄 Reading file: {variable_file}\")\n",
    "            if variable_file.exists():\n",
    "                variable_data = np.load(variable_file)\n",
    "                organized_data[case_number] = {\n",
    "                    \"magnitude\": magnitude,\n",
    "                    variable_name: variable_data\n",
    "                }\n",
    "                print(f\"✅ Loaded {variable_name} for Case {case_number}\")\n",
    "            else:\n",
    "                print(f\"❌ File not found: {variable_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error reading {case_folder.name}: {str(e)}\")\n",
    "    return organized_data\n",
    "\n",
    "base_dir = \"Dynamic_solution\"\n",
    "variables = [\"displacement_analytical\", \"velocity_analytical\", \"acceleration_analytical\", \"force_analytical\"]\n",
    "data_lists = {var: [] for var in variables}\n",
    "\n",
    "for var in variables:\n",
    "    organized = read_and_organize_data(base_dir, var)\n",
    "    for case_num in sorted(organized.keys()):\n",
    "        data_lists[var].append(organized[case_num][var].T)\n",
    "    if data_lists[var]:\n",
    "        globals()[f\"organized_{var}_data\"] = np.hstack(data_lists[var])\n",
    "    else:\n",
    "        globals()[f\"organized_{var}_data\"] = np.array([])\n",
    "\n",
    "# ---------------------- STEP 2: Perform SVD on Displacement ----------------------\n",
    "\n",
    "def perform_complete_svd_analysis(displacement_matrix, energy_threshold=0.999, sv_threshold=1e-19):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" COMPLETE SVD AND REDUCED BASIS ANALYSIS \".center(80))\n",
    "    print(\"=\"*80)\n",
    "    U, S, VT = np.linalg.svd(displacement_matrix, full_matrices=False)\n",
    "    cum_energy = np.cumsum(S) / np.sum(S)\n",
    "    r_energy = np.argmax(cum_energy >= energy_threshold) + 1\n",
    "    r_threshold = np.sum(S >= sv_threshold)\n",
    "    final_rank = min(r_energy, r_threshold)\n",
    "    V_r = U[:, :final_rank]\n",
    "\n",
    "    print(f\"\\n{' SVD SUMMARY ':-^80}\")\n",
    "    print(f\"Original shape         : {displacement_matrix.shape}\")\n",
    "    print(f\"Energy threshold       : {energy_threshold:.3f}\")\n",
    "    print(f\"SV threshold           : {sv_threshold:.1e}\")\n",
    "    print(f\"Rank by energy         : {r_energy}\")\n",
    "    print(f\"Rank by threshold      : {r_threshold}\")\n",
    "    print(f\"Final selected rank    : {final_rank}\")\n",
    "    print(f\"Dimensionality reduced : {100 * (1 - final_rank/displacement_matrix.shape[0]):.1f}%\")\n",
    "\n",
    "    return V_r, {\n",
    "        'U': U, 'S': S, 'VT': VT, 'V_r': V_r,\n",
    "        'cumulative_energy': cum_energy,\n",
    "        'final_rank': final_rank\n",
    "    }\n",
    "\n",
    "displacement_matrix = organized_displacement_analytical_data\n",
    "if displacement_matrix.size == 0:\n",
    "    raise ValueError(\"No displacement data loaded.\")\n",
    "V_r, svd_results = perform_complete_svd_analysis(displacement_matrix)\n",
    "\n",
    "# ---------------------- STEP 3: Projection & Reconstruction ----------------------\n",
    "\n",
    "def project_and_reconstruct(matrix, V_r, label=\"\"):\n",
    "    original_shape = matrix.shape\n",
    "    projected = V_r.T @ matrix\n",
    "    reconstructed = V_r @ projected\n",
    "    error = np.linalg.norm(matrix - reconstructed) / np.linalg.norm(matrix)\n",
    "    error_percent = error * 100\n",
    "\n",
    "    print(f\"\\n{' ' + label + ' RECONSTRUCTION ':=^80}\")\n",
    "    print(f\"Original shape         : {original_shape}\")\n",
    "    print(f\"Reduced shape          : {projected.shape}\")\n",
    "    print(f\"Reconstructed shape    : {reconstructed.shape}\")\n",
    "    print(f\"Reconstruction error   : {error:.3e}\")\n",
    "    print(f\"Percentage error       : {error_percent:.3f}%\")\n",
    "\n",
    "    return projected, reconstructed, error\n",
    "\n",
    "results = {}\n",
    "results[\"Displacement\"] = project_and_reconstruct(organized_displacement_analytical_data, V_r, \"Displacement\")\n",
    "results[\"Velocity\"]     = project_and_reconstruct(organized_velocity_analytical_data, V_r, \"Velocity\")\n",
    "results[\"Acceleration\"] = project_and_reconstruct(organized_acceleration_analytical_data, V_r, \"Acceleration\")\n",
    "results[\"Force\"]        = project_and_reconstruct(organized_force_analytical_data, V_r, \"Force\")\n",
    "\n",
    "# ---------------------- STEP 4: Final Summary Table ----------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" FINAL RECONSTRUCTION ERROR SUMMARY \".center(80))\n",
    "print(\"=\"*80)\n",
    "summary_table = []\n",
    "for var, (_, _, error) in results.items():\n",
    "    summary_table.append([var, f\"{error:.3e}\", f\"{error * 100:.3f}%\"])\n",
    "print(tabulate(summary_table, headers=[\"Variable\", \"Relative Error\", \"Percentage Error\"], tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Ensure organized data and V_r from previous SVD are available\n",
    "assert 'organized_displacement_data' in globals()\n",
    "assert 'organized_velocity_data' in globals()\n",
    "assert 'organized_acceleration_data' in globals()\n",
    "assert 'organized_force_data' in globals()\n",
    "assert 'V_r' in globals()\n",
    "\n",
    "print(f\"\\n{' V_r (Reduced Basis) ':-^80}\")\n",
    "print(f\"Shape: {V_r.shape} (DOFs × modes)\")\n",
    "\n",
    "# === ANALYSIS FOR ANALYTICAL SOLUTION ===\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" REDUCED ORDER ANALYSIS FOR ANALYTICAL SOLUTION \".center(80))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Function to project and reconstruct a matrix\n",
    "\n",
    "def project_and_reconstruct(matrix, V_r, label=\"\"):\n",
    "    original_shape = matrix.shape\n",
    "    projected = V_r.T @ matrix\n",
    "    reconstructed = V_r @ projected\n",
    "    error = np.linalg.norm(matrix - reconstructed) / np.linalg.norm(matrix)\n",
    "    error_percent = error * 100\n",
    "\n",
    "    print(f\"\\n{' ' + label + ' RECONSTRUCTION DETAILS ':=^80}\")\n",
    "    print(f\"Original shape      : {original_shape}\")\n",
    "    print(f\"Reduced shape       : {projected.shape}\")\n",
    "    print(f\"Reconstructed shape : {reconstructed.shape}\")\n",
    "    print(f\"Reconstruction error: {error:.3e}\")\n",
    "    print(f\"Percentage error    : {error_percent:.3f}%\")\n",
    "\n",
    "    return projected, reconstructed, error\n",
    "\n",
    "# Apply to each variable\n",
    "projected_displacement, reconstructed_displacement, err_disp = project_and_reconstruct(\n",
    "    organized_displacement_data, V_r, label=\"Displacement\"\n",
    ")\n",
    "\n",
    "projected_velocity, reconstructed_velocity, err_vel = project_and_reconstruct(\n",
    "    organized_velocity_data, V_r, label=\"Velocity\"\n",
    ")\n",
    "\n",
    "projected_acceleration, reconstructed_acceleration, err_acc = project_and_reconstruct(\n",
    "    organized_acceleration_data, V_r, label=\"Acceleration\"\n",
    ")\n",
    "\n",
    "projected_force, reconstructed_force, err_force = project_and_reconstruct(\n",
    "    organized_force_data, V_r, label=\"Force\"\n",
    ")\n",
    "\n",
    "# Collect all errors into a dictionary for summary\n",
    "reconstruction_errors = {\n",
    "    \"Displacement\": err_disp,\n",
    "    \"Velocity\": err_vel,\n",
    "    \"Acceleration\": err_acc,\n",
    "    \"Force\": err_force\n",
    "}\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" FINAL RECONSTRUCTION ERROR SUMMARY FOR ANALYTICAL SOLUTION \".center(80))\n",
    "print(\"=\"*80)\n",
    "for var, err in reconstruction_errors.items():\n",
    "    print(f\"{var:<20}: {err:.3e} ({err * 100:.3f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = f\"Dynamic_solution/case_{i}_magnitude_({', '.join(map(str, magnitude))})/Analytical_Solution\"\n",
    "print(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def create_displacement_gif(folder_path, mdpa_file, scale_factor=1e6, step_interval=100):\n",
    "    \"\"\"\n",
    "    Create a displacement GIF for a specific case.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    folder_path: str, path to the folder containing displacement, velocity, and acceleration files.\n",
    "    mdpa_file: pathlib.Path, path to the .mdpa file for mesh and connectivity information.\n",
    "    scale_factor: float, scaling factor for displacements.\n",
    "    step_interval: int, time in milliseconds between frames.\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    output_file = folder_path / 'displacement_animation.gif'\n",
    "\n",
    "    print(f\"Processing folder: {folder_path}\")\n",
    "\n",
    "    # Load solution data\n",
    "    time = np.load(folder_path / 'time.npy')\n",
    "    displacement = np.load(folder_path / 'displacement.npy')\n",
    "    print(f\"Loaded files:\\n- {folder_path / 'time.npy'}\\n- {folder_path / 'displacement.npy'}\")\n",
    "\n",
    "    # Read node coordinates and elements from the .mdpa file\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    x, y = float(parts[1]), float(parts[2])\n",
    "                    node_coords.append([x, y])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "                    elements.append([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 15))\n",
    "\n",
    "    # Create base triangulation for undeformed mesh\n",
    "    x = node_coords[:, 0]\n",
    "    y = node_coords[:, 1]\n",
    "    triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "\n",
    "    # Find global displacement limits for consistent colorbar\n",
    "    disp_magnitudes = []\n",
    "    for step in range(len(time)):\n",
    "        disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "        disp_magnitudes.append(disp_mag)\n",
    "\n",
    "    global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "    global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "\n",
    "    print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "\n",
    "        # Get displacements for current frame\n",
    "        disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "\n",
    "        # Calculate deformed coordinates\n",
    "        deformed_coords = node_coords + disp\n",
    "\n",
    "        # Plot undeformed mesh\n",
    "        ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "\n",
    "        # Plot deformed mesh with displacement magnitude coloring\n",
    "        triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "        tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                           vmin=global_min, vmax=global_max)\n",
    "        ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "        # Set labels and title\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "\n",
    "        ax.grid(True)\n",
    "        ax.axis('equal')\n",
    "        ax.legend()\n",
    "\n",
    "        # Add colorbar only once\n",
    "        if frame == 0:\n",
    "            plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # Create animation\n",
    "    print(\"Creating animation...\")\n",
    "    anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "\n",
    "    # Save animation\n",
    "    print(f\"Saving animation to {output_file}\")\n",
    "    writer = PillowWriter(fps=1000 / step_interval)\n",
    "    anim.save(output_file, writer=writer)\n",
    "\n",
    "    plt.close()\n",
    "    print(\"Animation completed!\")\n",
    "\n",
    "# Process all cases\n",
    "for case in results:\n",
    "    folder_path = f\"Dynamic_solution/case_{case['case']}_magnitude_({', '.join(map(str, case['magnitude']))})/Analytical_Solution\"\n",
    "    create_displacement_gif(folder_path, mdpa_file, scale_factor=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def save_displacement_screenshots(folder_path, mdpa_file, scale_factor=1e6):\n",
    "    \"\"\"\n",
    "    Save displacement screenshots for each timestep.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    folder_path: str, path to the folder containing displacement, velocity, and acceleration files.\n",
    "    mdpa_file: pathlib.Path, path to the .mdpa file for mesh and connectivity information.\n",
    "    scale_factor: float, scaling factor for displacements.\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    output_folder = folder_path / 'displacement_screenshots'\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"Processing folder: {folder_path}\")\n",
    "\n",
    "    # Load solution data\n",
    "    time = np.load(folder_path / 'time.npy')\n",
    "    displacement = np.load(folder_path / 'displacement.npy')\n",
    "    print(f\"Loaded files:\\n- {folder_path / 'time.npy'}\\n- {folder_path / 'displacement.npy'}\")\n",
    "\n",
    "    # Read node coordinates and elements from the .mdpa file\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    x, y = float(parts[1]), float(parts[2])\n",
    "                    node_coords.append([x, y])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]) - 1, int(parts[3]) - 1, int(parts[4]) - 1\n",
    "                    elements.append([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "\n",
    "    # Create base triangulation for undeformed mesh\n",
    "    x = node_coords[:, 0]\n",
    "    y = node_coords[:, 1]\n",
    "    triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "\n",
    "    # Find global displacement limits for consistent colorbar\n",
    "    disp_magnitudes = []\n",
    "    for step in range(len(time)):\n",
    "        disp = displacement[step].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "        disp_magnitudes.append(disp_mag)\n",
    "\n",
    "    global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "    global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "\n",
    "    print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "    # Save screenshots for each timestep\n",
    "    for frame in range(len(time)):\n",
    "        fig, ax = plt.subplots(figsize=(10, 15))\n",
    "\n",
    "        # Get displacements for current frame\n",
    "        disp = displacement[frame].reshape(-1, 2) * scale_factor\n",
    "        disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "\n",
    "        # Calculate deformed coordinates\n",
    "        deformed_coords = node_coords + disp\n",
    "\n",
    "        # Plot undeformed mesh\n",
    "        ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "\n",
    "        # Plot deformed mesh with displacement magnitude coloring\n",
    "        triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "        tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                           vmin=global_min, vmax=global_max)\n",
    "        ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "\n",
    "        # Set labels and title\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "\n",
    "        ax.grid(True)\n",
    "        ax.axis('equal')\n",
    "        ax.legend()\n",
    "\n",
    "        # Add colorbar\n",
    "        plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot as an image\n",
    "        output_file = output_folder / f'displacement_frame_{frame:04d}.png'\n",
    "        plt.savefig(output_file)\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"Saved frame {frame}/{len(time)-1} to {output_file}\")\n",
    "\n",
    "    print(\"All screenshots saved!\")\n",
    "\n",
    "# Example usage\n",
    "# Iterate through all cases\n",
    "for case in results:\n",
    "    case_folder = Path(folder_path) / f\"case_{case['case']}_magnitude_({case['magnitude'][0]:.2f}, {case['magnitude'][1]:.2f}, {case['magnitude'][2]:.2f})\"\n",
    "    output_folder = case_folder / 'displacement_screenshots'\n",
    "\n",
    "    # Check if the output folder already exists\n",
    "    if output_folder.exists():\n",
    "        print(f\"Output folder already exists for case {case['case']}. Deleting and recreating...\")\n",
    "        shutil.rmtree(output_folder)\n",
    "\n",
    "    # Perform the operation\n",
    "    save_displacement_screenshots(case_folder, mdpa_file, scale_factor=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the displacement array shape\n",
    "disp_shape = case_results[0]['displacement'].shape\n",
    "\n",
    "# Print the details\n",
    "print(\"Displacement vector size:\")\n",
    "print(f\"Shape: {disp_shape}\")\n",
    "print(f\"Number of timesteps: {disp_shape[0]}\")\n",
    "print(f\"Number of DOFs: {disp_shape[1]}\")\n",
    "print(f\"Total number of displacement values: {disp_shape[0] * disp_shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "\n",
    "def create_displacement_animation(case_folder, mdpa_file, scale_factor=1e6, step_interval=100):\n",
    "    \"\"\"\n",
    "    Create an animated GIF of displacement field for a specific case.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output_file = case_folder / 'displacement_animation.gif'\n",
    "        print(f\"\\nProcessing: {case_folder.name}\")\n",
    "\n",
    "        # Load solution data\n",
    "        time = np.load(case_folder / \"time.npy\")\n",
    "        displacement = np.load(case_folder / \"displacement.npy\")\n",
    "        print(f\"Loaded displacement data shape: {displacement.shape}\")\n",
    "        print(f\"Time steps available: {len(time)}\")\n",
    "\n",
    "        # Read node coordinates and elements\n",
    "        node_coords = []\n",
    "        elements = []\n",
    "        reading_nodes = False\n",
    "        reading_elements = False\n",
    "\n",
    "        with open(mdpa_file, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "\n",
    "                if \"Begin Nodes\" in line:\n",
    "                    reading_nodes = True\n",
    "                    continue\n",
    "                elif \"End Nodes\" in line:\n",
    "                    reading_nodes = False\n",
    "                    continue\n",
    "                elif reading_nodes and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4:\n",
    "                        x, y = float(parts[1]), float(parts[2])\n",
    "                        node_coords.append([x, y])\n",
    "\n",
    "                if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                    reading_elements = True\n",
    "                    continue\n",
    "                elif reading_elements and \"End Elements\" in line:\n",
    "                    reading_elements = False\n",
    "                    continue\n",
    "                elif reading_elements and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 5:\n",
    "                        n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "                        elements.append([n1, n2, n3])\n",
    "\n",
    "        node_coords = np.array(node_coords)\n",
    "        elements = np.array(elements)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 15))\n",
    "        x = node_coords[:, 0]\n",
    "        y = node_coords[:, 1]\n",
    "        triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "\n",
    "        # Compute global min and max for color normalization\n",
    "        num_nodes = displacement.shape[1] // 2\n",
    "        disp_magnitudes = []\n",
    "        for step in range(len(time)):\n",
    "            disp = displacement[step, :].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            disp_magnitudes.append(disp_mag)\n",
    "\n",
    "        global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "        global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "\n",
    "        print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "        def update(frame):\n",
    "            ax.clear()\n",
    "            disp = displacement[frame, :].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            deformed_coords = node_coords + disp\n",
    "\n",
    "            ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3)\n",
    "            triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "            tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                               vmin=global_min, vmax=global_max)\n",
    "            ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5)\n",
    "\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "            ax.grid(True)\n",
    "            ax.axis('equal')\n",
    "\n",
    "            if frame == 0:\n",
    "                plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "            plt.tight_layout()\n",
    "\n",
    "        print(\"Creating animation...\")\n",
    "        anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "        print(f\"Saving animation to {output_file}\")\n",
    "        writer = PillowWriter(fps=1000 / step_interval)\n",
    "        anim.save(output_file, writer=writer)\n",
    "        plt.close()\n",
    "        print(\"Animation completed!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {case_folder.name}: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "\n",
    "def process_all_cases(base_dir=\"Dynamic_solution\", scale_factor=1e6):\n",
    "    base_path = Path(base_dir)\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*/Analytical_Solution\"))\n",
    "\n",
    "    def extract_case_number(folder_name):\n",
    "        return int(folder_name.parts[-2].split(\"_\")[1])\n",
    "\n",
    "    case_folders.sort(key=extract_case_number)\n",
    "    print(f\"Found {len(case_folders)} cases to process\")\n",
    "\n",
    "    cwd = Path.cwd()\n",
    "    mdpa_file = next((f for f in cwd.glob(\"*.mdpa\")), None)\n",
    "    if mdpa_file is None:\n",
    "        raise FileNotFoundError(\"No .mdpa file found in the current directory.\")\n",
    "    print(f\"Using .mdpa file: {mdpa_file}\")\n",
    "\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "\n",
    "    for folder in case_folders:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {folder.parent.name}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        if create_displacement_animation(folder, mdpa_file, scale_factor):\n",
    "            successful += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Processing Complete!\")\n",
    "    print(f\"Successfully processed: {successful} cases\")\n",
    "    print(f\"Failed to process: {failed} cases\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n",
    "# Run the animation processing\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        process_all_cases(base_dir=\"Dynamic_solution\", scale_factor=1e6)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def save_displacement_screenshots(case_folder, mdpa_file, scale_factor=1e6):\n",
    "    \"\"\"\n",
    "    Save displacement screenshots for every time step in a folder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output folder for screenshots\n",
    "        output_folder = case_folder / 'displacement_screenshots'\n",
    "        output_folder.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\nProcessing: {case_folder.name}\")\n",
    "\n",
    "        # Load solution data\n",
    "        time = np.load(case_folder / \"time.npy\")\n",
    "        displacement = np.load(case_folder / \"displacement.npy\")\n",
    "        print(f\"Loaded displacement data shape: {displacement.shape}\")\n",
    "        print(f\"Time steps available: {len(time)}\")\n",
    "\n",
    "        # Read node coordinates and elements\n",
    "        node_coords = []\n",
    "        elements = []\n",
    "        reading_nodes = False\n",
    "        reading_elements = False\n",
    "\n",
    "        with open(mdpa_file, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "\n",
    "                if \"Begin Nodes\" in line:\n",
    "                    reading_nodes = True\n",
    "                    continue\n",
    "                elif \"End Nodes\" in line:\n",
    "                    reading_nodes = False\n",
    "                    continue\n",
    "                elif reading_nodes and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4:\n",
    "                        x, y = float(parts[1]), float(parts[2])\n",
    "                        node_coords.append([x, y])\n",
    "\n",
    "                if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                    reading_elements = True\n",
    "                    continue\n",
    "                elif reading_elements and \"End Elements\" in line:\n",
    "                    reading_elements = False\n",
    "                    continue\n",
    "                elif reading_elements and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 5:\n",
    "                        n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "                        elements.append([n1, n2, n3])\n",
    "\n",
    "        node_coords = np.array(node_coords)\n",
    "        elements = np.array(elements)\n",
    "\n",
    "        # Create base triangulation for undeformed mesh\n",
    "        x = node_coords[:, 0]\n",
    "        y = node_coords[:, 1]\n",
    "        triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "\n",
    "        # Compute global min and max for color normalization\n",
    "        disp_magnitudes = []\n",
    "        for step in range(len(time)):\n",
    "            disp = displacement[step, :].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            disp_magnitudes.append(disp_mag)\n",
    "\n",
    "        global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "        global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "\n",
    "        print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "\n",
    "        # Save screenshots for each time step\n",
    "        for frame in range(len(time)):\n",
    "            fig, ax = plt.subplots(figsize=(10, 15))\n",
    "            disp = displacement[frame, :].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            deformed_coords = node_coords + disp\n",
    "\n",
    "            ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3)\n",
    "            triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "            tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                               vmin=global_min, vmax=global_max)\n",
    "            ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5)\n",
    "\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "            ax.grid(True)\n",
    "            ax.axis('equal')\n",
    "\n",
    "            plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save the screenshot\n",
    "            output_file = output_folder / f\"displacement_frame_{frame:04d}.png\"\n",
    "            plt.savefig(output_file)\n",
    "            plt.close(fig)\n",
    "\n",
    "            if frame % 10 == 0:\n",
    "                print(f\"Saved screenshot for frame {frame}/{len(time)-1}\")\n",
    "\n",
    "        print(\"All screenshots saved successfully!\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {case_folder.name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def process_all_cases(base_dir=\"Dynamic_solution\", scale_factor=1e6):\n",
    "    base_path = Path(base_dir)\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*/Analytical_Solution\"))\n",
    "\n",
    "    def extract_case_number(folder_name):\n",
    "        return int(folder_name.parts[-2].split(\"_\")[1])\n",
    "\n",
    "    case_folders.sort(key=extract_case_number)\n",
    "    print(f\"Found {len(case_folders)} cases to process\")\n",
    "\n",
    "    cwd = Path.cwd()\n",
    "    mdpa_file = next((f for f in cwd.glob(\"*.mdpa\")), None)\n",
    "    if mdpa_file is None:\n",
    "        raise FileNotFoundError(\"No .mdpa file found in the current directory.\")\n",
    "    print(f\"Using .mdpa file: {mdpa_file}\")\n",
    "\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "\n",
    "    for folder in case_folders:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {folder.parent.name}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        if save_displacement_screenshots(folder, mdpa_file, scale_factor):\n",
    "            successful += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Processing Complete!\")\n",
    "    print(f\"Successfully processed: {successful} cases\")\n",
    "    print(f\"Failed to process: {failed} cases\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n",
    "# Run the screenshot saving process\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        process_all_cases(base_dir=\"Dynamic_solution\", scale_factor=1e6)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def read_mdpa_and_select_boundary_nodes(mdpa_file):\n",
    "    \"\"\"\n",
    "    Reads the mdpa file and identifies boundary nodes.\n",
    "    Returns the node coordinates and boundary nodes.\n",
    "    \"\"\"\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    boundary_nodes = set()\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    node_coords.append([int(parts[0]), float(parts[1]), float(parts[2])])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]), int(parts[3]), int(parts[4])\n",
    "                    elements.append([n1, n2, n3])\n",
    "                    boundary_nodes.update([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "    return node_coords, elements, boundary_nodes\n",
    "\n",
    "def select_boundary_points(node_coords, boundary_nodes):\n",
    "    \"\"\"\n",
    "    Selects 3 boundary points: one at the bottom, one in the middle, and one at the top.\n",
    "    \"\"\"\n",
    "    boundary_coords = node_coords[np.isin(node_coords[:, 0], list(boundary_nodes))]\n",
    "    sorted_coords = boundary_coords[np.argsort(boundary_coords[:, 2])]  # Sort by Y-coordinate\n",
    "\n",
    "    bottom_node = sorted_coords[0]\n",
    "    top_node = sorted_coords[-1]\n",
    "    middle_node = sorted_coords[len(sorted_coords) // 2]\n",
    "\n",
    "    return bottom_node, middle_node, top_node\n",
    "\n",
    "def plot_displacement_graphs(case_results, results, nodes, node_coords, mdpa_file):\n",
    "    \"\"\"\n",
    "    Plots displacement, velocity, and acceleration vs time for the selected nodes and highlights the nodes on the mesh.ights the nodes on the mesh.ights the nodes on the mesh.\n",
    "    \"\"\"\n",
    "    time_newmark = case_results[0].get('time', None)\n",
    "    time_ivp = results[0].get('time', case_results[0].get('time', None))  # Use case_results[0]['time'] as a fallback\n",
    "\n",
    "    if time_newmark is None or time_ivp is None:\n",
    "        raise KeyError(\"The 'time' key is missing in case_results or results.\")\n",
    "\n",
    "    for i, node in enumerate(nodes):\n",
    "        node_id = int(node[0])\n",
    "        node_x, node_y = node[1], node[2]\n",
    "\n",
    "        # Extract displacement, velocity, and acceleration for the nodend acceleration for the nodend acceleration for the node\n",
    "        idx = np.where(node_coords[:, 0] == node_id)[0][0]\n",
    "        displacement_newmark = case_results[0]['displacement'][:, idx]\n",
    "        displacement_ivp = u[:, idx]  # Use the correct displacement data\n",
    "        velocity_newmark = case_results[0]['velocity'][:, idx]\n",
    "        # Plot displacement vs time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_newmark, displacement_newmark, label='Newmark Method', color='blue')\n",
    "        plt.plot(time_ivp, displacement_ivp, label='Solve IVP Method', color='red', linestyle='--')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Displacement (m)')\n",
    "        plt.title(f'Displacement vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Highlight the selected node on the mesh\n",
    "        highlight_selected_node(mdpa_file, node_id)\n",
    "\n",
    "def highlight_selected_node(mdpa_file, node_id):\n",
    "    \"\"\"\n",
    "    Highlights the selected node on the mesh by drawing a circle around it.\n",
    "    \"\"\"\n",
    "    node_coords, elements, _ = read_mdpa_and_select_boundary_nodes(mdpa_file)\n",
    "    x = node_coords[:, 1]\n",
    "    y = node_coords[:, 2]\n",
    "\n",
    "    triangulation = tri.Triangulation(x, y, elements - 1)\n",
    "\n",
    "    selected_node = node_coords[node_coords[:, 0] == node_id][0]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.triplot(triangulation, 'k-', lw=0.5, alpha=0.5)\n",
    "    plt.scatter(selected_node[1], selected_node[2], color='red', label=f'Selected Node {node_id}')\n",
    "    plt.gca().add_artist(plt.Circle((selected_node[1], selected_node[2]), radius=0.1, color='red', fill=False))\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title(f'Mesh with Highlighted Node {node_id}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "node_coords, elements, boundary_nodes = read_mdpa_and_select_boundary_nodes(mdpa_file)\n",
    "bottom_node, middle_node, top_node = select_boundary_points(node_coords, boundary_nodes)\n",
    "\n",
    "selected_nodes = [bottom_node, middle_node, top_node]\n",
    "plot_displacement_graphs(case_results, results, selected_nodes, node_coords, mdpa_file)\n",
    "\n",
    "# Plot velocity and acceleration graphs\n",
    "for i, node in enumerate(selected_nodes):\n",
    "    node_id = int(node[0])\n",
    "    node_x, node_y = node[1], node[2]\n",
    "\n",
    "    # Extract velocity and acceleration for the node\n",
    "    idx = np.where(node_coords[:, 0] == node_id)[0][0]\n",
    "    velocity_newmark = case_results[0]['velocity'][:, idx]\n",
    "    velocity_ivp = v[:, idx]  # Use the correct velocity data\n",
    "    acceleration_newmark = case_results[0]['acceleration'][:, idx]\n",
    "    acceleration_ivp = a[:, idx]  # Use the correct acceleration data\n",
    "\n",
    "    # Plot velocity vs time\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(case_results[0]['time'], velocity_newmark, label='Newmark Method', color='blue')\n",
    "    plt.plot(case_results[0]['time'], velocity_ivp, label='Solve IVP Method', color='red', linestyle='--')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Velocity (m/s)')\n",
    "    plt.title(f'Velocity vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot acceleration vs time\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(case_results[0]['time'], acceleration_newmark, label='Newmark Method', color='blue')\n",
    "    plt.plot(case_results[0]['time'], acceleration_ivp, label='Solve IVP Method', color='red', linestyle='--')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Acceleration (m/s²)')\n",
    "    plt.title(f'Acceleration vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "def read_mdpa_and_select_boundary_nodes(mdpa_file):\n",
    "    \"\"\"\n",
    "    Reads the mdpa file and identifies boundary nodes.\n",
    "    Returns the node coordinates and boundary nodes.\n",
    "    \"\"\"\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    boundary_nodes = set()\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "\n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    node_coords.append([int(parts[0]), float(parts[1]), float(parts[2])])\n",
    "\n",
    "            if \"Begin Elements\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2]), int(parts[3]), int(parts[4])\n",
    "                    elements.append([n1, n2, n3])\n",
    "                    boundary_nodes.update([n1, n2, n3])\n",
    "\n",
    "    node_coords = np.array(node_coords)\n",
    "    elements = np.array(elements)\n",
    "    return node_coords, elements, boundary_nodes\n",
    "\n",
    "def select_boundary_points(node_coords, boundary_nodes):\n",
    "    \"\"\"\n",
    "    Selects 3 boundary points: one at the bottom, one in the middle, and one at the top.\n",
    "    \"\"\"\n",
    "    boundary_coords = node_coords[np.isin(node_coords[:, 0], list(boundary_nodes))]\n",
    "    sorted_coords = boundary_coords[np.argsort(boundary_coords[:, 2])]  # Sort by Y-coordinate\n",
    "\n",
    "    bottom_node = sorted_coords[0]\n",
    "    top_node = sorted_coords[-1]\n",
    "    middle_node = sorted_coords[len(sorted_coords) // 2]\n",
    "\n",
    "    return bottom_node, middle_node, top_node\n",
    "\n",
    "def plot_node_representation(mdpa_file, node_id):\n",
    "    \"\"\"\n",
    "    Highlights the selected node on the mesh by drawing a circle around it.\n",
    "    \"\"\"\n",
    "    node_coords, elements, _ = read_mdpa_and_select_boundary_nodes(mdpa_file)\n",
    "    x = node_coords[:, 1]\n",
    "    y = node_coords[:, 2]\n",
    "\n",
    "    triangulation = tri.Triangulation(x, y, elements - 1)\n",
    "\n",
    "    selected_node = node_coords[node_coords[:, 0] == node_id][0]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.triplot(triangulation, 'k-', lw=0.5, alpha=0.5)\n",
    "    plt.scatter(selected_node[1], selected_node[2], color='red', label=f'Selected Node {node_id}')\n",
    "    plt.gca().add_artist(plt.Circle((selected_node[1], selected_node[2]), radius=0.1, color='red', fill=False))\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title(f'Mesh with Highlighted Node {node_id}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_displacement(time_newmark, displacement_newmark, time_ivp, displacement_ivp, node_id, node_x, node_y):\n",
    "    \"\"\"\n",
    "    Plots displacement vs time for the selected node.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time_newmark, displacement_newmark, label='Newmark Method', color='blue')\n",
    "    plt.plot(time_ivp, displacement_ivp, label='Solve IVP Method', color='red', linestyle='--')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Displacement (m)')\n",
    "    plt.title(f'Displacement vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_velocity(time_newmark, velocity_newmark, time_ivp, velocity_ivp, node_id, node_x, node_y):\n",
    "    \"\"\"\n",
    "    Plots velocity vs time for the selected node.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time_newmark, velocity_newmark, label='Newmark Method', color='blue')\n",
    "    plt.plot(time_ivp, velocity_ivp, label='Solve IVP Method', color='red', linestyle='--')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Velocity (m/s)')\n",
    "    plt.title(f'Velocity vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_acceleration(time_newmark, acceleration_newmark, time_ivp, acceleration_ivp, node_id, node_x, node_y):\n",
    "    \"\"\"\n",
    "    Plots acceleration vs time for the selected node.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time_newmark, acceleration_newmark, label='Newmark Method', color='blue')\n",
    "    plt.plot(time_ivp, acceleration_ivp, label='Solve IVP Method', color='red', linestyle='--')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Acceleration (m/s²)')\n",
    "    plt.title(f'Acceleration vs Time for Node {node_id} (X: {node_x}, Y: {node_y})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "node_coords, elements, boundary_nodes = read_mdpa_and_select_boundary_nodes(mdpa_file)\n",
    "bottom_node, middle_node, top_node = select_boundary_points(node_coords, boundary_nodes)\n",
    "\n",
    "selected_nodes = [bottom_node, middle_node, top_node]\n",
    "\n",
    "# Plot node representation\n",
    "plot_node_representation(mdpa_file, node_id)\n",
    "\n",
    "# Plot displacement, velocity, and acceleration for each selected node\n",
    "for node in selected_nodes:\n",
    "    node_id = int(node[0])\n",
    "    node_x, node_y = node[1], node[2]\n",
    "\n",
    "    idx = np.where(node_coords[:, 0] == node_id)[0][0]\n",
    "    displacement_newmark = case_results[0]['displacement'][:, idx]\n",
    "    displacement_ivp = u[:, idx]  \n",
    "    velocity_newmark = case_results[0]['velocity'][:, idx]\n",
    "    velocity_ivp = v[:, idx]\n",
    "    acceleration_newmark = case_results[0]['acceleration'][:, idx]\n",
    "    acceleration_ivp = a[:, idx]\n",
    "\n",
    "    plot_displacement(case_results[0]['time'], displacement_newmark, case_results[0]['time'], displacement_ivp, node_id, node_x, node_y)\n",
    "    plot_velocity(case_results[0]['time'], velocity_newmark, case_results[0]['time'], velocity_ivp, node_id, node_x, node_y)\n",
    "    plot_acceleration(case_results[0]['time'], acceleration_newmark, case_results[0]['time'], acceleration_ivp, node_id, node_x, node_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def calculate_and_print_error(case_results, results, selected_nodes, node_coords):\n",
    "    \"\"\"\n",
    "    Calculate and print the error differences between Newmark and Solve IVP methods for displacement, velocity, and acceleration.\n",
    "    \"\"\"\n",
    "    error_data = []\n",
    "\n",
    "    for node in selected_nodes:\n",
    "        node_id = int(node[0])\n",
    "        node_x, node_y = node[1], node[2]\n",
    "\n",
    "        # Find the index of the node in the node coordinates\n",
    "        idx = np.where(node_coords[:, 0] == node_id)[0][0]\n",
    "\n",
    "        # Extract data for the node\n",
    "        displacement_newmark = case_results[0]['displacement'][:, idx]\n",
    "        displacement_ivp = results[0]['displacement'][:, idx]\n",
    "        velocity_newmark = case_results[0]['velocity'][:, idx]\n",
    "        velocity_ivp = results[0]['velocity'][:, idx]\n",
    "        acceleration_newmark = case_results[0]['acceleration'][:, idx]\n",
    "        acceleration_ivp = results[0]['acceleration'][:, idx]\n",
    "\n",
    "        # Calculate absolute errors\n",
    "        displacement_error = np.max(np.abs(displacement_newmark - displacement_ivp))\n",
    "        velocity_error = np.max(np.abs(velocity_newmark - velocity_ivp))\n",
    "        acceleration_error = np.max(np.abs(acceleration_newmark - acceleration_ivp))\n",
    "\n",
    "        # Append to error data\n",
    "        error_data.append([\n",
    "            node_id,\n",
    "            f\"({node_x:.2f}, {node_y:.2f})\",\n",
    "            f\"{displacement_error:.2e}\",\n",
    "            f\"{velocity_error:.2e}\",\n",
    "            f\"{acceleration_error:.2e}\"\n",
    "        ])\n",
    "\n",
    "    # Print the error data in tabular form\n",
    "    headers = [\"Node ID\", \"Coordinates (X, Y)\", \"Max Displacement Error\", \"Max Velocity Error\", \"Max Acceleration Error\"]\n",
    "    print(\"\\nError Differences Between Newmark and Solve IVP Methods:\")\n",
    "    print(tabulate(error_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Call the function to calculate and print the error\n",
    "calculate_and_print_error(case_results, results, selected_nodes, node_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def prepare_displacement_matrix(base_dir):\n",
    "    \"\"\"\n",
    "    Reads displacement data from folders and arranges it into a matrix for SVD calculation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_dir: str or Path\n",
    "        The base directory containing case folders with displacement data.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    displacement_matrix: np.ndarray\n",
    "        A 2D matrix where each column corresponds to a flattened displacement vector across all time steps.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*/Analytical_Solution\"))\n",
    "\n",
    "    displacement_list = []\n",
    "\n",
    "    for folder in case_folders:\n",
    "        displacement_file = folder / \"displacement.npy\"\n",
    "        if displacement_file.exists():\n",
    "            # Load displacement data\n",
    "            displacement = np.load(displacement_file)\n",
    "            # Reshape displacement data to (DOF, time_steps) and append to the list\n",
    "            displacement_list.append(displacement.T)  # Transpose to make DOF rows and time columns\n",
    "        else:\n",
    "            print(f\"Displacement file not found in {folder}\")\n",
    "\n",
    "    # Concatenate all displacement data along the time axis\n",
    "    displacement_matrix = np.hstack(displacement_list)\n",
    "    return displacement_matrix\n",
    "\n",
    "# Prepare the displacement matrix\n",
    "displacement_matrix = prepare_displacement_matrix(output_dir)\n",
    "\n",
    "# Print the shape of the displacement matrix\n",
    "print(f\"Displacement matrix shape: {displacement_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perform SVD on the displacement matrix\n",
    "U, S, Vt = np.linalg.svd(displacement_matrix, full_matrices=False)\n",
    "\n",
    "# Plot the singular values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(S, marker='o', linestyle='-', color='b')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Singular Value (log scale)')\n",
    "plt.title('Singular Values of the Displacement Matrix')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the first few singular vectors (modes)\n",
    "num_modes_to_plot = 5\n",
    "time_steps = displacement_matrix.shape[1]\n",
    "\n",
    "for i in range(num_modes_to_plot):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(U[:, i], label=f'Mode {i + 1}')\n",
    "    plt.xlabel('DOF Index')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title(f'Singular Vector (Mode {i + 1})')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the temporal coefficients for the first few modes\n",
    "for i in range(num_modes_to_plot):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(Vt[i, :], label=f'Mode {i + 1}')\n",
    "    plt.xlabel('Time Step Index')\n",
    "    plt.ylabel('Coefficient')\n",
    "    plt.title(f'Temporal Coefficient for Mode {i + 1}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "def svd_analysis(displacement_matrix, energy_threshold=0.999, sv_threshold=1e-19, max_basis_plot=3):\n",
    "    print(\"\\n\" + \"-\" * 30 + \" MATRIX PROPERTIES \" + \"-\" * 30)\n",
    "    n_dof, n_snap = displacement_matrix.shape\n",
    "    print(f\"Shape:                    ({n_dof}, {n_snap}) (DOFs × snapshots)\")\n",
    "\n",
    "    # Perform SVD\n",
    "    U, S, Vt = np.linalg.svd(displacement_matrix, full_matrices=False)\n",
    "    condition_number = S[0] / S[-1]\n",
    "    numerical_rank = np.sum(S > 1e-14)\n",
    "    effective_rank = np.sum(S > 1e-10)\n",
    "    print(f\"Numerical rank:           {numerical_rank}\")\n",
    "    print(f\"Condition number:         {condition_number:.2e}\")\n",
    "    print(f\"Effective rank (1e-10):   {effective_rank}\")\n",
    "\n",
    "    # Energy calculations\n",
    "    energy = np.cumsum(S**2) / np.sum(S**2)\n",
    "    rank_energy = np.searchsorted(energy, energy_threshold) + 1\n",
    "    rank_sv = np.sum(S > sv_threshold)\n",
    "    final_rank = min(rank_energy, rank_sv)\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 27 + \" REDUCED BASIS SELECTION \" + \"-\" * 27)\n",
    "    print(f\"Energy threshold:         {energy_threshold:.3f} ({energy_threshold*100:.1f}%)\")\n",
    "    print(f\"SV threshold:             {sv_threshold:.1e}\")\n",
    "    print(f\"Rank by energy:           {rank_energy} (captures {energy[rank_energy-1]*100:.2f}% energy)\")\n",
    "    print(f\"Rank by SV threshold:     {rank_sv}\")\n",
    "    print(f\"Final selected rank:      {final_rank}\")\n",
    "    print(f\"Dimensionality reduction: {(1 - final_rank/n_dof)*100:.1f}% ({n_dof} → {final_rank})\")\n",
    "\n",
    "    # Table of singular values\n",
    "    print(\"\\n\" + \"-\" * 32 + \" MODE ANALYSIS \" + \"-\" * 33)\n",
    "    mode_table = []\n",
    "    for i in range(final_rank):\n",
    "        mode_table.append([i+1, f\"{S[i]:.3e}\", f\"{energy[i]*100:.2f}%\"])\n",
    "    print(tabulate(mode_table, headers=[\"Mode\", \"Singular Value\", \"Cumulative Energy\"], tablefmt=\"grid\"))\n",
    "\n",
    "    # Access programmatic output\n",
    "    U_r = U[:, :final_rank]\n",
    "    S_r = S[:final_rank]\n",
    "    Vt_r = Vt[:final_rank, :]\n",
    "    reduced_basis = U_r @ np.diag(S_r)\n",
    "\n",
    "    print(\"\\nAccessing specific results programmatically:\")\n",
    "    print(f\"Reduced basis shape: {reduced_basis.shape}\")\n",
    "    print(f\"First singular value: {S[0]:.3e}\")\n",
    "    print(f\"Dimensionality reduction: {(1 - final_rank/n_dof)*100:.1f}%\")\n",
    "\n",
    "    # === PLOTS ===\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # Plot 1: Singular values (log scale)\n",
    "    axs[0].semilogy(S, marker='o', color='blue')\n",
    "    axs[0].axhline(y=sv_threshold, color='r', linestyle='--', label=f'Threshold ({sv_threshold:.1e})')\n",
    "    axs[0].axvline(x=final_rank-1, color='green', linestyle=':', label=f'Selected rank ({final_rank})')\n",
    "    axs[0].set_title(\"Singular Values (Log Scale)\")\n",
    "    axs[0].set_xlabel(\"Mode Number\")\n",
    "    axs[0].set_ylabel(\"Singular Value (σ)\")\n",
    "    axs[0].grid(True)\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot 2: Cumulative Energy\n",
    "    axs[1].plot(energy, marker='o', color='green')\n",
    "    axs[1].axhline(y=energy_threshold, color='r', linestyle='--', label=f\"{energy_threshold*100:.1f}% threshold\")\n",
    "    axs[1].axvline(x=final_rank-1, color='green', linestyle=':', label=f'Selected rank ({final_rank})')\n",
    "    axs[1].set_title(\"Cumulative Energy\")\n",
    "    axs[1].set_xlabel(\"Mode Number\")\n",
    "    axs[1].set_ylabel(\"Fraction of Total Energy\")\n",
    "    axs[1].grid(True)\n",
    "    axs[1].legend()\n",
    "\n",
    "    # Plot 3: First few spatial basis vectors\n",
    "    for i in range(min(max_basis_plot, final_rank)):\n",
    "        axs[2].plot(U_r[:50, i], label=f'Basis {i+1}')\n",
    "    axs[2].set_title(f\"First {min(max_basis_plot, final_rank)} Basis Vectors (First 50 elements)\")\n",
    "    axs[2].set_xlabel(\"Degree of Freedom\")\n",
    "    axs[2].set_ylabel(\"Value\")\n",
    "    axs[2].legend()\n",
    "    axs[2].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'U_r': U_r,\n",
    "        'S_r': S_r,\n",
    "        'Vt_r': Vt_r,\n",
    "        'rank': final_rank,\n",
    "        'reduced_basis': reduced_basis,\n",
    "        'singular_values': S,\n",
    "        'cumulative_energy': energy\n",
    "    }\n",
    "\n",
    "# Example:\n",
    "results = svd_analysis(displacement_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Get system dimensions\n",
    "n_dof = M_constrained.shape[0]  # Number of degrees of freedom\n",
    "n_cases = f_constrained.shape[0]  # Number of load cases\n",
    "\n",
    "# Define x using the same values as x_analtical\n",
    "# x0 = np.zeros((1,n_dof)) # Displacement (m) as a 1x1 matrix\n",
    "x0 = x.flatten()  # Converts a 2D array to 1D if needed\n",
    "\n",
    "\n",
    "s = f_constrained.shape[0]\n",
    "# Initialize initial velocity as zero vector\n",
    "# v0 = np.zeros((n_dof))  # Initial velocities (n×m)\n",
    "v0 = np.zeros_like(x0)  # This will make sure v0 has the same shape as x0\n",
    "\n",
    "\n",
    "y0 = np.vstack([x0, v0])  # Stack initial conditions into a column vector|\n",
    "\n",
    "# Time step and total simulation time\n",
    "dt = 0.01               # Time step = T/200\n",
    "total_time = 20          # Total simulation time\n",
    "\n",
    "# Calculate number of steps\n",
    "n_steps = int(total_time / dt) + 1\n",
    "\n",
    "# Compute M⁻¹\n",
    "M_inv = np.linalg.inv(M_constrained)\n",
    "\n",
    "print(np.zeros((n_dof,1)).shape)\n",
    "prod = M_inv@f_constrained\n",
    "print(prod.shape)\n",
    "\n",
    "# Define system matrix A and input vector B\n",
    "A = np.block([\n",
    "    [np.zeros((n_dof, n_dof)), np.eye(n_dof)], \n",
    "    [-M_inv @ K_constrained, np.zeros((n_dof, n_dof))]\n",
    "])\n",
    "\n",
    "B = np.vstack([np.zeros((n_dof, 1)), M_inv @ f_constrained])\n",
    "\n",
    "# Time span\n",
    "t_span = (0, total_time)  # From t=0 to t=1\n",
    "t_eval = np.linspace(0, total_time, n_steps)  # Time points where the solution is evaluated\n",
    "\n",
    "def dUdt(t, y):\n",
    "    return A @ y + B.flatten()\n",
    "\n",
    "\n",
    "# Get number of cases and magnitudes\n",
    "num_cases = f_constrained.shape[1]\n",
    "\n",
    "# Create the base directory\n",
    "base_dir = Path(\"Dynamic_solution\")\n",
    "base_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Print initial information\n",
    "print(\"Starting multi-case dynamic analysis...\")\n",
    "print(f\"Function called with:\\nM: {M_constrained.shape}, K: {K_constrained.shape}, f: {f_constrained.shape}, magnitudes: {magnitudes}, x: {x0.shape}\\n\")\n",
    "print(f\"Number of cases: {num_cases}\")\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "case_times = []\n",
    "\n",
    "# Solve the system for each case\n",
    "start_time = time.time()\n",
    "for case in tqdm(range(num_cases), desc=\"Solving cases\"):\n",
    "    case_start_time = time.time()\n",
    "    print(f\"\\nSolving case {case + 1}/{num_cases}\")\n",
    "    magnitude = magnitudes[case]\n",
    "    print(f\"Magnitude: {magnitude}\")\n",
    "    \n",
    "    # Create case folder name\n",
    "    magnitude_str = \", \".join(str(val) for val in magnitude)\n",
    "    case_folder = base_dir / f\"case_{case+1}_magnitude_({magnitude_str})\"\n",
    "    analytical_folder = case_folder / \"Analytical_Solution\"\n",
    "    analytical_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Solve the system\n",
    "    sol = solve_ivp(dUdt, t_span, y0, t_eval=t_eval, method='RK45', atol=1e-10, rtol=1e-10)\n",
    "    \n",
    "    # Extract results\n",
    "    t = sol.t\n",
    "    U = sol.y\n",
    "    u = U[:s]  # Velocity\n",
    "    v = U[s:]  # Displacement\n",
    "    a = np.linalg.solve(M_constrained, f_constrained - (K_constrained @ u))  # Acceleration\n",
    "    \n",
    "    # Save results\n",
    "    np.save(analytical_folder / 'time.npy', t)\n",
    "    np.save(analytical_folder / 'displacement.npy', u)\n",
    "    np.save(analytical_folder / 'velocity.npy', v)\n",
    "    np.save(analytical_folder / 'acceleration.npy', a)\n",
    "    \n",
    "    # Store summary results\n",
    "    case_time = time.time() - case_start_time\n",
    "    case_times.append(case_time)\n",
    "    \n",
    "    results.append({\n",
    "        \"case\": case + 1,\n",
    "        \"magnitude\": magnitude,\n",
    "        \"max_displacement\": np.max(np.abs(u)),\n",
    "        \"max_velocity\": np.max(np.abs(v)),\n",
    "        \"max_acceleration\": np.max(np.abs(a)),\n",
    "        \"solve_time\": case_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Case {case + 1} completed in {case_time:.2f} seconds.\")\n",
    "    print(f\"Results saved to {analytical_folder}\")\n",
    "\n",
    "# Print results summary\n",
    "print(\"\\nResults Summary:\")\n",
    "print(\"=\" * 80)\n",
    "summary_data = [[r[\"case\"], \n",
    "                str(r[\"magnitude\"]), \n",
    "                f\"{r['max_displacement']:.2e}\",\n",
    "                f\"{r['max_velocity']:.2e}\", \n",
    "                f\"{r['max_acceleration']:.2e}\",\n",
    "                f\"{r['solve_time']:.2f}\"] for r in results]\n",
    "\n",
    "headers = [\"Case\", \"Magnitude\", \"Max Displacement\", \"Max Velocity\", \"Max Acceleration\", \"Solve Time (s)\"]\n",
    "print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Print overall statistics\n",
    "total_time = sum(case_times)\n",
    "print(\"\\nOverall Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total computation time: {total_time:.2f} seconds\")\n",
    "print(f\"Average time per case: {total_time/num_cases:.2f} seconds\")\n",
    "print(f\"Number of cases: {num_cases}\")\n",
    "print(f\"Fastest case: {min(case_times):.2f} seconds (Case {np.argmin(case_times)+1})\")\n",
    "print(f\"Slowest case: {max(case_times):.2f} seconds (Case {np.argmax(case_times)+1})\")\n",
    "\n",
    "# Print maximum values for each mode\n",
    "for mode in range(u.shape[0]):\n",
    "    print(f\"Mode {mode + 1}:\")\n",
    "    print(f\"  Maximum displacement: {np.max(np.abs(u[mode, :])):.2e}\")\n",
    "    print(f\"  Maximum velocity: {np.max(np.abs(v[mode, :])):.2e}\")\n",
    "    print(f\"  Maximum acceleration: {np.max(np.abs(a[mode, :])):.2e}\")\n",
    "\n",
    "print(f\"\\nAnalysis complete. Results saved in: {base_dir.resolve()}\")\n",
    "\n",
    "max_displacement_combined = np.sum([np.max(np.abs(u[mode, :])) for mode in range(u.shape[0])])\n",
    "print(f\"\\nMaximum displacement considering both modes: {max_displacement_combined}\")\n",
    "print(np.max(np.abs(u)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDOF System Solver using State-Space Approach (Using MATLAB Logic)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def mdof_system_dynamics(t, y, A, B):\n",
    "    return A @ y + B.flatten()\n",
    "\n",
    "\n",
    "def solve_mdof(M, K, f, magnitudes, X, total_time, dt):\n",
    "    n_dof = M.shape[0]\n",
    "    num_cases = f.shape[1]\n",
    "    time_steps = np.arange(0, total_time, dt)\n",
    "    t_span = (0, total_time)\n",
    "\n",
    "    M_inv = np.linalg.inv(M)  # Compute once and reuse\n",
    "    MK_product = M_inv @ K  # Pre-compute M^-1 * K\n",
    "\n",
    "    results = []\n",
    "    case_times = []\n",
    "\n",
    "    print(\"\\nStarting multi-case dynamic analysis...\\n\")\n",
    "    print(f\"Number of cases: {num_cases}\")\n",
    "    print(f\"System DOFs: {n_dof}\")\n",
    "\n",
    "    for case in tqdm(range(num_cases), desc=\"Solving cases\"):\n",
    "        F = f[:, case]  # Extract force vector for the current case\n",
    "        initial_displacement = X[:, case]  # Extract initial displacement for the current case\n",
    "        initial_velocity = np.zeros(n_dof)\n",
    "\n",
    "        # Ensure y0 is correctly initialized\n",
    "        y0 = np.concatenate([initial_displacement.flatten(), initial_velocity.flatten()])\n",
    "\n",
    "        # Define system matrix A\n",
    "        A = np.block([\n",
    "            [np.zeros((n_dof, n_dof)), np.eye(n_dof)],\n",
    "            [-MK_product, np.zeros((n_dof, n_dof))]  # Reusing precomputed MK_product\n",
    "        ])\n",
    "\n",
    "        # Create the B matrix ensuring it matches dimensions\n",
    "        F_case = M_inv @ F  # Directly use the force vector for this case\n",
    "        B = np.hstack([np.zeros(n_dof), F_case]).reshape(-1, 1)\n",
    "\n",
    "        case_start_time = time.time()\n",
    "\n",
    "        # Solving using solve_ivp\n",
    "        sol = solve_ivp(mdof_system_dynamics, t_span, y0, t_eval=time_steps, args=(A, B), method='RK45', rtol=1e-10, atol=1e-10)\n",
    "\n",
    "        U = sol.y\n",
    "        displacement = U[:n_dof, :]\n",
    "        velocity = U[n_dof:, :]\n",
    "\n",
    "        # Compute acceleration at each time step (using precomputed MK_product)\n",
    "        acceleration = np.array([np.linalg.solve(M, F - K @ displacement[:, i]) for i in range(len(time_steps))])\n",
    "\n",
    "        case_time = time.time() - case_start_time\n",
    "        case_times.append(case_time)\n",
    "\n",
    "        results.append({\n",
    "            \"case\": case + 1,\n",
    "            \"magnitude\": magnitudes[case],\n",
    "            \"max_displacement\": np.max(np.abs(displacement)),\n",
    "            \"max_velocity\": np.max(np.abs(velocity)),\n",
    "            \"max_acceleration\": np.max(np.abs(acceleration)),\n",
    "            \"solve_time\": case_time\n",
    "        })\n",
    "\n",
    "        print(f\"\\nCase {case + 1}/{num_cases} completed in {case_time:.2f} seconds.\")\n",
    "        print(f\"Maximum Displacement: {np.max(np.abs(displacement)):.2e}\")\n",
    "        print(f\"Maximum Velocity: {np.max(np.abs(velocity)):.2e}\")\n",
    "        print(f\"Maximum Acceleration: {np.max(np.abs(acceleration)):.2e}\\n\")\n",
    "\n",
    "    return results, case_times\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "# Matrices M, K, f_constrained, X, and magnitudes are already defined externally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time parameters\n",
    "total_time = 1.0   # Total simulation time (adjust as needed)\n",
    "dt = 0.01           # Time step size\n",
    "\n",
    "# Call the function with your matrices\n",
    "results, case_times = solve_mdof(\n",
    "    M=M_constrained,\n",
    "    K=K_constrained,\n",
    "    f=f_constrained,\n",
    "    magnitudes=magnitudes,\n",
    "    X=x,\n",
    "    total_time=total_time,\n",
    "    dt=dt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDOF System Solver using State-Space Approach (Using MATLAB Logic)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def mdof_system_dynamics(t, y, A, B):\n",
    "    return A @ y + B.flatten()\n",
    "\n",
    "\n",
    "def solve_mdof(M, K, f, magnitudes, x, total_time, dt):\n",
    "    n_dof = M.shape[0]\n",
    "    num_cases = f.shape[1]\n",
    "    time_steps = np.arange(0, total_time, dt)\n",
    "    t_span = (0, total_time)\n",
    "\n",
    "    M_inv = np.linalg.inv(M)\n",
    "\n",
    "    results = []\n",
    "    case_times = []\n",
    "\n",
    "    for case in tqdm(range(num_cases), desc=\"Solving cases\"):\n",
    "        F = f[:, case]  # Extract force vector for the current case\n",
    "        initial_displacement = x[:, case]  # Extract initial displacement for the current case\n",
    "        initial_velocity = np.zeros(n_dof)\n",
    "\n",
    "        # Ensure y0 is of size 2*n_dof\n",
    "        y0 = np.concatenate([initial_displacement.flatten(), initial_velocity.flatten()])\n",
    "\n",
    "        # Define system matrix A and input matrix B (Based on MATLAB logic)\n",
    "        A = np.block([\n",
    "            [np.zeros((n_dof, n_dof)), np.eye(n_dof)],\n",
    "            [-M_inv @ K, np.zeros((n_dof, n_dof))]\n",
    "        ])\n",
    "\n",
    "        F_case = M_inv @ F.reshape(-1, 1)  # Ensure force is a column vector\n",
    "        B = np.vstack([np.zeros((n_dof, 1)), F_case])  # B must have size (2*n_dof, 1)\n",
    "\n",
    "        case_start_time = time.time()\n",
    "\n",
    "        # Solving using solve_ivp\n",
    "        sol = solve_ivp(mdof_system_dynamics, t_span, y0, t_eval=time_steps, args=(A, B), method='RK45')\n",
    "\n",
    "        U = sol.y\n",
    "        displacement = U[:n_dof, :]\n",
    "        velocity = U[n_dof:, :]\n",
    "\n",
    "        # Compute acceleration at each time step\n",
    "        acceleration = np.array([np.linalg.solve(M, F - K @ displacement[:, i]) for i in range(len(time_steps))])\n",
    "\n",
    "        case_time = time.time() - case_start_time\n",
    "        case_times.append(case_time)\n",
    "\n",
    "        results.append({\n",
    "            \"case\": case + 1,\n",
    "            \"magnitude\": magnitudes[case],\n",
    "            \"max_displacement\": np.max(np.abs(displacement)),\n",
    "            \"max_velocity\": np.max(np.abs(velocity)),\n",
    "            \"max_acceleration\": np.max(np.abs(acceleration)),\n",
    "            \"solve_time\": case_time\n",
    "        })\n",
    "\n",
    "    return results, case_times\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "# Matrices M, K, f, x, and magnitudes are already defined externally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your matrices and input values\n",
    "M = M_constrained          # Your mass matrix (e.g., shape (612, 612))\n",
    "K = K_constrained          # Your stiffness matrix (e.g., shape (612, 612))\n",
    "f = f_constrained          # Your force matrix (e.g., shape (612, num_cases))\n",
    "x = x                      # Your initial displacement matrix (e.g., shape (612, num_cases))\n",
    "magnitudes = magnitudes    # List of magnitudes for each case (e.g., [(1.0, 0.5), (2.0, 1.0)])\n",
    "\n",
    "# Time-related parameters\n",
    "total_time = 20.0          # Total simulation time\n",
    "dt = 0.01                  # Time step size\n",
    "\n",
    "results, case_times = solve_mdof(M, K, f, magnitudes, x, total_time, dt)\n",
    "# def solve_mdof(M, K, f, magnitudes, x, total_time, dt):\n",
    "\n",
    "# Print results summary\n",
    "print(\"\\nResults Summary:\")\n",
    "print(\"=\" * 80)\n",
    "summary_data = [[r[\"case\"], r[\"magnitude\"], f\"{r['max_displacement']:.2e}\", f\"{r['max_velocity']:.2e}\", f\"{r['max_acceleration']:.2e}\", f\"{r['solve_time']:.2f}\"] for r in results]\n",
    "\n",
    "headers = [\"Case\", \"Magnitude\", \"Max Displacement\", \"Max Velocity\", \"Max Acceleration\", \"Solve Time (s)\"]\n",
    "print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDOF System Solver using State-Space Approach\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def mdof_system_dynamics(t, y, M, K, F):\n",
    "    n = M.shape[0]\n",
    "    x = y[:n]\n",
    "    x_dot = y[n:]\n",
    "\n",
    "    # Compute acceleration\n",
    "    x_ddot = np.linalg.solve(M, F - K @ x)\n",
    "\n",
    "    return np.concatenate((x_dot, x_ddot))\n",
    "\n",
    "\n",
    "def solve_mdof(M, K, f, magnitudes, x, total_time, dt):\n",
    "    n_dof = M.shape[0]\n",
    "    num_cases = f.shape[1]\n",
    "    time_steps = np.arange(0, total_time, dt)\n",
    "    t_span = (0, total_time)\n",
    "\n",
    "    results = []\n",
    "    case_times = []\n",
    "\n",
    "    for case in tqdm(range(num_cases), desc=\"Solving cases\"):\n",
    "        F = f[:, case]\n",
    "        initial_displacement = x[:, case]\n",
    "        initial_velocity = np.zeros(n_dof)\n",
    "        y0 = np.concatenate((initial_displacement, initial_velocity))\n",
    "\n",
    "        case_start_time = time.time()\n",
    "\n",
    "        sol = solve_ivp(mdof_system_dynamics, t_span, y0, t_eval=time_steps, args=(M, K, F), method='RK45')\n",
    "\n",
    "        displacement = sol.y[:n_dof, :].T\n",
    "        velocity = sol.y[n_dof:, :].T\n",
    "        # acceleration = np.array([np.linalg.solve(M, F - K @ displacement[i, :]) for i in range(len(time))])\n",
    "        acceleration = np.array([np.linalg.solve(M, F - K @ displacement[i, :]) for i in range(len(time_steps))])\n",
    "\n",
    "\n",
    "\n",
    "        case_time = time.time() - case_start_time\n",
    "        case_times.append(case_time)\n",
    "\n",
    "        results.append({\n",
    "            \"case\": case + 1,\n",
    "            \"magnitude\": magnitudes[case],\n",
    "            \"max_displacement\": np.max(np.abs(displacement)),\n",
    "            \"max_velocity\": np.max(np.abs(velocity)),\n",
    "            \"max_acceleration\": np.max(np.abs(acceleration)),\n",
    "            \"solve_time\": case_time\n",
    "        })\n",
    "\n",
    "    return results, case_times\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "M = np.array([[2.0, 0.0], [0.0, 1.0]])  # Mass matrix\n",
    "K = np.array([[10.0, -2.0], [-2.0, 5.0]])  # Stiffness matrix\n",
    "f = np.zeros((2, 1))  # External force for one case\n",
    "magnitudes = [(1.0, 0.5)]\n",
    "x = np.array([[1.0, 0.0], [0.5, 0.0]])\n",
    "\n",
    "total_time = 0.01\n",
    "dt = 3.14e-6\n",
    "\n",
    "results, case_times = solve_mdof(M, K, f, magnitudes, x, total_time, dt)\n",
    "\n",
    "# Print results summary\n",
    "print(\"\\nResults Summary:\")\n",
    "print(\"=\" * 80)\n",
    "summary_data = [[r[\"case\"], r[\"magnitude\"], f\"{r['max_displacement']:.2e}\", f\"{r['max_velocity']:.2e}\", f\"{r['max_acceleration']:.2e}\", f\"{r['solve_time']:.2f}\"] for r in results]\n",
    "\n",
    "headers = [\"Case\", \"Magnitude\", \"Max Displacement\", \"Max Velocity\", \"Max Acceleration\", \"Solve Time (s)\"]\n",
    "print(tabulate(summary_data, headers=headers, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import os\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "\n",
    "def create_displacement_animation(case_folder, mdpa_file, scale_factor=1e7, step_interval=100):\n",
    "    \"\"\"\n",
    "    Create an animated GIF of displacement field for a specific case.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    case_folder: Path object, full path to case folder\n",
    "    mdpa_file: str, path to mdpa file\n",
    "    scale_factor: float, scaling factor for displacements\n",
    "    step_interval: int, time in milliseconds between frames\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output filename from case folder name\n",
    "        output_file = case_folder / 'displacement_animation.gif'\n",
    "        \n",
    "        print(f\"\\nProcessing: {case_folder.name}\")\n",
    "        \n",
    "        # Load solution data\n",
    "        time = np.load(case_folder / \"time.npy\")\n",
    "        displacement = np.load(case_folder / \"displacement.npy\")\n",
    "        \n",
    "        print(f\"Loaded displacement data shape: {displacement.shape}\")\n",
    "        print(f\"Time steps available: {len(time)}\")\n",
    "        \n",
    "        # Read node coordinates and elements\n",
    "        node_coords = []\n",
    "        elements = []\n",
    "        reading_nodes = False\n",
    "        reading_elements = False\n",
    "        \n",
    "        with open(mdpa_file, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                \n",
    "                if \"Begin Nodes\" in line:\n",
    "                    reading_nodes = True\n",
    "                    continue\n",
    "                elif \"End Nodes\" in line:\n",
    "                    reading_nodes = False\n",
    "                    continue\n",
    "                elif reading_nodes and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4:\n",
    "                        x, y = float(parts[1]), float(parts[2])\n",
    "                        node_coords.append([x, y])\n",
    "                        \n",
    "                if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                    reading_elements = True\n",
    "                    continue\n",
    "                elif reading_elements and \"End Elements\" in line:\n",
    "                    reading_elements = False\n",
    "                    continue\n",
    "                elif reading_elements and line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 5:\n",
    "                        n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "                        elements.append([n1, n2, n3])\n",
    "        \n",
    "        node_coords = np.array(node_coords)\n",
    "        elements = np.array(elements)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=(10, 15))\n",
    "        \n",
    "        # Create base triangulation for undeformed mesh\n",
    "        x = node_coords[:, 0]\n",
    "        y = node_coords[:, 1]\n",
    "        triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "        \n",
    "        # Find global displacement limits for consistent colorbar\n",
    "        disp_magnitudes = []\n",
    "        for step in range(len(time)):\n",
    "            disp = displacement[:, step].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            disp_magnitudes.append(disp_mag)\n",
    "        \n",
    "        global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "        global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "        \n",
    "        print(f\"Animation Information:\")\n",
    "        print(f\"Total frames: {len(time)}\")\n",
    "        print(f\"Time range: [{time[0]:.3f}, {time[-1]:.3f}] seconds\")\n",
    "        print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "        \n",
    "        def update(frame):\n",
    "            ax.clear()\n",
    "            \n",
    "            # Get displacements for current frame\n",
    "            disp = displacement[:, frame].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            \n",
    "            # Calculate deformed coordinates\n",
    "            deformed_coords = node_coords + disp\n",
    "            \n",
    "            # Plot undeformed mesh\n",
    "            ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "            \n",
    "            # Plot deformed mesh with displacement magnitude coloring\n",
    "            triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "            tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                             vmin=global_min, vmax=global_max)\n",
    "            ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "            \n",
    "            # Set labels and title\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "            \n",
    "            ax.grid(True)\n",
    "            ax.axis('equal')\n",
    "            ax.legend()\n",
    "            \n",
    "            # Add colorbar only once\n",
    "            if frame == 0:\n",
    "                plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Print progress\n",
    "            if frame % 10 == 0:\n",
    "                print(f\"Processing frame {frame}/{len(time)-1}\")\n",
    "        \n",
    "        # Create animation\n",
    "        print(\"Creating animation...\")\n",
    "        anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "        \n",
    "        # Save animation\n",
    "        print(f\"Saving animation to {output_file}\")\n",
    "        writer = PillowWriter(fps=1000/step_interval)\n",
    "        anim.save(output_file, writer=writer)\n",
    "        \n",
    "        plt.close()\n",
    "        print(\"Animation completed!\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {case_folder.name}: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "    \n",
    "def process_all_cases(base_dir=\"Dynamic_solution\", scale_factor=1e7):\n",
    "    \"\"\"Process all cases in the Dynamic_solution directory.\"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    \n",
    "    # Find all case folders dynamically\n",
    "    case_folders = list(base_path.glob(\"case_*_magnitude_*/Analytical_Solution\"))\n",
    "    \n",
    "    # Sort case folders by case number\n",
    "    def extract_case_number(folder_name):\n",
    "        # Extract the case number from the folder name (e.g., \"case_1_magnitude_0.1\" -> 1)\n",
    "        return int(folder_name.parts[-2].split(\"_\")[1])\n",
    "    \n",
    "    case_folders.sort(key=extract_case_number)\n",
    "    \n",
    "    print(f\"Found {len(case_folders)} cases to process\")\n",
    "    print(\"\\nProcessing order:\")\n",
    "    for folder in case_folders:\n",
    "        print(f\"  {folder.parent.name}\")\n",
    "    \n",
    "    # Find the .mdpa file in the current working directory\n",
    "    cwd = Path.cwd()\n",
    "    mdpa_file = next((f for f in cwd.glob(\"*.mdpa\")), None)\n",
    "    if mdpa_file is None:\n",
    "        raise FileNotFoundError(\"No .mdpa file found in the current directory.\")\n",
    "    \n",
    "    print(f\"Using .mdpa file: {mdpa_file}\")\n",
    "    \n",
    "    # Process each case\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for folder in case_folders:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {folder.parent.name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if create_displacement_animation(folder, mdpa_file, scale_factor):\n",
    "            successful += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Processing Complete!\")\n",
    "    print(f\"Successfully processed: {successful} cases\")\n",
    "    print(f\"Failed to process: {failed} cases\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Run the processing\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        process_all_cases(\n",
    "            base_dir=\"Dynamic_solution\",\n",
    "            scale_factor=1e6  # Adjust this if needed   \n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_with_solve_ivp(M_constrained, K_constrained, x, f_constrained, t_total=1.0, n_divisions=100):\n",
    "    # Get dimensions\n",
    "    n_dof, n_cases = x.shape\n",
    "    \n",
    "    # Precompute inverse of mass matrix\n",
    "    M_inv = np.linalg.inv(M_constrained)\n",
    "    \n",
    "    # Time parameters\n",
    "    t_eval = np.linspace(0, t_total, n_divisions + 1)\n",
    "    \n",
    "    # Initialize arrays\n",
    "    u_results = np.zeros((n_divisions + 1, n_dof, n_cases))\n",
    "    v_results = np.zeros((n_divisions + 1, n_dof, n_cases))\n",
    "    a_results = np.zeros((n_divisions + 1, n_dof, n_cases))\n",
    "    \n",
    "    # Define zero initial velocity matrix\n",
    "    v0_matrix = np.zeros_like(x)\n",
    "    \n",
    "    # Solve for each case\n",
    "    for case in range(n_cases):\n",
    "        u0 = x[:, case]\n",
    "        v0 = v0_matrix[:, case]\n",
    "        F = f_constrained[:, case]\n",
    "        \n",
    "        # Initial state vector\n",
    "        y0 = np.concatenate([u0, v0])\n",
    "        \n",
    "        # Solver with jit_function option to compile the RHS function\n",
    "        sol = solve_ivp(\n",
    "            lambda t, y: np.concatenate([\n",
    "                y[n_dof:], \n",
    "                M_inv @ (F - K_constrained @ y[:n_dof])\n",
    "            ]),\n",
    "            (0, t_total),\n",
    "            y0,\n",
    "            t_eval=t_eval,\n",
    "            method='Radau',  # Use Radau which is good for stiff problems\n",
    "            # rtol=1e-3,       # Looser tolerance for speed\n",
    "            # atol=1e-6\n",
    "        )\n",
    "        \n",
    "        # Extract results\n",
    "        u_results[:, :, case] = sol.y[:n_dof, :].T\n",
    "        v_results[:, :, case] = sol.y[n_dof:, :].T\n",
    "        \n",
    "        # Calculate accelerations\n",
    "        for i in range(n_divisions + 1):\n",
    "            a_results[i, :, case] = M_inv @ (F - K_constrained @ u_results[i, :, case])\n",
    "    \n",
    "    return u_results, v_results, a_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the optimized solver\n",
    "u_results, v_results, a_results = solve_dynamic_system_cas(\n",
    "    M_constrained, K_constrained, x, f_constrained, \n",
    "    t_total=1.0, n_divisions=100\n",
    ")\n",
    "\n",
    "# Results are in shape (n_steps+1, n_dof, n_cases)\n",
    "# u_results[i,j,k] is the displacement of DOF j at time step i for case k\n",
    "# v_results[i,j,k] is the velocity of DOF j at time step i for case k\n",
    "# a_results[i,j,k] is the acceleration of DOF j at time step i for case k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "def system_of_odes(t, y, M_inv, K, F):\n",
    "    \"\"\"\n",
    "    Define the system of ODEs for the dynamic system.\n",
    "    \"\"\"\n",
    "    x, v = y[:len(M_inv)], y[len(M_inv):]\n",
    "    dxdt = v\n",
    "    dvdt = M_inv @ (F - K @ x)  # Use precomputed M_inv\n",
    "    return np.concatenate((dxdt, dvdt))\n",
    "\n",
    "def save_case_results(results, case_dir, prefix=\"analytical\"):\n",
    "    \"\"\"\n",
    "    Save results for a single case with comprehensive solution storage.\n",
    "    \"\"\"\n",
    "    # Create solution directory\n",
    "    solution_dir = case_dir / 'solution'\n",
    "    solution_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save raw solution arrays as .npy files\n",
    "    np.save(solution_dir / f'{prefix}_time.npy', results['time'])\n",
    "    np.save(solution_dir / f'{prefix}_displacement.npy', results['displacement'])\n",
    "    np.save(solution_dir / f'{prefix}_velocity.npy', results['velocity'])\n",
    "    np.save(solution_dir / f'{prefix}_acceleration.npy', results['acceleration'])\n",
    "    \n",
    "    # Save time history data in compressed format\n",
    "    np.savez(case_dir / f'{prefix}_time_history.npz',\n",
    "             time=results['time'],\n",
    "             displacement=results['displacement'],\n",
    "             velocity=results['velocity'],\n",
    "             acceleration=results['acceleration'])\n",
    "    \n",
    "    # Save summary statistics\n",
    "    with open(case_dir / f'{prefix}_summary.txt', 'w') as f:\n",
    "        f.write(\"Results Summary:\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(f\"Time steps completed: {len(results['time'])}\\n\")\n",
    "        f.write(f\"Maximum displacement: {np.max(np.abs(results['displacement'])):.2e}\\n\")\n",
    "        f.write(f\"Maximum velocity: {np.max(np.abs(results['velocity'])):.2e}\\n\")\n",
    "        f.write(f\"Maximum acceleration: {np.max(np.abs(results['acceleration'])):.2e}\\n\")\n",
    "        f.write(\"\\nFile Locations:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(f\"Solution arrays (.npy files): {solution_dir}\\n\")\n",
    "        f.write(f\"Time history: {case_dir/f'{prefix}_time_history.npz'}\\n\")\n",
    "\n",
    "def solve_dynamic_system(M, K, F, x0, t_span, t_eval, case_dir):\n",
    "    \"\"\"\n",
    "    Solve the dynamic system for a single case and save the results.\n",
    "    \"\"\"\n",
    "    # Precompute the inverse of the mass matrix\n",
    "    M_inv = np.linalg.inv(M)\n",
    "    \n",
    "    # Initial conditions\n",
    "    v0 = np.zeros_like(x0)\n",
    "    y0 = np.concatenate((x0, v0))\n",
    "    \n",
    "    # Solve the ODE\n",
    "    sol = solve_ivp(system_of_odes, t_span, y0, args=(M_inv, K, F), t_eval=t_eval, method='RK45')\n",
    "    \n",
    "    # Extract results\n",
    "    displacement = sol.y[:len(M), :]\n",
    "    velocity = sol.y[len(M):, :]\n",
    "    acceleration = np.gradient(velocity, t_eval, axis=1)\n",
    "    \n",
    "    # Prepare results dictionary\n",
    "    results = {\n",
    "        'time': t_eval,\n",
    "        'displacement': displacement,\n",
    "        'velocity': velocity,\n",
    "        'acceleration': acceleration\n",
    "    }\n",
    "    \n",
    "    # Save results\n",
    "    save_case_results(results, case_dir)\n",
    "\n",
    "# Example usage\n",
    "# M_constrained = np.array(...)  # Mass matrix (612, 612)\n",
    "# K_constrained = np.array(...)  # Stiffness matrix (612, 612)\n",
    "# f_constrained = np.array(...)  # Force vector (612, num_cases)\n",
    "# x = np.array(...)  # Initial displacement (612, num_cases)\n",
    "\n",
    "# Determine the number of cases\n",
    "num_cases = f_constrained.shape[1]\n",
    "\n",
    "# Define time span and evaluation points\n",
    "t_span = (0, 1)  # Example time span\n",
    "t_eval = np.linspace(t_span[0], t_span[1], num=100)  # Time points for evaluation\n",
    "\n",
    "# Start time tracking\n",
    "start_time = time.time()\n",
    "\n",
    "# Loop through each case\n",
    "for case_idx in range(num_cases):\n",
    "    case_dir = Path(f\"case_{case_idx}\")\n",
    "    case_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Extract force and initial displacement for the current case\n",
    "    F = f_constrained[:, case_idx]\n",
    "    x0 = x[:, case_idx]\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Solving Case {case_idx + 1}/{num_cases}...\")\n",
    "    \n",
    "    # Solve the dynamic system for the current case\n",
    "    solve_dynamic_system(M_constrained, K_constrained, F, x0, t_span, t_eval, case_dir)\n",
    "    \n",
    "    # Print time elapsed for the current case\n",
    "    case_time = time.time() - start_time\n",
    "    print(f\"Case {case_idx + 1} completed in {case_time:.2f} seconds.\")\n",
    "\n",
    "# Total time elapsed\n",
    "total_time = time.time() - start_time\n",
    "print(f\"All cases completed in {total_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def system_of_odes(t, y, M_inv, M_inv_K, F):\n",
    "    \"\"\"\n",
    "    Define the system of ODEs for the dynamic system.\n",
    "    \"\"\"\n",
    "    print(f\"Solving at time t = {t}\")\n",
    "    x, v = y[:len(M_inv)], y[len(M_inv):]\n",
    "    dxdt = v\n",
    "    # dvdt = M_inv @ (F - K @ x)  # Use precomputed M_inv\n",
    "    dvdt = M_inv @ F - M_inv_K @ x\n",
    "    return np.concatenate((dxdt, dvdt))\n",
    "\n",
    "def save_case_results(results, case_dir, prefix=\"analytical\"):\n",
    "    \"\"\"\n",
    "    Save results for a single case with comprehensive solution storage.\n",
    "    \"\"\"\n",
    "    # Create solution directory\n",
    "    solution_dir = case_dir / 'solution'\n",
    "    solution_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save raw solution arrays as .npy files\n",
    "    np.save(solution_dir / f'{prefix}_time.npy', results['time'])\n",
    "    np.save(solution_dir / f'{prefix}_displacement.npy', results['displacement'])\n",
    "    np.save(solution_dir / f'{prefix}_velocity.npy', results['velocity'])\n",
    "    np.save(solution_dir / f'{prefix}_acceleration.npy', results['acceleration'])\n",
    "    \n",
    "    # Save time history data in compressed format\n",
    "    np.savez(case_dir / f'{prefix}_time_history.npz',\n",
    "             time=results['time'],\n",
    "             displacement=results['displacement'],\n",
    "             velocity=results['velocity'],\n",
    "             acceleration=results['acceleration'])\n",
    "    \n",
    "    # Save summary statistics\n",
    "    with open(case_dir / f'{prefix}_summary.txt', 'w') as f:\n",
    "        f.write(\"Results Summary:\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(f\"Time steps completed: {len(results['time'])}\\n\")\n",
    "        f.write(f\"Maximum displacement: {np.max(np.abs(results['displacement'])):.2e}\\n\")\n",
    "        f.write(f\"Maximum velocity: {np.max(np.abs(results['velocity'])):.2e}\\n\")\n",
    "        f.write(f\"Maximum acceleration: {np.max(np.abs(results['acceleration'])):.2e}\\n\")\n",
    "        f.write(\"\\nFile Locations:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(f\"Solution arrays (.npy files): {solution_dir}\\n\")\n",
    "        f.write(f\"Time history: {case_dir/f'{prefix}_time_history.npz'}\\n\")\n",
    "\n",
    "# def solve_dynamic_system(M, K, F, x0, t_span, t_eval, case_dir, magnitude):\n",
    "#     \"\"\"\n",
    "#     Solve the dynamic system for a single case and save the results.\n",
    "#     \"\"\"\n",
    "#     # Precompute the inverse of the mass matrix\n",
    "#     M_inv = np.linalg.inv(M)\n",
    "    \n",
    "#     # Initial conditions\n",
    "#     v0 = np.zeros_like(x0)\n",
    "#     y0 = np.concatenate((x0, v0))\n",
    "    \n",
    "#     # Solve the ODE\n",
    "#     sol = solve_ivp(system_of_odes, t_span, y0, args=(M_inv, K, F), t_eval=t_eval, method='RK45')\n",
    "    \n",
    "#     # Extract results\n",
    "#     displacement = sol.y[:len(M), :]\n",
    "#     velocity = sol.y[len(M):, :]\n",
    "#     acceleration = np.gradient(velocity, t_eval, axis=1)\n",
    "    \n",
    "#     # Prepare results dictionary\n",
    "#     results = {\n",
    "#         'time': t_eval,\n",
    "#         'displacement': displacement,\n",
    "#         'velocity': velocity,\n",
    "#         'acceleration': acceleration\n",
    "#     }\n",
    "    \n",
    "#     # Save results\n",
    "#     save_case_results(results, case_dir)\n",
    "    \n",
    "#     # Generate animation\n",
    "#     generate_animation(results, case_dir, magnitude)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "def solve_dynamic_system(M, K, F, x0, t_span, t_eval, case_dir, magnitude):\n",
    "    \"\"\"\n",
    "    Solve the dynamic system for a single case and save the results.\n",
    "    \"\"\"\n",
    "    # Precompute the inverse of the mass matrix\n",
    "    M_inv = np.linalg.inv(M)\n",
    "    \n",
    "    # Precompute M_inv @ K for efficiency\n",
    "    M_inv_K = M_inv @ K\n",
    "    \n",
    "    # Initial conditions\n",
    "    v0 = np.zeros_like(x0)\n",
    "    y0 = np.concatenate((x0, v0))\n",
    "    \n",
    "    # Solve the ODE\n",
    "    sol = solve_ivp(\n",
    "        system_of_odes, \n",
    "        t_span, \n",
    "        y0, \n",
    "        args=(M_inv, M_inv_K, F), \n",
    "        t_eval=t_eval, \n",
    "        method='BDF',  # Use a stiff solver\n",
    "        atol=1e-6,     # Absolute tolerance\n",
    "        rtol=1e-6      # Relative tolerance\n",
    "    )\n",
    "    \n",
    "    # Extract results\n",
    "    displacement = sol.y[:len(M), :]\n",
    "    velocity = sol.y[len(M):, :]\n",
    "    acceleration = M_inv @ (F[:, np.newaxis] - K @ displacement)\n",
    "    \n",
    "    # Prepare results dictionary\n",
    "    results = {\n",
    "        'time': t_eval,\n",
    "        'displacement': displacement,\n",
    "        'velocity': velocity,\n",
    "        'acceleration': acceleration\n",
    "    }\n",
    "    \n",
    "    # Save results\n",
    "    save_case_results(results, case_dir)\n",
    "    \n",
    "    # Generate animation\n",
    "    generate_animation(results, case_dir, magnitude)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def generate_animation(results, case_dir, magnitude):\n",
    "    \"\"\"\n",
    "    Generate an animation of the displacement over time and save it as a GIF.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    line, = ax.plot([], [], lw=2)\n",
    "    ax.set_xlim(min(results['time']), max(results['time']))\n",
    "    ax.set_ylim(np.min(results['displacement']), np.max(results['displacement']))\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Displacement')\n",
    "    ax.set_title(f'Case Magnitude: {magnitude}')\n",
    "    \n",
    "    def animate(i):\n",
    "        line.set_data(results['time'][:i], results['displacement'][0, :i])\n",
    "        return line,\n",
    "    \n",
    "    ani = animation.FuncAnimation(fig, animate, frames=len(results['time']), interval=50, blit=True)\n",
    "    ani.save(case_dir / 'displacement_animation.gif', writer='pillow')\n",
    "    plt.close()\n",
    "\n",
    "# def print_summary_table(results_list, magnitudes, solve_times):\n",
    "#     \"\"\"\n",
    "#     Print a summary table of the results.\n",
    "#     \"\"\"\n",
    "#     print(\"\\nResults Summary:\")\n",
    "#     print(\"=\" * 80)\n",
    "#     print(f\"{'Case':<6} | {'Magnitude':<30} | {'Max Displacement':<18} | {'Max Velocity':<14} | {'Max Acceleration':<18} | {'Solve Time (s)':<14}\")\n",
    "#     print(\"=\" * 80)\n",
    "#     for i, (results, magnitude, solve_time) in enumerate(zip(results_list, magnitudes, solve_times)):\n",
    "#         max_disp = np.max(np.abs(results['displacement']))\n",
    "#         max_vel = np.max(np.abs(results['velocity']))\n",
    "#         max_acc = np.max(np.abs(results['acceleration']))\n",
    "#         print(f\"{i+1:<6} | {str(magnitude):<30} | {max_disp:.2e} | {max_vel:.2e} | {max_acc:.2e} | {solve_time:.2f}\")\n",
    "#     print(\"=\" * 80)\n",
    "\n",
    "def print_summary_table(results_list, magnitudes, solve_times):\n",
    "    \"\"\"\n",
    "    Print a well-aligned summary table of the results.\n",
    "    \"\"\"\n",
    "    # Define column widths\n",
    "    col_widths = {\n",
    "        'case': 6,\n",
    "        'magnitude': 30,\n",
    "        'max_disp': 18,\n",
    "        'max_vel': 14,\n",
    "        'max_acc': 18,\n",
    "        'solve_time': 14\n",
    "    }\n",
    "    \n",
    "    # Print table header\n",
    "    header = (\n",
    "        f\"{'Case':<{col_widths['case']}} | \"\n",
    "        f\"{'Magnitude':<{col_widths['magnitude']}} | \"\n",
    "        f\"{'Max Displacement':<{col_widths['max_disp']}} | \"\n",
    "        f\"{'Max Velocity':<{col_widths['max_vel']}} | \"\n",
    "        f\"{'Max Acceleration':<{col_widths['max_acc']}} | \"\n",
    "        f\"{'Solve Time (s)':<{col_widths['solve_time']}}\"\n",
    "    )\n",
    "    separator = \"-\" * len(header)\n",
    "    \n",
    "    print(\"\\nResults Summary:\")\n",
    "    print(separator)\n",
    "    print(header)\n",
    "    print(separator)\n",
    "    \n",
    "    # Print each row\n",
    "    for i, (results, magnitude, solve_time) in enumerate(zip(results_list, magnitudes, solve_times)):\n",
    "        max_disp = np.max(np.abs(results['displacement']))\n",
    "        max_vel = np.max(np.abs(results['velocity']))\n",
    "        max_acc = np.max(np.abs(results['acceleration']))\n",
    "        \n",
    "        row = (\n",
    "            f\"{i+1:<{col_widths['case']}} | \"\n",
    "            f\"{str(magnitude):<{col_widths['magnitude']}} | \"\n",
    "            f\"{max_disp:<{col_widths['max_disp']}.2e} | \"\n",
    "            f\"{max_vel:<{col_widths['max_vel']}.2e} | \"\n",
    "            f\"{max_acc:<{col_widths['max_acc']}.2e} | \"\n",
    "            f\"{solve_time:<{col_widths['solve_time']}.2f}\"\n",
    "        )\n",
    "        print(row)\n",
    "    \n",
    "    print(separator)\n",
    "\n",
    "# def main():\n",
    "#     # Example inputs\n",
    "#     # M_constrained = np.random.rand(612, 612)  # Mass matrix (612, 612)\n",
    "#     # K_constrained = np.random.rand(612, 612)  # Stiffness matrix (612, 612)\n",
    "#     # f_constrained = np.random.rand(612, 5)    # Force vector (612, 5)\n",
    "#     # x = np.random.rand(612, 5)                # Initial displacement (612, 5)\n",
    "#     # magnitudes = [(-14.86, 219.86, -73.96), (-156.43, 241.68, -136.57), (247.25, 261.07, -32.92),\n",
    "#     #               (268.73, -248.86, 369.87), (343.57, 131.52, -255.83)]  # Example magnitudes\n",
    "    \n",
    "#     # Define time span and evaluation points\n",
    "#     t_span = (0, 1)  # Example time span\n",
    "#     t_eval = np.linspace(t_span[0], t_span[1], num=100)  # Time points for evaluation\n",
    "    \n",
    "#     # Start time tracking\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     # Print initial information\n",
    "#     print(\"Starting multi-case dynamic analysis...\")\n",
    "#     print(f\"Function called with:\\nM: {M_constrained.shape}, K: {K_constrained.shape}, f: {f_constrained.shape}, magnitudes: {magnitudes}, x: {x.shape}\")\n",
    "#     print(f\"\\nNumber of DOFs: {M_constrained.shape[0]}\")\n",
    "#     print(f\"Number of cases: {f_constrained.shape[1]}\")\n",
    "    \n",
    "#     # Loop through each case\n",
    "#     results_list = []\n",
    "#     solve_times = []\n",
    "#     for case_idx in tqdm(range(f_constrained.shape[1]), desc=\"Processing cases\"):\n",
    "#         case_dir = Path(f\"case_{case_idx}\")\n",
    "#         case_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "#         # Extract force and initial displacement for the current case\n",
    "#         F = f_constrained[:, case_idx]\n",
    "#         x0 = x[:, case_idx]\n",
    "#         magnitude = magnitudes[case_idx]\n",
    "        \n",
    "#         # Print case information\n",
    "#         print(f\"\\nSolving case {case_idx + 1}/{f_constrained.shape[1]}\")\n",
    "#         print(f\"Magnitude: {magnitude}\")\n",
    "#         # print(\"\\nMatrix scaling factors:\")\n",
    "#         # print(f\"Mass matrix scale: {np.linalg.norm(M_constrained):.2e}\")\n",
    "#         # print(f\"Stiffness matrix scale: {np.linalg.norm(K_constrained):.2e}\")\n",
    "#         # print(f\"Force vector scale: {np.linalg.norm(F):.2e}\")\n",
    "        \n",
    "#         # Solve the dynamic system for the current case\n",
    "#         case_start_time = time.time()\n",
    "#         results = solve_dynamic_system(M_constrained, K_constrained, F, x0, t_span, t_eval, case_dir, magnitude)\n",
    "#         case_solve_time = time.time() - case_start_time\n",
    "#         solve_times.append(case_solve_time)\n",
    "        \n",
    "#         # Append results\n",
    "#         results_list.append(results)\n",
    "        \n",
    "#         # Print time elapsed for the current case\n",
    "#         print(f\"Case {case_idx + 1} completed in {case_solve_time:.2f} seconds.\")\n",
    "    \n",
    "#     # Print summary table\n",
    "#     print_summary_table(results_list, magnitudes, solve_times)\n",
    "    \n",
    "#     # Total time elapsed\n",
    "#     total_time = time.time() - start_time\n",
    "#     print(f\"\\nOverall Statistics:\")\n",
    "#     print(\"=\" * 80)\n",
    "#     print(f\"Total computation time: {total_time:.2f} seconds\")\n",
    "#     print(f\"Average time per case: {np.mean(solve_times):.2f} seconds\")\n",
    "#     print(f\"Number of cases: {f_constrained.shape[1]}\")\n",
    "#     print(f\"Fastest case: {np.min(solve_times):.2f} seconds (Case {np.argmin(solve_times) + 1})\")\n",
    "#     print(f\"Slowest case: {np.max(solve_times):.2f} seconds (Case {np.argmax(solve_times) + 1})\")\n",
    "#     print(\"=\" * 80)\n",
    "#     print(\"\\nAnalysis complete. Results saved in: Dynamic_solution\")\n",
    "\n",
    "def main():\n",
    "    # Example inputs\n",
    "    # M_constrained = np.random.rand(612, 612)  # Mass matrix (612, 612)\n",
    "    # K_constrained = np.random.rand(612, 612)  # Stiffness matrix (612, 612)\n",
    "    # f_constrained = np.random.rand(612, 5)    # Force vector (612, 5)\n",
    "    # x = np.random.rand(612, 5)                # Initial displacement (612, 5)\n",
    "    # magnitudes = [(-14.86, 219.86, -73.96), (-156.43, 241.68, -136.57), (247.25, 261.07, -32.92),\n",
    "    #               (268.73, -248.86, 369.87), (343.57, 131.52, -255.83)]  # Example magnitudes\n",
    "    \n",
    "    # Define time span and evaluation points\n",
    "    t_span = (0, 1)  # Example time span\n",
    "    t_eval = np.linspace(t_span[0], t_span[1], num=100)  # Time points for evaluation\n",
    "    \n",
    "    # Start time tracking\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Print initial information\n",
    "    print(\"Starting multi-case dynamic analysis...\")\n",
    "    print(f\"Function called with:\\nM: {M_constrained.shape}, K: {K_constrained.shape}, f: {f_constrained.shape}, magnitudes: {magnitudes}, x: {x.shape}\")\n",
    "    print(f\"\\nNumber of DOFs: {M_constrained.shape[0]}\")\n",
    "    print(f\"Number of cases: {f_constrained.shape[1]}\")\n",
    "    \n",
    "    # Loop through each case\n",
    "    results_list = []\n",
    "    solve_times = []\n",
    "    for case_idx in tqdm(range(f_constrained.shape[1]), desc=\"Processing cases\"):\n",
    "        case_dir = Path(f\"case_{case_idx}\")\n",
    "        case_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Extract force and initial displacement for the current case\n",
    "        F = f_constrained[:, case_idx]\n",
    "        x0 = x[:, case_idx]\n",
    "        magnitude = magnitudes[case_idx]\n",
    "        \n",
    "        # Print case information\n",
    "        print(f\"\\nSolving case {case_idx + 1}/{f_constrained.shape[1]}\")\n",
    "        print(f\"Magnitude: {magnitude}\")\n",
    "        \n",
    "        # Print iteration number and current case details\n",
    "        print(f\"Iteration: {case_idx + 1}\")\n",
    "        print(f\"Case details: Force vector scale = {np.linalg.norm(F):.2e}, Initial displacement scale = {np.linalg.norm(x0):.2e}\")\n",
    "        \n",
    "        # Solve the dynamic system for the current case\n",
    "        case_start_time = time.time()\n",
    "        results = solve_dynamic_system(M_constrained, K_constrained, F, x0, t_span, t_eval, case_dir, magnitude)\n",
    "        case_solve_time = time.time() - case_start_time\n",
    "        solve_times.append(case_solve_time)\n",
    "        \n",
    "        # Append results\n",
    "        results_list.append(results)\n",
    "        \n",
    "        # Print time elapsed for the current case\n",
    "        print(f\"Case {case_idx + 1} completed in {case_solve_time:.2f} seconds.\")\n",
    "    \n",
    "    # Print summary table\n",
    "    print_summary_table(results_list, magnitudes, solve_times)\n",
    "    \n",
    "    # Total time elapsed\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total computation time: {total_time:.2f} seconds\")\n",
    "    print(f\"Average time per case: {np.mean(solve_times):.2f} seconds\")\n",
    "    print(f\"Number of cases: {f_constrained.shape[1]}\")\n",
    "    print(f\"Fastest case: {np.min(solve_times):.2f} seconds (Case {np.argmin(solve_times) + 1})\")\n",
    "    print(f\"Slowest case: {np.max(solve_times):.2f} seconds (Case {np.argmax(solve_times) + 1})\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nAnalysis complete. Results saved in: Dynamic_solution\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def system_of_odes(t, y, M_inv, M_inv_K, F):\n",
    "    \"\"\"\n",
    "    Define the system of ODEs for the dynamic system.\n",
    "    \"\"\"\n",
    "    logging.debug(f\"Solving at time t = {t}\")\n",
    "    x, v = y[:len(M_inv)], y[len(M_inv):]\n",
    "    dxdt = v\n",
    "    dvdt = M_inv @ F - M_inv_K @ x\n",
    "    return np.concatenate((dxdt, dvdt))\n",
    "\n",
    "def save_case_results(results, case_dir, prefix=\"analytical\"):\n",
    "    \"\"\"\n",
    "    Save results for a single case with comprehensive solution storage.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create solution directory\n",
    "        solution_dir = case_dir / 'solution'\n",
    "        solution_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save raw solution arrays as .npy files\n",
    "        np.save(solution_dir / f'{prefix}_time.npy', results['time'])\n",
    "        np.save(solution_dir / f'{prefix}_displacement.npy', results['displacement'])\n",
    "        np.save(solution_dir / f'{prefix}_velocity.npy', results['velocity'])\n",
    "        np.save(solution_dir / f'{prefix}_acceleration.npy', results['acceleration'])\n",
    "        \n",
    "        # Save time history data in compressed format\n",
    "        np.savez(case_dir / f'{prefix}_time_history.npz',\n",
    "                 time=results['time'],\n",
    "                 displacement=results['displacement'],\n",
    "                 velocity=results['velocity'],\n",
    "                 acceleration=results['acceleration'])\n",
    "        \n",
    "        # Save summary statistics\n",
    "        with open(case_dir / f'{prefix}_summary.txt', 'w') as f:\n",
    "            f.write(\"Results Summary:\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\")\n",
    "            f.write(f\"Time steps completed: {len(results['time'])}\\n\")\n",
    "            f.write(f\"Maximum displacement: {np.max(np.abs(results['displacement'])):.2e}\\n\")\n",
    "            f.write(f\"Maximum velocity: {np.max(np.abs(results['velocity'])):.2e}\\n\")\n",
    "            f.write(f\"Maximum acceleration: {np.max(np.abs(results['acceleration'])):.2e}\\n\")\n",
    "            f.write(\"\\nFile Locations:\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "            f.write(f\"Solution arrays (.npy files): {solution_dir}\\n\")\n",
    "            f.write(f\"Time history: {case_dir/f'{prefix}_time_history.npz'}\\n\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving case results: {e}\")\n",
    "\n",
    "# def solve_dynamic_system(M, K, F, x0, t_span, t_eval, case_dir, magnitude):\n",
    "#     \"\"\"\n",
    "#     Solve the dynamic system for a single case and save the results.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Precompute the inverse of the mass matrix and M_inv @ K\n",
    "#         M_inv = np.linalg.inv(M)\n",
    "#         M_inv_K = M_inv @ K\n",
    "        \n",
    "#         # Initial conditions\n",
    "#         v0 = np.zeros_like(x0)\n",
    "#         y0 = np.concatenate((x0, v0))\n",
    "        \n",
    "#         # Solve the ODE\n",
    "#         sol = solve_ivp(\n",
    "#             system_of_odes, \n",
    "#             t_span, \n",
    "#             y0, \n",
    "#             args=(M_inv, M_inv_K, F), \n",
    "#             t_eval=t_eval, \n",
    "#             method='BDF',  # Use a stiff solver\n",
    "#             atol=1e-6,     # Absolute tolerance\n",
    "#             rtol=1e-6      # Relative tolerance\n",
    "#         )\n",
    "        \n",
    "#         # Extract results\n",
    "#         displacement = sol.y[:len(M), :]\n",
    "#         velocity = sol.y[len(M):, :]\n",
    "#         acceleration = M_inv @ (F[:, np.newaxis] - K @ displacement)\n",
    "        \n",
    "#         # Prepare results dictionary\n",
    "#         results = {\n",
    "#             'time': t_eval,\n",
    "#             'displacement': displacement,\n",
    "#             'velocity': velocity,\n",
    "#             'acceleration': acceleration\n",
    "#         }\n",
    "        \n",
    "#         # Save results\n",
    "#         save_case_results(results, case_dir)\n",
    "        \n",
    "#         # Generate animation\n",
    "#         generate_animation(results, case_dir, magnitude)\n",
    "        \n",
    "#         return results\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error solving dynamic system: {e}\")\n",
    "#         return None\n",
    "\n",
    "def solve_dynamic_system(M, K, F, x0, t_span, t_eval, case_dir, magnitude):\n",
    "    \"\"\"\n",
    "    Solve the dynamic system for a single case and save the results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Debugging: Print norms of input matrices and vectors\n",
    "        logging.info(f\"Norm of M: {np.linalg.norm(M)}\")\n",
    "        logging.info(f\"Norm of K: {np.linalg.norm(K)}\")\n",
    "        logging.info(f\"Norm of F: {np.linalg.norm(F)}\")\n",
    "        logging.info(f\"Condition number of M: {np.linalg.cond(M)}\")\n",
    "        logging.info(f\"Condition number of K: {np.linalg.cond(K)}\")\n",
    "        \n",
    "        # Scale the force vector if necessary\n",
    "        F = F / 1000  # Example scaling\n",
    "        logging.info(f\"Scaled norm of F: {np.linalg.norm(F)}\")\n",
    "        \n",
    "        # Precompute the inverse of the mass matrix and M_inv @ K\n",
    "        M_inv = np.linalg.inv(M)\n",
    "        M_inv_K = M_inv @ K\n",
    "        \n",
    "        # Initial conditions\n",
    "        v0 = np.zeros_like(x0)\n",
    "        y0 = np.concatenate((x0, v0))\n",
    "        \n",
    "        # Debugging: Print initial conditions\n",
    "        logging.info(f\"Initial displacement norm: {np.linalg.norm(x0)}\")\n",
    "        logging.info(f\"Initial velocity norm: {np.linalg.norm(v0)}\")\n",
    "        \n",
    "        # Solve the ODE\n",
    "        sol = solve_ivp(\n",
    "            system_of_odes, \n",
    "            t_span, \n",
    "            y0, \n",
    "            args=(M_inv, M_inv_K, F), \n",
    "            t_eval=t_eval, \n",
    "            method='BDF', \n",
    "            atol=1e-8,  # Tighter absolute tolerance\n",
    "            rtol=1e-8   # Tighter relative tolerance\n",
    "        )\n",
    "        \n",
    "        # Extract results\n",
    "        displacement = sol.y[:len(M), :]\n",
    "        velocity = sol.y[len(M):, :]\n",
    "        acceleration = M_inv @ (F[:, np.newaxis] - K @ displacement)\n",
    "        \n",
    "        # Debugging: Print maximum values\n",
    "        logging.info(f\"Max displacement: {np.max(np.abs(displacement))}\")\n",
    "        logging.info(f\"Max velocity: {np.max(np.abs(velocity))}\")\n",
    "        logging.info(f\"Max acceleration: {np.max(np.abs(acceleration))}\")\n",
    "        \n",
    "        # Prepare results dictionary\n",
    "        results = {\n",
    "            'time': t_eval,\n",
    "            'displacement': displacement,\n",
    "            'velocity': velocity,\n",
    "            'acceleration': acceleration\n",
    "        }\n",
    "        \n",
    "        # Save results\n",
    "        save_case_results(results, case_dir)\n",
    "        \n",
    "        # Generate animation\n",
    "        generate_animation(results, case_dir, magnitude)\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error solving dynamic system: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_animation(results, case_dir, magnitude):\n",
    "    \"\"\"\n",
    "    Generate an animation of the displacement over time and save it as a GIF.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fig, ax = plt.subplots()\n",
    "        line, = ax.plot([], [], lw=2)\n",
    "        ax.set_xlim(min(results['time']), max(results['time']))\n",
    "        ax.set_ylim(np.min(results['displacement']), np.max(results['displacement']))\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_ylabel('Displacement')\n",
    "        ax.set_title(f'Case Magnitude: {magnitude}')\n",
    "        \n",
    "        def animate(i):\n",
    "            line.set_data(results['time'][:i], results['displacement'][0, :i])\n",
    "            return line,\n",
    "        \n",
    "        ani = animation.FuncAnimation(fig, animate, frames=len(results['time']), interval=50, blit=True)\n",
    "        ani.save(case_dir / 'displacement_animation.gif', writer='pillow')\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating animation: {e}\")\n",
    "\n",
    "def print_summary_table(results_list, magnitudes, solve_times):\n",
    "    \"\"\"\n",
    "    Print a well-aligned summary table of the results.\n",
    "    \"\"\"\n",
    "    # Define column widths\n",
    "    col_widths = {\n",
    "        'case': 6,\n",
    "        'magnitude': 30,\n",
    "        'max_disp': 18,\n",
    "        'max_vel': 14,\n",
    "        'max_acc': 18,\n",
    "        'solve_time': 14\n",
    "    }\n",
    "    \n",
    "    # Print table header\n",
    "    header = (\n",
    "        f\"{'Case':<{col_widths['case']}} | \"\n",
    "        f\"{'Magnitude':<{col_widths['magnitude']}} | \"\n",
    "        f\"{'Max Displacement':<{col_widths['max_disp']}} | \"\n",
    "        f\"{'Max Velocity':<{col_widths['max_vel']}} | \"\n",
    "        f\"{'Max Acceleration':<{col_widths['max_acc']}} | \"\n",
    "        f\"{'Solve Time (s)':<{col_widths['solve_time']}}\"\n",
    "    )\n",
    "    separator = \"-\" * len(header)\n",
    "    \n",
    "    logging.info(\"\\nResults Summary:\")\n",
    "    logging.info(separator)\n",
    "    logging.info(header)\n",
    "    logging.info(separator)\n",
    "    \n",
    "    # Print each row\n",
    "    for i, (results, magnitude, solve_time) in enumerate(zip(results_list, magnitudes, solve_times)):\n",
    "        max_disp = np.max(np.abs(results['displacement']))\n",
    "        max_vel = np.max(np.abs(results['velocity']))\n",
    "        max_acc = np.max(np.abs(results['acceleration']))\n",
    "        \n",
    "        row = (\n",
    "            f\"{i+1:<{col_widths['case']}} | \"\n",
    "            f\"{str(magnitude):<{col_widths['magnitude']}} | \"\n",
    "            f\"{max_disp:<{col_widths['max_disp']}.2e} | \"\n",
    "            f\"{max_vel:<{col_widths['max_vel']}.2e} | \"\n",
    "            f\"{max_acc:<{col_widths['max_acc']}.2e} | \"\n",
    "            f\"{solve_time:<{col_widths['solve_time']}.2f}\"\n",
    "        )\n",
    "        logging.info(row)\n",
    "    \n",
    "    logging.info(separator)\n",
    "\n",
    "def main():\n",
    "    # Example inputs\n",
    "    # M_constrained = np.random.rand(612, 612)  # Mass matrix (612, 612)\n",
    "    # K_constrained = np.random.rand(612, 612)  # Stiffness matrix (612, 612)\n",
    "    # f_constrained = np.random.rand(612, 5)    # Force vector (612, 5)\n",
    "    # x = np.random.rand(612, 5)                # Initial displacement (612, 5)\n",
    "    # magnitudes = [(-14.86, 219.86, -73.96), (-156.43, 241.68, -136.57), (247.25, 261.07, -32.92),\n",
    "    #               (268.73, -248.86, 369.87), (343.57, 131.52, -255.83)]  # Example magnitudes\n",
    "    \n",
    "    # Define time span and evaluation points\n",
    "    t_span = (0, 1)  # Example time span\n",
    "    t_eval = np.linspace(t_span[0], t_span[1], num=100)  # Time points for evaluation\n",
    "    \n",
    "    # Start time tracking\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Print initial information\n",
    "    logging.info(\"Starting multi-case dynamic analysis...\")\n",
    "    logging.info(f\"Function called with:\\nM: {M_constrained.shape}, K: {K_constrained.shape}, f: {f_constrained.shape}, magnitudes: {magnitudes}, x: {x.shape}\")\n",
    "    logging.info(f\"\\nNumber of DOFs: {M_constrained.shape[0]}\")\n",
    "    logging.info(f\"Number of cases: {f_constrained.shape[1]}\")\n",
    "    \n",
    "    # Loop through each case\n",
    "    results_list = []\n",
    "    solve_times = []\n",
    "    for case_idx in tqdm(range(f_constrained.shape[1]), desc=\"Processing cases\"):\n",
    "        case_dir = Path(f\"case_{case_idx}\")\n",
    "        case_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Extract force and initial displacement for the current case\n",
    "        F = f_constrained[:, case_idx]\n",
    "        x0 = x[:, case_idx]\n",
    "        magnitude = magnitudes[case_idx]\n",
    "        \n",
    "        # Print case information\n",
    "        logging.info(f\"\\nSolving case {case_idx + 1}/{f_constrained.shape[1]}\")\n",
    "        logging.info(f\"Magnitude: {magnitude}\")\n",
    "        \n",
    "        # Solve the dynamic system for the current case\n",
    "        case_start_time = time.time()\n",
    "        results = solve_dynamic_system(M_constrained, K_constrained, F, x0, t_span, t_eval, case_dir, magnitude)\n",
    "        case_solve_time = time.time() - case_start_time\n",
    "        solve_times.append(case_solve_time)\n",
    "        \n",
    "        # Append results\n",
    "        if results is not None:\n",
    "            results_list.append(results)\n",
    "        \n",
    "        # Print time elapsed for the current case\n",
    "        logging.info(f\"Case {case_idx + 1} completed in {case_solve_time:.2f} seconds.\")\n",
    "    \n",
    "    # Print summary table\n",
    "    print_summary_table(results_list, magnitudes, solve_times)\n",
    "    \n",
    "    # Total time elapsed\n",
    "    total_time = time.time() - start_time\n",
    "    logging.info(f\"\\nOverall Statistics:\")\n",
    "    logging.info(\"=\" * 80)\n",
    "    logging.info(f\"Total computation time: {total_time:.2f} seconds\")\n",
    "    logging.info(f\"Average time per case: {np.mean(solve_times):.2f} seconds\")\n",
    "    logging.info(f\"Number of cases: {f_constrained.shape[1]}\")\n",
    "    logging.info(f\"Fastest case: {np.min(solve_times):.2f} seconds (Case {np.argmin(solve_times) + 1})\")\n",
    "    logging.info(f\"Slowest case: {np.max(solve_times):.2f} seconds (Case {np.argmax(solve_times) + 1})\")\n",
    "    logging.info(\"=\" * 80)\n",
    "    logging.info(\"\\nAnalysis complete. Results saved in: Dynamic_solution\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from pathlib import Path\n",
    "\n",
    "def read_mdpa_file(mdpa_file):\n",
    "    \"\"\"\n",
    "    Read node coordinates and element connectivity from an .mdpa file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mdpa_file: str, path to the .mdpa file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    node_coords: numpy array, shape (n_nodes, 2)\n",
    "        Coordinates of the nodes.\n",
    "    elements: numpy array, shape (n_elements, 3)\n",
    "        Connectivity of the elements (triangles).\n",
    "    \"\"\"\n",
    "    node_coords = []\n",
    "    elements = []\n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "    \n",
    "    with open(mdpa_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "                continue\n",
    "            elif reading_nodes and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    x, y = float(parts[1]), float(parts[2])\n",
    "                    node_coords.append([x, y])\n",
    "                    \n",
    "            if \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif reading_elements and \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "                continue\n",
    "            elif reading_elements and line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    n1, n2, n3 = int(parts[2])-1, int(parts[3])-1, int(parts[4])-1\n",
    "                    elements.append([n1, n2, n3])\n",
    "    \n",
    "    return np.array(node_coords), np.array(elements)\n",
    "\n",
    "def create_displacement_animation(case_folder, mdpa_file, scale_factor=1e7, step_interval=100):\n",
    "    \"\"\"\n",
    "    Create an animated GIF of displacement field for a specific case.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    case_folder: Path object, full path to case folder\n",
    "    mdpa_file: str, path to mdpa file\n",
    "    scale_factor: float, scaling factor for displacements\n",
    "    step_interval: int, time in milliseconds between frames\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output filename\n",
    "        output_file = case_folder / 'displacement_animation.gif'\n",
    "        \n",
    "        print(f\"\\nProcessing: {case_folder.name}\")\n",
    "        \n",
    "        # Load solution data\n",
    "        time = np.load(case_folder / \"solution\" / \"analytical_time.npy\")\n",
    "        displacement = np.load(case_folder / \"solution\" / \"analytical_displacement.npy\")\n",
    "        \n",
    "        print(f\"Loaded displacement data shape: {displacement.shape}\")\n",
    "        print(f\"Time steps available: {len(time)}\")\n",
    "        \n",
    "        # Read node coordinates and elements from .mdpa file\n",
    "        node_coords, elements = read_mdpa_file(mdpa_file)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        # Create base triangulation for undeformed mesh\n",
    "        x = node_coords[:, 0]\n",
    "        y = node_coords[:, 1]\n",
    "        triangulation_orig = tri.Triangulation(x, y, elements)\n",
    "        \n",
    "        # Find global displacement limits for consistent colorbar\n",
    "        disp_magnitudes = []\n",
    "        for step in range(len(time)):\n",
    "            disp = displacement[:, step].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            disp_magnitudes.append(disp_mag)\n",
    "        \n",
    "        global_min = min(np.min(mag) for mag in disp_magnitudes)\n",
    "        global_max = max(np.max(mag) for mag in disp_magnitudes)\n",
    "        \n",
    "        print(f\"Animation Information:\")\n",
    "        print(f\"Total frames: {len(time)}\")\n",
    "        print(f\"Time range: [{time[0]:.3f}, {time[-1]:.3f}] seconds\")\n",
    "        print(f\"Global displacement range: [{global_min:.2e}, {global_max:.2e}]\")\n",
    "        \n",
    "        def update(frame):\n",
    "            ax.clear()\n",
    "            \n",
    "            # Get displacements for current frame\n",
    "            disp = displacement[:, frame].reshape(-1, 2) * scale_factor\n",
    "            disp_mag = np.sqrt(disp[:, 0]**2 + disp[:, 1]**2)\n",
    "            \n",
    "            # Calculate deformed coordinates\n",
    "            deformed_coords = node_coords + disp\n",
    "            \n",
    "            # Plot undeformed mesh\n",
    "            ax.triplot(triangulation_orig, 'k--', lw=0.5, alpha=0.3, label='Undeformed')\n",
    "            \n",
    "            # Plot deformed mesh with displacement magnitude coloring\n",
    "            triangulation_def = tri.Triangulation(deformed_coords[:, 0], deformed_coords[:, 1], elements)\n",
    "            tcf = ax.tripcolor(triangulation_def, disp_mag, shading='flat', cmap='coolwarm',\n",
    "                             vmin=global_min, vmax=global_max)\n",
    "            ax.triplot(triangulation_def, 'k-', lw=0.5, alpha=0.5, label='Deformed')\n",
    "            \n",
    "            # Set labels and title\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_title(f'Displacement Field\\nTime: {time[frame]:.3f}s (Frame {frame}/{len(time)-1})')\n",
    "            \n",
    "            ax.grid(True)\n",
    "            ax.axis('equal')\n",
    "            ax.legend()\n",
    "            \n",
    "            # Add colorbar only once\n",
    "            if frame == 0:\n",
    "                plt.colorbar(tcf, ax=ax, label='Displacement Magnitude')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Print progress\n",
    "            if frame % 10 == 0:\n",
    "                print(f\"Processing frame {frame}/{len(time)-1}\")\n",
    "        \n",
    "        # Create animation\n",
    "        print(\"Creating animation...\")\n",
    "        anim = FuncAnimation(fig, update, frames=len(time), interval=step_interval)\n",
    "        \n",
    "        # Save animation\n",
    "        print(f\"Saving animation to {output_file}\")\n",
    "        writer = PillowWriter(fps=1000/step_interval)\n",
    "        anim.save(output_file, writer=writer)\n",
    "        \n",
    "        plt.close()\n",
    "        print(\"Animation completed!\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {case_folder.name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    case_folder = Path(\"case_0\")  # Path to the case folder\n",
    "    mdpa_file = \"2D_beam_udl_loading.mdpa\"  # Path to the .mdpa file\n",
    "    create_displacement_animation(case_folder, mdpa_file, scale_factor=1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def system_of_odes(t, y, M_inv, K, F):\n",
    "    \"\"\"\n",
    "    Define the system of ODEs for the dynamic system.\n",
    "    \"\"\"\n",
    "    x, v = y[:len(M_inv)], y[len(M_inv):]\n",
    "    dxdt = v\n",
    "    dvdt = M_inv @ (F - K @ x)  # Use precomputed M_inv\n",
    "    return np.concatenate((dxdt, dvdt))\n",
    "\n",
    "def save_case_results(results, case_dir, prefix=\"analytical\"):\n",
    "    \"\"\"\n",
    "    Save results for a single case with comprehensive solution storage.\n",
    "    \"\"\"\n",
    "    # Create solution directory\n",
    "    solution_dir = case_dir / 'solution'\n",
    "    solution_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save raw solution arrays as .npy files\n",
    "    np.save(solution_dir / f'{prefix}_time.npy', results['time'])\n",
    "    np.save(solution_dir / f'{prefix}_displacement.npy', results['displacement'])\n",
    "    np.save(solution_dir / f'{prefix}_velocity.npy', results['velocity'])\n",
    "    np.save(solution_dir / f'{prefix}_acceleration.npy', results['acceleration'])\n",
    "    \n",
    "    # Save time history data in compressed format\n",
    "    np.savez(case_dir / f'{prefix}_time_history.npz',\n",
    "             time=results['time'],\n",
    "             displacement=results['displacement'],\n",
    "             velocity=results['velocity'],\n",
    "             acceleration=results['acceleration'])\n",
    "    \n",
    "    # Save summary statistics\n",
    "    with open(case_dir / f'{prefix}_summary.txt', 'w') as f:\n",
    "        f.write(\"Results Summary:\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(f\"Time steps completed: {len(results['time'])}\\n\")\n",
    "        f.write(f\"Maximum displacement: {np.max(np.abs(results['displacement'])):.2e}\\n\")\n",
    "        f.write(f\"Maximum velocity: {np.max(np.abs(results['velocity'])):.2e}\\n\")\n",
    "        f.write(f\"Maximum acceleration: {np.max(np.abs(results['acceleration'])):.2e}\\n\")\n",
    "        f.write(\"\\nFile Locations:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(f\"Solution arrays (.npy files): {solution_dir}\\n\")\n",
    "        f.write(f\"Time history: {case_dir/f'{prefix}_time_history.npz'}\\n\")\n",
    "\n",
    "def solve_dynamic_system(M, K, F, x0, t_span, t_eval, case_dir, magnitude):\n",
    "    \"\"\"\n",
    "    Solve the dynamic system for a single case and save the results.\n",
    "    \"\"\"\n",
    "    # Precompute the inverse of the mass matrix\n",
    "    M_inv = np.linalg.inv(M)\n",
    "    \n",
    "    # Initial conditions\n",
    "    v0 = np.zeros_like(x0)\n",
    "    y0 = np.concatenate((x0, v0))\n",
    "    \n",
    "    # Solve the ODE\n",
    "    sol = solve_ivp(system_of_odes, t_span, y0, args=(M_inv, K, F), t_eval=t_eval, method='RK45')\n",
    "    \n",
    "    # Extract results\n",
    "    displacement = sol.y[:len(M), :]\n",
    "    velocity = sol.y[len(M):, :]\n",
    "    acceleration = np.gradient(velocity, t_eval, axis=1)\n",
    "    \n",
    "    # Prepare results dictionary\n",
    "    results = {\n",
    "        'time': t_eval,\n",
    "        'displacement': displacement,\n",
    "        'velocity': velocity,\n",
    "        'acceleration': acceleration\n",
    "    }\n",
    "    \n",
    "    # Save results\n",
    "    save_case_results(results, case_dir)\n",
    "    \n",
    "    # Generate animation\n",
    "    generate_animation(results, case_dir, magnitude)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def generate_animation(results, case_dir, magnitude):\n",
    "    \"\"\"\n",
    "    Generate an animation of the displacement over time and save it as a GIF.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    line, = ax.plot([], [], lw=2)\n",
    "    ax.set_xlim(min(results['time']), max(results['time']))\n",
    "    ax.set_ylim(np.min(results['displacement']), np.max(results['displacement']))\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Displacement')\n",
    "    ax.set_title(f'Case Magnitude: {magnitude}')\n",
    "    \n",
    "    def animate(i):\n",
    "        line.set_data(results['time'][:i], results['displacement'][0, :i])\n",
    "        return line,\n",
    "    \n",
    "    ani = animation.FuncAnimation(fig, animate, frames=len(results['time']), interval=50, blit=True)\n",
    "    ani.save(case_dir / 'displacement_animation.gif', writer='pillow')\n",
    "    plt.close()\n",
    "\n",
    "# def print_summary_table(results_list, magnitudes, solve_times):\n",
    "#     \"\"\"\n",
    "#     Print a summary table of the results.\n",
    "#     \"\"\"\n",
    "#     print(\"\\nResults Summary:\")\n",
    "#     print(\"=\" * 80)\n",
    "#     print(f\"{'Case':<6} | {'Magnitude':<30} | {'Max Displacement':<18} | {'Max Velocity':<14} | {'Max Acceleration':<18} | {'Solve Time (s)':<14}\")\n",
    "#     print(\"=\" * 80)\n",
    "#     for i, (results, magnitude, solve_time) in enumerate(zip(results_list, magnitudes, solve_times)):\n",
    "#         max_disp = np.max(np.abs(results['displacement']))\n",
    "#         max_vel = np.max(np.abs(results['velocity']))\n",
    "#         max_acc = np.max(np.abs(results['acceleration']))\n",
    "#         print(f\"{i+1:<6} | {str(magnitude):<30} | {max_disp:.2e} | {max_vel:.2e} | {max_acc:.2e} | {solve_time:.2f}\")\n",
    "#     print(\"=\" * 80)\n",
    "\n",
    "def print_summary_table(results_list, magnitudes, solve_times):\n",
    "    \"\"\"\n",
    "    Print a well-aligned summary table of the results.\n",
    "    \"\"\"\n",
    "    # Define column widths\n",
    "    col_widths = {\n",
    "        'case': 6,\n",
    "        'magnitude': 30,\n",
    "        'max_disp': 18,\n",
    "        'max_vel': 14,\n",
    "        'max_acc': 18,\n",
    "        'solve_time': 14\n",
    "    }\n",
    "    \n",
    "    # Print table header\n",
    "    header = (\n",
    "        f\"{'Case':<{col_widths['case']}} | \"\n",
    "        f\"{'Magnitude':<{col_widths['magnitude']}} | \"\n",
    "        f\"{'Max Displacement':<{col_widths['max_disp']}} | \"\n",
    "        f\"{'Max Velocity':<{col_widths['max_vel']}} | \"\n",
    "        f\"{'Max Acceleration':<{col_widths['max_acc']}} | \"\n",
    "        f\"{'Solve Time (s)':<{col_widths['solve_time']}}\"\n",
    "    )\n",
    "    separator = \"-\" * len(header)\n",
    "    \n",
    "    print(\"\\nResults Summary:\")\n",
    "    print(separator)\n",
    "    print(header)\n",
    "    print(separator)\n",
    "    \n",
    "    # Print each row\n",
    "    for i, (results, magnitude, solve_time) in enumerate(zip(results_list, magnitudes, solve_times)):\n",
    "        max_disp = np.max(np.abs(results['displacement']))\n",
    "        max_vel = np.max(np.abs(results['velocity']))\n",
    "        max_acc = np.max(np.abs(results['acceleration']))\n",
    "        \n",
    "        row = (\n",
    "            f\"{i+1:<{col_widths['case']}} | \"\n",
    "            f\"{str(magnitude):<{col_widths['magnitude']}} | \"\n",
    "            f\"{max_disp:<{col_widths['max_disp']}.2e} | \"\n",
    "            f\"{max_vel:<{col_widths['max_vel']}.2e} | \"\n",
    "            f\"{max_acc:<{col_widths['max_acc']}.2e} | \"\n",
    "            f\"{solve_time:<{col_widths['solve_time']}.2f}\"\n",
    "        )\n",
    "        print(row)\n",
    "    \n",
    "    print(separator)\n",
    "\n",
    "def main():\n",
    "    # Example inputs\n",
    "    # M_constrained = np.random.rand(612, 612)  # Mass matrix (612, 612)\n",
    "    # K_constrained = np.random.rand(612, 612)  # Stiffness matrix (612, 612)\n",
    "    # f_constrained = np.random.rand(612, 5)    # Force vector (612, 5)\n",
    "    # x = np.random.rand(612, 5)                # Initial displacement (612, 5)\n",
    "    # magnitudes = [(-14.86, 219.86, -73.96), (-156.43, 241.68, -136.57), (247.25, 261.07, -32.92),\n",
    "    #               (268.73, -248.86, 369.87), (343.57, 131.52, -255.83)]  # Example magnitudes\n",
    "    \n",
    "    # Define time span and evaluation points\n",
    "    t_span = (0, 1)  # Example time span\n",
    "    t_eval = np.linspace(t_span[0], t_span[1], num=100)  # Time points for evaluation\n",
    "    \n",
    "    # Start time tracking\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Print initial information\n",
    "    print(\"Starting multi-case dynamic analysis...\")\n",
    "    print(f\"Function called with:\\nM: {M_constrained.shape}, K: {K_constrained.shape}, f: {f_constrained.shape}, magnitudes: {magnitudes}, x: {x.shape}\")\n",
    "    print(f\"\\nNumber of DOFs: {M_constrained.shape[0]}\")\n",
    "    print(f\"Number of cases: {f_constrained.shape[1]}\")\n",
    "    \n",
    "    # Loop through each case\n",
    "    results_list = []\n",
    "    solve_times = []\n",
    "    for case_idx in tqdm(range(f_constrained.shape[1]), desc=\"Processing cases\"):\n",
    "        case_dir = Path(f\"case_{case_idx}\")\n",
    "        case_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Extract force and initial displacement for the current case\n",
    "        F = f_constrained[:, case_idx]\n",
    "        x0 = x[:, case_idx]\n",
    "        magnitude = magnitudes[case_idx]\n",
    "        \n",
    "        # Print case information\n",
    "        print(f\"\\nSolving case {case_idx + 1}/{f_constrained.shape[1]}\")\n",
    "        print(f\"Magnitude: {magnitude}\")\n",
    "        # print(\"\\nMatrix scaling factors:\")\n",
    "        # print(f\"Mass matrix scale: {np.linalg.norm(M_constrained):.2e}\")\n",
    "        # print(f\"Stiffness matrix scale: {np.linalg.norm(K_constrained):.2e}\")\n",
    "        # print(f\"Force vector scale: {np.linalg.norm(F):.2e}\")\n",
    "        \n",
    "        # Solve the dynamic system for the current case\n",
    "        case_start_time = time.time()\n",
    "        results = solve_dynamic_system(M_constrained, K_constrained, F, x0, t_span, t_eval, case_dir, magnitude)\n",
    "        case_solve_time = time.time() - case_start_time\n",
    "        solve_times.append(case_solve_time)\n",
    "        \n",
    "        # Append results\n",
    "        results_list.append(results)\n",
    "        \n",
    "        # Print time elapsed for the current case\n",
    "        print(f\"Case {case_idx + 1} completed in {case_solve_time:.2f} seconds.\")\n",
    "    \n",
    "    # Print summary table\n",
    "    print_summary_table(results_list, magnitudes, solve_times)\n",
    "    \n",
    "    # Total time elapsed\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total computation time: {total_time:.2f} seconds\")\n",
    "    print(f\"Average time per case: {np.mean(solve_times):.2f} seconds\")\n",
    "    print(f\"Number of cases: {f_constrained.shape[1]}\")\n",
    "    print(f\"Fastest case: {np.min(solve_times):.2f} seconds (Case {np.argmin(solve_times) + 1})\")\n",
    "    print(f\"Slowest case: {np.max(solve_times):.2f} seconds (Case {np.argmax(solve_times) + 1})\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nAnalysis complete. Results saved in: Dynamic_solution\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import matplotlib.tri as mtri\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.collections as collections\n",
    "\n",
    "def parse_mdpa_file(mdpa_file):\n",
    "    \"\"\"Parse MDPA file to extract node coordinates, elements and load conditions\"\"\"\n",
    "    nodes = []\n",
    "    elements = []\n",
    "    load_nodes = {\n",
    "        'Load_1': [],\n",
    "        'Load_2': [],\n",
    "        'Load_3': []\n",
    "    }\n",
    "    \n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "    current_load = None\n",
    "    \n",
    "    with open(mdpa_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "            elif \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "            elif \"Begin SubModelPart LinePressure2D_Load_1\" in line:\n",
    "                current_load = 'Load_1'\n",
    "            elif \"Begin SubModelPart LinePressure2D_Load_2\" in line:\n",
    "                current_load = 'Load_2'\n",
    "            elif \"Begin SubModelPart LinePressure2D_Load_3\" in line:\n",
    "                current_load = 'Load_3'\n",
    "            elif \"End SubModelPart\" in line:\n",
    "                current_load = None\n",
    "            \n",
    "            # Parse nodes\n",
    "            if reading_nodes and line:\n",
    "                try:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4:\n",
    "                        node_id = int(parts[0])\n",
    "                        x = float(parts[1])\n",
    "                        y = float(parts[2])\n",
    "                        nodes.append([x, y])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            \n",
    "            # Parse elements\n",
    "            if reading_elements and line:\n",
    "                try:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 5:\n",
    "                        element_nodes = [int(node)-1 for node in parts[2:5]]\n",
    "                        elements.append(element_nodes)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            \n",
    "            # Parse load nodes\n",
    "            if current_load and not reading_nodes and not reading_elements:\n",
    "                try:\n",
    "                    node_id = int(line)\n",
    "                    load_nodes[current_load].append(node_id - 1)  # Convert to 0-based indexing\n",
    "                except ValueError:\n",
    "                    continue\n",
    "    \n",
    "    return np.array(nodes), np.array(elements), load_nodes\n",
    "\n",
    "def plot_force_field(case_dir, node_coords, elements, load_nodes, time_step=0, scale_factor=1.0):\n",
    "    \"\"\"Create force field visualization for a specific time step\"\"\"\n",
    "    case_dir = Path(case_dir)\n",
    "    \n",
    "    # Load force data\n",
    "    time_history = np.load(case_dir / 'time_history.npz')\n",
    "    force = time_history['force'] if 'force' in time_history else np.zeros_like(time_history['displacement'])\n",
    "    time = time_history['time']\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Create triangulation for mesh visualization\n",
    "    triang = mtri.Triangulation(node_coords[:, 0], node_coords[:, 1], elements)\n",
    "    \n",
    "    # Custom colormap: blue (compression) to red (tension)\n",
    "    colors = [(0, 0, 1), (1, 1, 1), (1, 0, 0)]  # Blue -> White -> Red\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom\", colors, N=100)\n",
    "    \n",
    "    # Get force magnitude at current time step\n",
    "    current_force = force[time_step].reshape(-1, 2)\n",
    "    force_magnitude = np.linalg.norm(current_force, axis=1)\n",
    "    \n",
    "    # Plot mesh with force magnitude coloring\n",
    "    tripcolor = ax.tripcolor(triang, force_magnitude, cmap=cmap, \n",
    "                           shading='gouraud')\n",
    "    \n",
    "    # Plot original mesh\n",
    "    for element in elements:\n",
    "        x = node_coords[element, 0]\n",
    "        y = node_coords[element, 1]\n",
    "        ax.plot(x, y, 'k-', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    # Plot force arrows for each load condition\n",
    "    arrow_props = dict(width=0.05, head_width=0.2, head_length=0.3)\n",
    "    \n",
    "    # Different colors for different load conditions\n",
    "    load_colors = {\n",
    "        'Load_1': 'red',\n",
    "        'Load_2': 'blue',\n",
    "        'Load_3': 'green'\n",
    "    }\n",
    "    \n",
    "    # Plot force arrows\n",
    "    for load_type, nodes in load_nodes.items():\n",
    "        if nodes:  # If there are nodes for this load type\n",
    "            for node_idx in nodes:\n",
    "                force_vec = current_force[node_idx] * scale_factor\n",
    "                if np.any(force_vec != 0):\n",
    "                    ax.arrow(node_coords[node_idx, 0],\n",
    "                            node_coords[node_idx, 1],\n",
    "                            force_vec[0],\n",
    "                            force_vec[1],\n",
    "                            color=load_colors[load_type],\n",
    "                            **arrow_props)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(tripcolor)\n",
    "    cbar.set_label('Force Magnitude')\n",
    "    \n",
    "    # Set title and labels\n",
    "    ax.set_title(f'Force Field at Time Step {time_step}\\nTime: {time[time_step]:.3f} s')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # Add legend for load types\n",
    "    legend_elements = [patches.Patch(color=color, label=load_type)\n",
    "                      for load_type, color in load_colors.items()]\n",
    "    ax.legend(handles=legend_elements)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(case_dir / f'force_field_step_{time_step}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def process_force_visualizations(base_dir, mdpa_file, time_steps=None, scale_factor=1.0):\n",
    "    \"\"\"Process force visualizations for all cases\"\"\"\n",
    "    base_dir = Path(base_dir)\n",
    "    \n",
    "    # Parse MDPA file\n",
    "    print(f\"Parsing MDPA file: {mdpa_file}\")\n",
    "    node_coords, elements, load_nodes = parse_mdpa_file(mdpa_file)\n",
    "    \n",
    "    # Get all case directories\n",
    "    case_dirs = sorted(base_dir.glob(\"case_*\"))\n",
    "    \n",
    "    print(\"\\nCreating force field visualizations:\")\n",
    "    for case_dir in case_dirs:\n",
    "        print(f\"\\nProcessing {case_dir.name}\")\n",
    "        try:\n",
    "            # If time_steps not specified, create visualization for step 0\n",
    "            if time_steps is None:\n",
    "                time_steps = [0]\n",
    "            \n",
    "            for step in time_steps:\n",
    "                plot_force_field(case_dir, node_coords, elements, load_nodes,\n",
    "                               time_step=step, scale_factor=scale_factor)\n",
    "                print(f\"Force field plot saved for time step {step}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {case_dir.name}: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        base_dir = \"Dynamic_solution\"\n",
    "        mdpa_file = \"2D_beam_udl_loading.mdpa\"\n",
    "        \n",
    "        print(\"Starting force field visualization generation...\")\n",
    "        process_force_visualizations(base_dir, mdpa_file, \n",
    "                                   time_steps=[0, 1, 2, 3, 4],  # Specify time steps to visualize\n",
    "                                   scale_factor=1e-3)  # Adjust scale factor as needed\n",
    "        print(\"\\nVisualization generation complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operator Inference model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def create_solution_matrix(data_type=\"displacement\", base_dir=\"Dynamic_solution\"):\n",
    "    \"\"\"\n",
    "    Create a combined matrix from all cases for specified data type.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_type : str\n",
    "        Type of data to process: \"displacement\", \"velocity\", or \"acceleration\"\n",
    "    base_dir : str or Path\n",
    "        Base directory containing the case folders\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    matrix : ndarray\n",
    "        Combined matrix where:\n",
    "        - Rows represent DOFs\n",
    "        - Columns represent all time steps from all cases\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    \n",
    "    # Validate data type\n",
    "    valid_types = [\"displacement\", \"velocity\", \"acceleration\"]\n",
    "    if data_type not in valid_types:\n",
    "        raise ValueError(f\"data_type must be one of {valid_types}\")\n",
    "    \n",
    "    # First, determine number of cases by counting case folders\n",
    "    case_folders = []\n",
    "    case_num = 1\n",
    "    while True:\n",
    "        matching_folders = list(base_path.glob(f\"case_{case_num}_magnitude_*\"))\n",
    "        if not matching_folders:\n",
    "            break\n",
    "        case_folders.extend(matching_folders)\n",
    "        case_num += 1\n",
    "    \n",
    "    n_cases = len(case_folders)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing {data_type.upper()} data\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"\\nFound {n_cases} cases\")\n",
    "    \n",
    "    # Load first case to determine dimensions\n",
    "    first_case_data = np.load(case_folders[0] / \"solution\" / f\"{data_type}.npy\")\n",
    "    n_timesteps = first_case_data.shape[0]\n",
    "    n_dofs = first_case_data.shape[1]\n",
    "    total_cols = n_timesteps * n_cases\n",
    "    \n",
    "    print(f\"\\n{'-'*30}\")    \n",
    "    print(\"Data dimensions:\")\n",
    "    print(f\"{'-'*30}\")\n",
    "    print(f\"Number of DOFs: {n_dofs}\")\n",
    "    print(f\"Time steps per case: {n_timesteps}\")\n",
    "    print(f\"Total columns: {total_cols}\")\n",
    "    \n",
    "    # Initialize the combined matrix\n",
    "    matrix = np.zeros((n_dofs, total_cols))\n",
    "    \n",
    "    # Process each case in order\n",
    "    for i, case_folder in enumerate(case_folders):\n",
    "        print(f\"\\nProcessing {case_folder.name}\")\n",
    "        \n",
    "        # Load data\n",
    "        data = np.load(case_folder / \"solution\" / f\"{data_type}.npy\")\n",
    "        \n",
    "        # Verify dimensions match\n",
    "        if data.shape != (n_timesteps, n_dofs):\n",
    "            print(f\"Warning: Case {i+1} has different dimensions: {data.shape}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate the column indices for this case\n",
    "        start_col = i * n_timesteps\n",
    "        end_col = start_col + n_timesteps\n",
    "        \n",
    "        # Store the data\n",
    "        for t in range(n_timesteps):\n",
    "            matrix[:, start_col + t] = data[t]\n",
    "    \n",
    "    print(f\"\\n{'-'*30}\")\n",
    "    print(f\"{data_type.capitalize()} matrix created successfully!\")\n",
    "    print(f\"{'-'*30}\")\n",
    "    print(f\"Shape of matrix: {matrix.shape}\")\n",
    "    \n",
    "    # Calculate some basic statistics\n",
    "    print(f\"\\n{'-'*30}\")\n",
    "    print(\"Matrix Statistics:\")\n",
    "    print(f\"{'-'*30}\")\n",
    "    print(f\"Maximum {data_type}: {np.max(np.abs(matrix)):.6e}\")\n",
    "    print(f\"Minimum {data_type}: {np.min(np.abs(matrix[matrix != 0])):.6e}\")\n",
    "    print(f\"Mean {data_type}: {np.mean(np.abs(matrix)):.6e}\")\n",
    "    print(f\"Number of non-zero entries: {np.count_nonzero(matrix)}\")\n",
    "    print(f\"Matrix sparsity: {(1 - np.count_nonzero(matrix)/(matrix.shape[0]*matrix.shape[1]))*100:.2f}%\")\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Create matrices for all types\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"CREATING SOLUTION MATRICES FOR ALL DATA TYPES\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(\"\\nCreating displacement matrix...\")\n",
    "        x_constructed = create_solution_matrix(\"displacement\")\n",
    "        \n",
    "        print(\"\\nCreating velocity matrix...\")\n",
    "        v_constructed = create_solution_matrix(\"velocity\")\n",
    "        \n",
    "        print(\"\\nCreating acceleration matrix...\")\n",
    "        a_constructed = create_solution_matrix(\"acceleration\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating matrices: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def create_force_matrix(f_constrained, base_dir=\"Dynamic_solution\"):\n",
    "    \"\"\"\n",
    "    Create expanded force matrix by repeating each case's force vector\n",
    "    for the number of time steps in the solution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    f_constrained : ndarray\n",
    "        Original force matrix with shape (n_dofs, n_cases)\n",
    "    base_dir : str or Path\n",
    "        Base directory containing the case folders\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    F : ndarray\n",
    "        Expanded force matrix where each case's force vector is repeated\n",
    "        for all time steps\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    \n",
    "    # Get dimensions from f_constrained\n",
    "    n_dofs, n_cases = f_constrained.shape\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"PROCESSING FORCE MATRIX\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"\\nOriginal force matrix shape: {f_constrained.shape}\")\n",
    "    print(f\"Number of DOFs: {n_dofs}\")\n",
    "    print(f\"Number of cases: {n_cases}\")\n",
    "    \n",
    "    # Determine number of time steps by reading first case\n",
    "    case_folders = list(base_path.glob(\"case_1_magnitude_*\"))\n",
    "    if not case_folders:\n",
    "        raise ValueError(\"Cannot find case 1 folder to determine time steps\")\n",
    "    \n",
    "    # Load first case displacement to get number of time steps\n",
    "    first_case_disp = np.load(case_folders[0] / \"solution\" / \"displacement.npy\")\n",
    "    n_timesteps = first_case_disp.shape[0]\n",
    "    print(f\"Number of time steps per case: {n_timesteps}\")\n",
    "    \n",
    "    # Calculate total columns in expanded matrix\n",
    "    total_cols = n_timesteps * n_cases\n",
    "    print(f\"Total columns in expanded matrix: {total_cols}\")\n",
    "    \n",
    "    # Initialize expanded force matrix\n",
    "    F = np.zeros((n_dofs, total_cols))\n",
    "    \n",
    "    print(f\"\\n{'-'*30}\")\n",
    "    print(\"Expanding force vectors\")\n",
    "    print(f\"{'-'*30}\")\n",
    "    \n",
    "    # For each case\n",
    "    for i in range(n_cases):\n",
    "        # Calculate column indices for this case\n",
    "        start_col = i * n_timesteps\n",
    "        end_col = start_col + n_timesteps\n",
    "        \n",
    "        # Repeat the force vector for this case\n",
    "        force_vector = f_constrained[:, i:i+1]  # Keep 2D shape\n",
    "        F[:, start_col:end_col] = np.repeat(force_vector, n_timesteps, axis=1)\n",
    "        \n",
    "        print(f\"Case {i+1}: Force vector repeated {n_timesteps} times (columns {start_col} to {end_col-1})\")\n",
    "    \n",
    "    print(f\"\\n{'-'*30}\")\n",
    "    print(\"Force matrix created successfully!\")\n",
    "    print(f\"{'-'*30}\")\n",
    "    print(f\"Shape of expanded force matrix: {F.shape}\")\n",
    "    \n",
    "    # Calculate some basic statistics\n",
    "    print(f\"\\n{'-'*30}\")\n",
    "    print(\"Matrix Statistics:\")\n",
    "    print(f\"{'-'*30}\")\n",
    "    print(f\"Maximum force: {np.max(np.abs(F)):.6e}\")\n",
    "    print(f\"Minimum force: {np.min(np.abs(F[F != 0])):.6e}\")\n",
    "    print(f\"Mean force: {np.mean(np.abs(F)):.6e}\")\n",
    "    print(f\"Number of non-zero entries: {np.count_nonzero(F)}\")\n",
    "    print(f\"Matrix sparsity: {(1 - np.count_nonzero(F)/(F.shape[0]*F.shape[1]))*100:.2f}%\")\n",
    "    \n",
    "    # Verify expansion\n",
    "    print(f\"\\n{'-'*30}\")\n",
    "    print(\"Verification:\")\n",
    "    print(f\"{'-'*30}\")\n",
    "    for i in range(n_cases):\n",
    "        start_col = i * n_timesteps\n",
    "        end_col = start_col + n_timesteps\n",
    "        # Verify all columns for this case are identical\n",
    "        if np.allclose(F[:, start_col:end_col], F[:, start_col:start_col+1], rtol=1e-10):\n",
    "            print(f\"Case {i+1}: Force vector correctly repeated ✓\")\n",
    "        else:\n",
    "            print(f\"Case {i+1}: WARNING - Force vector not consistent!\")\n",
    "    \n",
    "    return F\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Create expanded force matrix\n",
    "        F_constructed = create_force_matrix(f_constrained)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating force matrix: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import matplotlib.tri as mtri\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "\n",
    "def parse_mdpa_file(mdpa_file):\n",
    "    \"\"\"Parse MDPA file to extract node coordinates and element connectivity\"\"\"\n",
    "    print(f\"Starting to parse {mdpa_file}\")\n",
    "    nodes = []\n",
    "    elements = []\n",
    "    load_nodes = {\n",
    "        'Load_1': [],\n",
    "        'Load_2': [],\n",
    "        'Load_3': []\n",
    "    }\n",
    "    \n",
    "    reading_nodes = False\n",
    "    reading_elements = False\n",
    "    reading_load_nodes = False\n",
    "    current_load = None\n",
    "    \n",
    "    with open(mdpa_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if \"Begin Nodes\" in line:\n",
    "                reading_nodes = True\n",
    "                continue\n",
    "            elif \"End Nodes\" in line:\n",
    "                reading_nodes = False\n",
    "            elif \"Begin Elements SmallDisplacementElement2D3N\" in line:\n",
    "                reading_elements = True\n",
    "                continue\n",
    "            elif \"End Elements\" in line:\n",
    "                reading_elements = False\n",
    "            elif \"Begin SubModelPart LinePressure2D_Load_1\" in line:\n",
    "                current_load = 'Load_1'\n",
    "            elif \"Begin SubModelPart LinePressure2D_Load_2\" in line:\n",
    "                current_load = 'Load_2'\n",
    "            elif \"Begin SubModelPart LinePressure2D_Load_3\" in line:\n",
    "                current_load = 'Load_3'\n",
    "            elif \"End SubModelPart\" in line:\n",
    "                current_load = None\n",
    "            \n",
    "            if reading_nodes and line:\n",
    "                try:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4:\n",
    "                        node_id = int(parts[0])\n",
    "                        x = float(parts[1])\n",
    "                        y = float(parts[2])\n",
    "                        nodes.append([x, y])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            \n",
    "            if reading_elements and line:\n",
    "                try:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 5:\n",
    "                        element_nodes = [int(node)-1 for node in parts[2:5]]\n",
    "                        elements.append(element_nodes)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                    \n",
    "            if current_load and \"Begin SubModelPartNodes\" in line:\n",
    "                reading_load_nodes = True\n",
    "            elif current_load and \"End SubModelPartNodes\" in line:\n",
    "                reading_load_nodes = False\n",
    "            elif current_load and reading_load_nodes and line:\n",
    "                try:\n",
    "                    node_id = int(line)\n",
    "                    load_nodes[current_load].append(node_id - 1)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "    \n",
    "    print(f\"Parsed {len(nodes)} nodes and {len(elements)} elements\")\n",
    "    return np.array(nodes), np.array(elements), load_nodes\n",
    "\n",
    "def create_force_plot(f_constrained, node_coords, elements, load_nodes, case_idx, output_dir, scale_factor=1.0):\n",
    "    \"\"\"Create and save enhanced force plot with detailed numerical annotations\"\"\"\n",
    "    print(f\"\\nCreating plot for case {case_idx + 1}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(output_dir)\n",
    "    case_dir = output_dir / f\"case_{case_idx+1}\"\n",
    "    case_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Get forces for this case\n",
    "    forces = f_constrained[:, case_idx].reshape(-1, 2)\n",
    "    \n",
    "    # Create figure with two subplots, adding extra space for legend\n",
    "    fig = plt.figure(figsize=(22, 10))\n",
    "    gs = plt.GridSpec(1, 2, width_ratios=[2.5, 1])\n",
    "    ax_main = fig.add_subplot(gs[0])\n",
    "    ax_info = fig.add_subplot(gs[1])\n",
    "    \n",
    "    # Create triangulation for heatmap\n",
    "    triang = mtri.Triangulation(node_coords[:, 0], node_coords[:, 1], elements)\n",
    "    \n",
    "    # Custom colormap using valid hex colors\n",
    "    colors = ['#03045E', '#0077B6', '#90E0EF', '#FFFFFF', '#FFAFCC', '#FF0000', '#6A040F']\n",
    "    cmap = LinearSegmentedColormap.from_list(\"force_cmap\", colors, N=256)\n",
    "    \n",
    "    # Calculate force magnitude\n",
    "    force_magnitude = np.linalg.norm(forces, axis=1)\n",
    "    force_max = np.max(np.abs(force_magnitude))\n",
    "    \n",
    "    # Plot force magnitude as color map\n",
    "    tripcolor = ax_main.tripcolor(triang, force_magnitude, cmap=cmap,\n",
    "                                shading='gouraud', vmin=-force_max, vmax=force_max)\n",
    "    \n",
    "    # Plot mesh with thin black lines\n",
    "    for element in elements:\n",
    "        x = node_coords[element, 0]\n",
    "        y = node_coords[element, 1]\n",
    "        ax_main.plot(x, y, color='#333333', linewidth=0.3, alpha=0.2)\n",
    "    \n",
    "    # Define load properties with valid hex colors\n",
    "    load_properties = {\n",
    "        'Load_1': {'color': '#FF0000', 'label': 'Vertical Load', 'marker': 's'},\n",
    "        'Load_2': {'color': '#0077B6', 'label': 'Horizontal Load 1', 'marker': 'o'},\n",
    "        'Load_3': {'color': '#38B000', 'label': 'Horizontal Load 2', 'marker': '^'}\n",
    "    }\n",
    "    \n",
    "    # Plot force vectors and create summary table data\n",
    "    table_data = []\n",
    "    legend_handles = []\n",
    "    \n",
    "    for load_type, nodes in load_nodes.items():\n",
    "        props = load_properties[load_type]\n",
    "        load_forces = []\n",
    "        \n",
    "        for node_idx in nodes:\n",
    "            force = forces[node_idx]\n",
    "            magnitude = np.linalg.norm(force)\n",
    "            load_forces.append(magnitude)\n",
    "            \n",
    "            if magnitude > 0:\n",
    "                # Plot arrow\n",
    "                quiver = ax_main.quiver(node_coords[node_idx, 0], node_coords[node_idx, 1],\n",
    "                                      force[0], force[1], color=props['color'],\n",
    "                                      scale=scale_factor, width=0.005,\n",
    "                                      label=props['label'])\n",
    "                \n",
    "                # Add force magnitude annotation based on direction\n",
    "                if abs(force[0]) > 0:  # X direction force\n",
    "                    # Place on the left side of the structure\n",
    "                    ax_main.annotate(f'Node {node_idx+1}\\n{magnitude:.2e} N',\n",
    "                                   xy=(node_coords[node_idx, 0], node_coords[node_idx, 1]),\n",
    "                                   xytext=(-120, 0),  # Offset to the left\n",
    "                                   textcoords='offset points',\n",
    "                                   color=props['color'],\n",
    "                                   fontsize=8,\n",
    "                                   bbox=dict(facecolor='#FFFFFF', edgecolor=props['color'],\n",
    "                                           alpha=0.7, boxstyle='round,pad=0.5'),\n",
    "                                   ha='right',\n",
    "                                   va='center',\n",
    "                                   arrowprops=dict(arrowstyle='->',\n",
    "                                                 color=props['color'],\n",
    "                                                 alpha=0.5))\n",
    "                if abs(force[1]) > 0:  # Y direction force\n",
    "                    # Place on top of the structure\n",
    "                    ax_main.annotate(f'Node {node_idx+1}\\n{magnitude:.2e} N',\n",
    "                                   xy=(node_coords[node_idx, 0], node_coords[node_idx, 1]),\n",
    "                                   xytext=(0, 40),  # Offset upward\n",
    "                                   textcoords='offset points',\n",
    "                                   color=props['color'],\n",
    "                                   fontsize=8,\n",
    "                                   bbox=dict(facecolor='#FFFFFF', edgecolor=props['color'],\n",
    "                                           alpha=0.7, boxstyle='round,pad=0.5'),\n",
    "                                   ha='center',\n",
    "                                   va='bottom',\n",
    "                                   arrowprops=dict(arrowstyle='->',\n",
    "                                                 color=props['color'],\n",
    "                                                 alpha=0.5))\n",
    "                \n",
    "                if load_type not in [h.get_label() for h in legend_handles]:\n",
    "                    legend_handles.append(quiver)\n",
    "        \n",
    "        if load_forces:  # Only add to table if there are forces\n",
    "            table_data.append([\n",
    "                props['label'],\n",
    "                f\"{len(nodes)} nodes\",\n",
    "                f\"{np.mean(load_forces):.2e}\",\n",
    "                f\"{np.max(load_forces):.2e}\",\n",
    "                f\"{np.min([f for f in load_forces if f > 0]):.2e}\"\n",
    "            ])\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(tripcolor, ax=ax_main, label='Force Magnitude (N)')\n",
    "    cbar.formatter.set_scientific(True)\n",
    "    cbar.formatter.set_powerlimits((-2, 2))\n",
    "    cbar.update_ticks()\n",
    "    \n",
    "    # Add legend outside the plot\n",
    "    ax_main.legend(handles=legend_handles, \n",
    "                  loc='center left', \n",
    "                  bbox_to_anchor=(1.02, 0.5),\n",
    "                  borderaxespad=0)\n",
    "    \n",
    "    # Configure main plot\n",
    "    ax_main.set_title(f'Force Field Distribution - Case {case_idx + 1}', pad=20)\n",
    "    ax_main.set_xlabel('X Coordinate (m)')\n",
    "    ax_main.set_ylabel('Y Coordinate (m)')\n",
    "    ax_main.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # Set axis limits with margin\n",
    "    x_min, x_max = np.min(node_coords[:, 0]), np.max(node_coords[:, 0])\n",
    "    y_min, y_max = np.min(node_coords[:, 1]), np.max(node_coords[:, 1])\n",
    "    margin = 0.1 * max(x_max - x_min, y_max - y_min)\n",
    "    ax_main.set_xlim(x_min - margin, x_max + margin)\n",
    "    ax_main.set_ylim(y_min - margin, y_max + margin)\n",
    "    ax_main.set_aspect('equal')\n",
    "    \n",
    "    # Create summary table in the right subplot\n",
    "    ax_info.axis('off')\n",
    "    if table_data:  # Only create table if we have data\n",
    "        table = ax_info.table(\n",
    "            cellText=table_data,\n",
    "            colLabels=['Load Type', 'Node Count', 'Mean Force (N)',\n",
    "                      'Max Force (N)', 'Min Force (N)'],\n",
    "            loc='center',\n",
    "            cellLoc='center',\n",
    "            colColours=['#F0F0F0']*5\n",
    "        )\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(9)\n",
    "        table.scale(1.2, 1.5)\n",
    "    \n",
    "    # Add title to the table\n",
    "    ax_info.set_title('Force Summary', pad=20)\n",
    "    \n",
    "    # Add case information\n",
    "    info_text = (f\"Case {case_idx + 1} Summary:\\n\"\n",
    "                f\"Total Nodes: {len(node_coords)}\\n\"\n",
    "                f\"Total Elements: {len(elements)}\\n\"\n",
    "                f\"Maximum Force: {force_max:.2e} N\\n\"\n",
    "                f\"Scale Factor: {scale_factor}\")\n",
    "    ax_info.text(0.1, 0.8, info_text, transform=ax_info.transAxes,\n",
    "                bbox=dict(facecolor='#FFFFFF', edgecolor='#000000', alpha=0.8))\n",
    "    \n",
    "    # Save plot\n",
    "    plt.tight_layout()\n",
    "    output_file = case_dir / 'force_field_detailed.png'\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Enhanced plot saved as: {output_file}\")\n",
    "\n",
    "def process_all_cases(f_constrained, mdpa_file, output_dir=\"Dynamic_solution\", scale_factor=1.0):\n",
    "    \"\"\"Process force visualizations for all cases\"\"\"\n",
    "    print(\"\\nStarting force visualization process...\")\n",
    "    print(f\"Force vector shape: {f_constrained.shape}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Parse MDPA file\n",
    "    node_coords, elements, load_nodes = parse_mdpa_file(mdpa_file)\n",
    "    \n",
    "    # Number of cases is the number of columns in f_constrained\n",
    "    n_cases = f_constrained.shape[1]\n",
    "    print(f\"Number of cases to process: {n_cases}\")\n",
    "    \n",
    "    for case_idx in range(n_cases):\n",
    "        try:\n",
    "            create_force_plot(f_constrained, node_coords, elements, load_nodes,\n",
    "                           case_idx, output_dir, scale_factor)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing case {case_idx + 1}: {str(e)}\")\n",
    "\n",
    "# Run the visualization\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "mdpa_file = \"2D_beam_udl_loading.mdpa\"\n",
    "process_all_cases(f_constrained=f_constrained,\n",
    "                 mdpa_file=mdpa_file,\n",
    "                 scale_factor=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_mode_shape_plot(displacements, node_coords, elements, case_idx, frequency, output_dir, scale_factor=1.0):\n",
    "    \"\"\"Create and save mode shape plot for a single case with frequency information\"\"\"\n",
    "    print(f\"\\nCreating mode shape plot for Mode {case_idx + 1}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(output_dir)\n",
    "    case_dir = output_dir / f\"mode_shape_{case_idx+1}\"\n",
    "    case_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Get displacements for this case\n",
    "    disp = displacements[:, case_idx].reshape(-1, 2)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Create triangulation for heatmap\n",
    "    triang = mtri.Triangulation(node_coords[:, 0], node_coords[:, 1], elements)\n",
    "    \n",
    "    # Custom colormap for displacements\n",
    "    colors = ['#03045E', '#0077B6', '#90E0EF', '#FFFFFF', '#FFAFCC', '#FF0000', '#6A040F']\n",
    "    cmap = LinearSegmentedColormap.from_list(\"disp_cmap\", colors, N=256)\n",
    "    \n",
    "    # Calculate displacement magnitude\n",
    "    disp_magnitude = np.linalg.norm(disp, axis=1)\n",
    "    disp_max = np.max(np.abs(disp_magnitude))\n",
    "    \n",
    "    # Plot displacement magnitude as color map\n",
    "    tripcolor = ax.tripcolor(triang, disp_magnitude, cmap=cmap,\n",
    "                             shading='gouraud', vmin=-disp_max, vmax=disp_max)\n",
    "    \n",
    "    # Plot mesh with thin black lines\n",
    "    for element in elements:\n",
    "        x = node_coords[element, 0]\n",
    "        y = node_coords[element, 1]\n",
    "        ax.plot(x, y, color='#333333', linewidth=0.3, alpha=0.2)\n",
    "    \n",
    "    # Plot displacement vectors\n",
    "    ax.quiver(node_coords[:, 0], node_coords[:, 1],\n",
    "              disp[:, 0], disp[:, 1], color='#FF0000',\n",
    "              scale=scale_factor, width=0.005, label='Displacement')\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(tripcolor, ax=ax, label='Displacement Magnitude (m)')\n",
    "    cbar.formatter.set_scientific(True)\n",
    "    cbar.formatter.set_powerlimits((-2, 2))\n",
    "    cbar.update_ticks()\n",
    "    \n",
    "    # Add title with frequency information\n",
    "    ax.set_title(f'Mode Shape {case_idx + 1}\\nFrequency: {frequency:.2f} Hz', pad=20)\n",
    "    ax.set_xlabel('X Coordinate (m)')\n",
    "    ax.set_ylabel('Y Coordinate (m)')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # Set axis limits with margin\n",
    "    x_min, x_max = np.min(node_coords[:, 0]), np.max(node_coords[:, 0])\n",
    "    y_min, y_max = np.min(node_coords[:, 1]), np.max(node_coords[:, 1])\n",
    "    margin = 0.1 * max(x_max - x_min, y_max - y_min)\n",
    "    ax.set_xlim(x_min - margin, x_max + margin)\n",
    "    ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # Save plot\n",
    "    plt.tight_layout()\n",
    "    output_file = case_dir / f'mode_shape_{case_idx+1}.png'\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Mode shape plot saved as: {output_file}\")\n",
    "\n",
    "def process_first_three_mode_shapes(displacements, frequencies, mdpa_file, output_dir=\"Mode_Shapes\", scale_factor=1.0):\n",
    "    \"\"\"Process and visualize the first three mode shapes\"\"\"\n",
    "    print(\"\\nStarting mode shape visualization process...\")\n",
    "    print(f\"Displacement vector shape: {displacements.shape}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Parse MDPA file\n",
    "    node_coords, elements, _ = parse_mdpa_file(mdpa_file)\n",
    "    \n",
    "    # Ensure we only process the first three mode shapes\n",
    "    n_modes = min(3, displacements.shape[1])\n",
    "    print(f\"Number of mode shapes to process: {n_modes}\")\n",
    "    \n",
    "    for case_idx in range(n_modes):\n",
    "        try:\n",
    "            create_mode_shape_plot(displacements, node_coords, elements,\n",
    "                                case_idx, frequencies[case_idx], output_dir, scale_factor)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing mode shape {case_idx + 1}: {str(e)}\")\n",
    "\n",
    "# Run the visualization\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "mdpa_file = \"2D_beam_udl_loading.mdpa\"\n",
    "\n",
    "# Example: Define displacements and frequencies\n",
    "# Replace this with your actual data\n",
    "displacements = np.random.rand(100, 6)  # Example: 100 nodes, 6 mode shapes\n",
    "frequencies = [0.03, 0.03, 0.03, 0.03, 0.03, 0.03]  # Example frequencies\n",
    "\n",
    "# Process the first three mode shapes\n",
    "process_first_three_mode_shapes(displacements=x_constructed,\n",
    "                                frequencies=frequencies,\n",
    "                                mdpa_file=mdpa_file,\n",
    "                                scale_factor=1e15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_svd_with_threshold(U, threshold=1e-12):\n",
    "    \"\"\"\n",
    "    Compute the Singular Value Decomposition (SVD) of matrix U\n",
    "    and determine the truncation index based on a singular value threshold.\n",
    "\n",
    "    Parameters:\n",
    "    U (ndarray): Input matrix.\n",
    "    threshold (float): Singular value threshold for truncation.\n",
    "\n",
    "    Returns:\n",
    "    U_svd (ndarray): Left singular vectors.\n",
    "    sigma (ndarray): Singular values.\n",
    "    Vt (ndarray): Right singular vectors (transposed).\n",
    "    U_truncated (ndarray): Truncated U_svd matrix.\n",
    "    truncation_index (int): Index where singular values drop below the threshold.\n",
    "    \"\"\"\n",
    "    # Perform SVD\n",
    "    U_svd, sigma, Vt = np.linalg.svd(U, full_matrices=False)\n",
    "\n",
    "    # Find the truncation index where sigma drops below the threshold\n",
    "    truncation_index = np.argmax(sigma < threshold) if np.any(sigma < threshold) else len(sigma)\n",
    "\n",
    "    # Truncate U_svd\n",
    "    U_truncated = U_svd[:, :truncation_index]\n",
    "\n",
    "    # Plot singular values\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.semilogy(sigma, 'bo-', label=\"Singular Values\")\n",
    "    plt.axvline(truncation_index, color='r', linestyle='--', label=f\"Truncation Index = {truncation_index}\")\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(\"Singular Value (log scale)\")\n",
    "    plt.title(\"Singular Value Spectrum with Threshold\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return U_svd, sigma, Vt, U_truncated, truncation_index\n",
    "\n",
    "# Example usage\n",
    "# Assuming x_constructed is your input matrix\n",
    "U_svd, sigma, Vt, V_r, truncation_index = compute_svd_with_threshold(x_constructed, threshold=1e-18)\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Truncation Index:\", truncation_index)\n",
    "print(\"V_r shape:\", V_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reduce_and_reconstruct_with_Vr(V_r, *vectors):\n",
    "    \"\"\"\n",
    "    Reduce and reconstruct multiple vectors using the reduced basis V_r.\n",
    "\n",
    "    Parameters:\n",
    "    V_r (ndarray): Reduced basis (truncated left singular vectors).\n",
    "    *vectors (ndarray): Original vectors to be reduced and reconstructed (e.g., displacement, velocity, acceleration, force).\n",
    "\n",
    "    Returns:\n",
    "    reconstructed_vectors (list): List of reconstructed vectors.\n",
    "    errors (list): List of percentage errors between original and reconstructed vectors.\n",
    "    \"\"\"\n",
    "    reconstructed_vectors = []\n",
    "    errors = []\n",
    "\n",
    "    for vector in vectors:\n",
    "        # Step 1: Project the vector onto the reduced basis\n",
    "        reduced_vector = V_r.T @ vector\n",
    "\n",
    "        # Step 2: Reconstruct the vector from the reduced representation\n",
    "        reconstructed_vector = V_r @ reduced_vector\n",
    "\n",
    "        # Step 3: Calculate the percentage error\n",
    "        error = np.linalg.norm(vector - reconstructed_vector) / np.linalg.norm(vector) * 100\n",
    "\n",
    "        # Append results to lists\n",
    "        reconstructed_vectors.append(reconstructed_vector)\n",
    "        errors.append(error)\n",
    "\n",
    "    return reconstructed_vectors, errors\n",
    "\n",
    "# Example usage\n",
    "# Assuming V_r is already computed (truncated left singular vectors)\n",
    "# Assuming x_constructed, v_constructed, a_constructed, F_constructed are your input matrices\n",
    "reconstructed_vectors, errors = reduce_and_reconstruct_with_Vr(\n",
    "    V_r, x_constructed, v_constructed, a_constructed, F_constructed\n",
    ")\n",
    "\n",
    "# Unpack the results\n",
    "x_reconstructed, v_reconstructed, a_reconstructed, F_reconstructed = reconstructed_vectors\n",
    "x_error, v_error, a_error, F_error = errors\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Displacement Error (%):\", x_error)\n",
    "print(\"Velocity Error (%):\", v_error)\n",
    "print(\"Acceleration Error (%):\", a_error)\n",
    "print(\"Force Error (%):\", F_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def reduce_and_reconstruct(V_r, X):\n",
    "#     \"\"\"\n",
    "#     Reduce and reconstruct a matrix using the truncated basis V_r.\n",
    "\n",
    "#     Parameters:\n",
    "#     V_r (ndarray): Truncated basis (U_truncated).\n",
    "#     X (ndarray): Original matrix to reduce and reconstruct.\n",
    "\n",
    "#     Returns:\n",
    "#     X_reduced (ndarray): Reduced matrix.\n",
    "#     X_reconstructed (ndarray): Reconstructed matrix.\n",
    "#     error_percentage (float): Error percentage after reconstruction.\n",
    "#     \"\"\"\n",
    "#     # Step 1: Reduce the matrix\n",
    "#     X_reduced = V_r.T @ X\n",
    "\n",
    "#     # Step 2: Reconstruct the matrix\n",
    "#     X_reconstructed = V_r @ X_reduced\n",
    "\n",
    "#     # Step 3: Calculate the error percentage\n",
    "#     error = np.linalg.norm(X - X_reconstructed, ord='fro') / np.linalg.norm(X, ord='fro') * 100\n",
    "\n",
    "#     return X_reduced, X_reconstructed, error\n",
    "\n",
    "# # Reduce and reconstruct each matrix\n",
    "# x_reduced, x_reconstructed, x_error = reduce_and_reconstruct(V_r, x_constructed)\n",
    "# v_reduced, v_reconstructed, v_error = reduce_and_reconstruct(V_r, v_constructed)\n",
    "# a_reduced, a_reconstructed, a_error = reduce_and_reconstruct(V_r, a_constructed)\n",
    "# f_reduced, f_reconstructed, f_error = reduce_and_reconstruct(V_r, F_constructed)\n",
    "\n",
    "# # Display results\n",
    "# print(\"=\" * 50)\n",
    "# print(\"Reduced and Reconstructed Matrices:\")\n",
    "# print(\"=\" * 50)\n",
    "# print(f\"x_constructed:\")\n",
    "# print(f\"  Reduced shape: {x_reduced.shape}\")\n",
    "# print(f\"  Reconstructed shape: {x_reconstructed.shape}\")\n",
    "# print(f\"  Error Percentage: {x_error:.4f}%\")\n",
    "# print(\"-\" * 50)\n",
    "# print(f\"v_constructed:\")\n",
    "# print(f\"  Reduced shape: {v_reduced.shape}\")\n",
    "# print(f\"  Reconstructed shape: {v_reconstructed.shape}\")\n",
    "# print(f\"  Error Percentage: {v_error:.4f}%\")\n",
    "# print(\"-\" * 50)\n",
    "# print(f\"a_constructed:\")\n",
    "# print(f\"  Reduced shape: {a_reduced.shape}\")\n",
    "# print(f\"  Reconstructed shape: {a_reconstructed.shape}\")\n",
    "# print(f\"  Error Percentage: {a_error:.4f}%\")\n",
    "# print(\"-\" * 50)\n",
    "# print(f\"f_constructed:\")\n",
    "# print(f\"  Reduced shape: {f_reduced.shape}\")\n",
    "# print(f\"  Reconstructed shape: {f_reconstructed.shape}\")\n",
    "# print(f\"  Error Percentage: {f_error:.4f}%\")\n",
    "# print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def compute_pod_basis(snapshots, energy_threshold=0.9999):\n",
    "#     \"\"\"\n",
    "#     Compute POD basis using SVD.\n",
    "    \n",
    "#     Parameters:\n",
    "#     snapshots: Snapshot matrix\n",
    "#     energy_threshold: Threshold for cumulative energy (default 0.9999)\n",
    "    \n",
    "#     Returns:\n",
    "#     V_r: Truncated POD basis\n",
    "#     \"\"\"\n",
    "#     # Compute SVD\n",
    "#     U, S, Vh = np.linalg.svd(snapshots, full_matrices=False)\n",
    "    \n",
    "#     # Compute cumulative energy\n",
    "#     total_energy = np.sum(S**2)\n",
    "#     cumulative_energy = np.cumsum(S**2) / total_energy\n",
    "    \n",
    "#     # Find number of modes needed\n",
    "#     n_modes = np.where(cumulative_energy >= energy_threshold)[0][0] + 1\n",
    "    \n",
    "#     # Return truncated basis\n",
    "#     return U[:, :n_modes]\n",
    "\n",
    "# def reduce_and_reconstruct(V_r, X):\n",
    "#     \"\"\"\n",
    "#     Reduce and reconstruct a matrix using the truncated basis V_r.\n",
    "#     \"\"\"\n",
    "#     # Reduce\n",
    "#     X_reduced = V_r.T @ X\n",
    "    \n",
    "#     # Reconstruct\n",
    "#     X_reconstructed = V_r @ X_reduced\n",
    "    \n",
    "#     # Calculate error\n",
    "#     error = np.linalg.norm(X - X_reconstructed, ord='fro') / np.linalg.norm(X, ord='fro') * 100\n",
    "    \n",
    "#     return X_reduced, X_reconstructed, error\n",
    "\n",
    "# # Approach 1: Separate bases for each quantity\n",
    "# def separate_bases_approach(x_snapshots, v_snapshots, a_snapshots, f_snapshots):\n",
    "#     \"\"\"\n",
    "#     Create and use separate POD bases for each quantity.\n",
    "#     \"\"\"\n",
    "#     # Compute separate bases\n",
    "#     V_r_x = compute_pod_basis(x_snapshots)\n",
    "#     V_r_v = compute_pod_basis(v_snapshots)\n",
    "#     V_r_a = compute_pod_basis(a_snapshots)\n",
    "#     V_r_f = compute_pod_basis(f_snapshots)\n",
    "    \n",
    "#     # Reduce and reconstruct each quantity\n",
    "#     x_results = reduce_and_reconstruct(V_r_x, x_constructed)\n",
    "#     v_results = reduce_and_reconstruct(V_r_v, v_constructed)\n",
    "#     a_results = reduce_and_reconstruct(V_r_a, a_constructed)\n",
    "#     f_results = reduce_and_reconstruct(V_r_f, F_constructed)\n",
    "    \n",
    "#     return {\n",
    "#         'displacement': x_results,\n",
    "#         'velocity': v_results,\n",
    "#         'acceleration': a_results,\n",
    "#         'force': f_results\n",
    "#     }\n",
    "\n",
    "# # Approach 2: Combined basis\n",
    "# def combined_basis_approach(x_snapshots, v_snapshots, a_snapshots, f_snapshots):\n",
    "#     \"\"\"\n",
    "#     Create and use a combined basis for all quantities.\n",
    "#     \"\"\"\n",
    "#     # Scale each quantity\n",
    "#     x_scaled = x_snapshots / np.linalg.norm(x_snapshots)\n",
    "#     v_scaled = v_snapshots / np.linalg.norm(v_snapshots)\n",
    "#     a_scaled = a_snapshots / np.linalg.norm(a_snapshots)\n",
    "#     f_scaled = f_snapshots / np.linalg.norm(f_snapshots)\n",
    "    \n",
    "#     # Combine scaled snapshots\n",
    "#     combined_snapshots = np.concatenate([x_scaled, v_scaled, a_scaled, f_scaled], axis=1)\n",
    "    \n",
    "#     # Compute combined basis\n",
    "#     V_r_combined = compute_pod_basis(combined_snapshots)\n",
    "    \n",
    "#     print(V_r_combined.shape)\n",
    "    \n",
    "#     # Reduce and reconstruct each quantity\n",
    "#     x_results = reduce_and_reconstruct(V_r_combined, x_constructed)\n",
    "#     v_results = reduce_and_reconstruct(V_r_combined, v_constructed)\n",
    "#     a_results = reduce_and_reconstruct(V_r_combined, a_constructed)\n",
    "#     f_results = reduce_and_reconstruct(V_r_combined, F_constructed)\n",
    "    \n",
    "#     return {\n",
    "#         'displacement': x_results,\n",
    "#         'velocity': v_results,\n",
    "#         'acceleration': a_results,\n",
    "#         'force': f_results\n",
    "#     }\n",
    "\n",
    "# # Function to display results\n",
    "# def display_results(results, approach_name):\n",
    "#     print(f\"\\n{approach_name} Results:\")\n",
    "#     print(\"=\" * 50)\n",
    "#     for quantity, (reduced, reconstructed, error) in results.items():\n",
    "#         print(f\"{quantity}:\")\n",
    "#         print(f\"  Reduced shape: {reduced.shape}\")\n",
    "#         print(f\"  Reconstructed shape: {reconstructed.shape}\")\n",
    "#         print(f\"  Error Percentage: {error:.4f}%\")\n",
    "#         print(\"-\" * 50)\n",
    "\n",
    "# # Use both approaches and compare\n",
    "# # First, separate bases\n",
    "# separate_results = separate_bases_approach(x_constructed, v_constructed, a_constructed, F_constructed)\n",
    "# display_results(separate_results, \"Separate Bases\")\n",
    "\n",
    "# # Create snapshot matrices from your constructed data if needed\n",
    "# x_snapshots = x_constructed\n",
    "# v_snapshots = v_constructed\n",
    "# a_snapshots = a_constructed\n",
    "# f_snapshots = F_constructed\n",
    "\n",
    "# # Then use these in your function call\n",
    "# combined_results = combined_basis_approach(x_snapshots, v_snapshots, a_snapshots, f_snapshots)\n",
    "\n",
    "# display_results(combined_results, \"Combined Basis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def compute_pod_basis(snapshots, energy_threshold=0.9999):\n",
    "#     \"\"\"\n",
    "#     Compute POD basis using SVD.\n",
    "    \n",
    "#     Parameters:\n",
    "#     snapshots: Snapshot matrix\n",
    "#     energy_threshold: Threshold for cumulative energy (default 0.9999)\n",
    "    \n",
    "#     Returns:\n",
    "#     V_r: Truncated POD basis\n",
    "#     \"\"\"\n",
    "#     # Compute SVD\n",
    "#     U, S, Vh = np.linalg.svd(snapshots, full_matrices=False)\n",
    "    \n",
    "#     # Compute cumulative energy\n",
    "#     total_energy = np.sum(S**2)\n",
    "#     cumulative_energy = np.cumsum(S**2) / total_energy\n",
    "    \n",
    "#     # Find number of modes needed\n",
    "#     n_modes = np.where(cumulative_energy >= energy_threshold)[0][0] + 1\n",
    "    \n",
    "#     # Return truncated basis\n",
    "#     return U[:, :n_modes]\n",
    "\n",
    "# def reduce_and_reconstruct(V_r, X):\n",
    "#     \"\"\"\n",
    "#     Reduce and reconstruct a matrix using the truncated basis V_r.\n",
    "#     \"\"\"\n",
    "#     # Reduce\n",
    "#     X_reduced = V_r.T @ X\n",
    "    \n",
    "#     # Reconstruct\n",
    "#     X_reconstructed = V_r @ X_reduced\n",
    "    \n",
    "#     # Calculate error\n",
    "#     error = np.linalg.norm(X - X_reconstructed, ord='fro') / np.linalg.norm(X, ord='fro') * 100\n",
    "    \n",
    "#     return X_reduced, X_reconstructed, error\n",
    "\n",
    "# # Approach 1: Separate bases for each quantity\n",
    "# def separate_bases_approach(x_snapshots, v_snapshots, a_snapshots, f_snapshots):\n",
    "#     \"\"\"\n",
    "#     Create and use separate POD bases for each quantity.\n",
    "#     \"\"\"\n",
    "#     # Compute separate bases\n",
    "#     V_r_x = compute_pod_basis(x_snapshots)\n",
    "#     V_r_v = compute_pod_basis(v_snapshots)\n",
    "#     V_r_a = compute_pod_basis(a_snapshots)\n",
    "#     V_r_f = compute_pod_basis(f_snapshots)\n",
    "    \n",
    "#     # Reduce and reconstruct each quantity\n",
    "#     x_results = reduce_and_reconstruct(V_r_x, x_constructed)\n",
    "#     v_results = reduce_and_reconstruct(V_r_v, v_constructed)\n",
    "#     a_results = reduce_and_reconstruct(V_r_a, a_constructed)\n",
    "#     f_results = reduce_and_reconstruct(V_r_f, F_constructed)\n",
    "    \n",
    "#     return {\n",
    "#         'displacement': x_results,\n",
    "#         'velocity': v_results,\n",
    "#         'acceleration': a_results,\n",
    "#         'force': f_results\n",
    "#     }\n",
    "\n",
    "# # Approach 2: Combined basis\n",
    "# def combined_basis_approach(x_snapshots, v_snapshots, a_snapshots, f_snapshots):\n",
    "#     \"\"\"\n",
    "#     Create and use a combined basis for all quantities and return the results as a tuple.\n",
    "#     \"\"\"\n",
    "#     # Scale each quantity so that each snapshot has unit norm\n",
    "#     x_scaled = x_snapshots / np.linalg.norm(x_snapshots)\n",
    "#     v_scaled = v_snapshots / np.linalg.norm(v_snapshots)\n",
    "#     a_scaled = a_snapshots / np.linalg.norm(a_snapshots)\n",
    "#     f_scaled = f_snapshots / np.linalg.norm(f_snapshots)\n",
    "    \n",
    "#     # Combine the scaled snapshot matrices along the columns\n",
    "#     combined_snapshots = np.concatenate([x_scaled, v_scaled, a_scaled, f_scaled], axis=1)\n",
    "    \n",
    "#     # Compute the POD basis for the combined snapshots\n",
    "#     V_r_combined = compute_pod_basis(combined_snapshots)\n",
    "    \n",
    "#     # print(V_r_combined.shape)\n",
    "    \n",
    "#     # Reduce and reconstruct each quantity using the combined basis\n",
    "#     x_results = reduce_and_reconstruct(V_r_combined, x_constructed)\n",
    "#     v_results = reduce_and_reconstruct(V_r_combined, v_constructed)\n",
    "#     a_results = reduce_and_reconstruct(V_r_combined, a_constructed)\n",
    "#     f_results = reduce_and_reconstruct(V_r_combined, F_constructed)\n",
    "    \n",
    "#     # Return the results as a tuple instead of a dictionary\n",
    "#     return x_results, V_r_combined\n",
    "\n",
    "# # Function to display results\n",
    "# def display_results(results, approach_name):\n",
    "#     print(f\"\\n{approach_name} Results:\")\n",
    "#     print(\"=\" * 50)\n",
    "#     for quantity, (reduced, reconstructed, error) in results.items():\n",
    "#         print(f\"{quantity}:\")\n",
    "#         print(f\"  Reduced shape: {reduced.shape}\")\n",
    "#         print(f\"  Reconstructed shape: {reconstructed.shape}\")\n",
    "#         print(f\"  Error Percentage: {error:.4f}%\")\n",
    "#         print(\"-\" * 50)\n",
    "\n",
    "# # Use both approaches and compare\n",
    "# # First, separate bases\n",
    "# separate_results = separate_bases_approach(x_constructed, v_constructed, a_constructed, F_constructed)\n",
    "# display_results(separate_results, \"Separate Bases\")\n",
    "\n",
    "# # Create snapshot matrices from your constructed data if needed\n",
    "# x_snapshots = x_constructed\n",
    "# v_snapshots = v_constructed\n",
    "# a_snapshots = a_constructed\n",
    "# f_snapshots = F_constructed\n",
    "\n",
    "# # Then use these in your function call\n",
    "# # combined_results = combined_basis_approach(x_snapshots, v_snapshots, a_snapshots, f_snapshots)\n",
    "# V_r = combined_basis_approach(x_snapshots, v_snapshots, a_snapshots, f_snapshots)\n",
    "\n",
    "# # display_results(V_r, \"Combined Basis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def compute_pod_basis(snapshots, energy_threshold=0.9999):\n",
    "#     \"\"\"\n",
    "#     Compute POD basis using SVD.\n",
    "\n",
    "#     Parameters:\n",
    "#     snapshots: Snapshot matrix\n",
    "#     energy_threshold: Threshold for cumulative energy (default 0.9999)\n",
    "\n",
    "#     Returns:\n",
    "#     V_r: Truncated POD basis\n",
    "#     \"\"\"\n",
    "#     # Compute SVD\n",
    "#     U, S, Vh = np.linalg.svd(snapshots, full_matrices=False)\n",
    "\n",
    "#     # Compute cumulative energy\n",
    "#     total_energy = np.sum(S**2)\n",
    "#     cumulative_energy = np.cumsum(S**2) / total_energy\n",
    "\n",
    "#     # Find number of modes needed\n",
    "#     n_modes = np.where(cumulative_energy >= energy_threshold)[0][0] + 1\n",
    "\n",
    "#     # Return truncated basis\n",
    "#     return U[:, :n_modes]\n",
    "\n",
    "# def reduce_and_reconstruct(V_r, X):\n",
    "#     \"\"\"\n",
    "#     Reduce and reconstruct a matrix using the truncated basis V_r.\n",
    "#     \"\"\"\n",
    "#     # Reduce\n",
    "#     X_reduced = V_r.T @ X\n",
    "\n",
    "#     # Reconstruct\n",
    "#     X_reconstructed = V_r @ X_reduced\n",
    "\n",
    "#     # Calculate error\n",
    "#     error = np.linalg.norm(X - X_reconstructed, ord='fro') / np.linalg.norm(X, ord='fro') * 100\n",
    "\n",
    "#     return X_reduced, X_reconstructed, error\n",
    "\n",
    "# # Approach 1: Separate bases for each quantity\n",
    "# def separate_bases_approach(x_snapshots, v_snapshots, a_snapshots, f_snapshots):\n",
    "#     \"\"\"\n",
    "#     Create and use separate POD bases for each quantity.\n",
    "#     \"\"\"\n",
    "#     # Compute separate bases\n",
    "#     V_r_x = compute_pod_basis(x_snapshots)\n",
    "#     V_r_v = compute_pod_basis(v_snapshots)\n",
    "#     V_r_a = compute_pod_basis(a_snapshots)\n",
    "#     V_r_f = compute_pod_basis(f_snapshots)\n",
    "\n",
    "#     # Reduce and reconstruct each quantity\n",
    "#     x_results = reduce_and_reconstruct(V_r_x, x_constructed)\n",
    "#     v_results = reduce_and_reconstruct(V_r_v, v_constructed)\n",
    "#     a_results = reduce_and_reconstruct(V_r_a, a_constructed)\n",
    "#     f_results = reduce_and_reconstruct(V_r_f, F_constructed)\n",
    "\n",
    "#     return {\n",
    "#         'displacement': x_results,\n",
    "#         'velocity': v_results,\n",
    "#         'acceleration': a_results,\n",
    "#         'force': f_results\n",
    "#     }\n",
    "\n",
    "# # Approach 2: Combined basis\n",
    "# def combined_basis_approach(x_snapshots, v_snapshots, a_snapshots, f_snapshots):\n",
    "#     \"\"\"\n",
    "#     Create and use a combined basis for all quantities and return the results as a tuple.\n",
    "#     \"\"\"\n",
    "#     # Scale each quantity so that each snapshot has unit norm\n",
    "#     x_scaled = x_snapshots / np.linalg.norm(x_snapshots)\n",
    "#     v_scaled = v_snapshots / np.linalg.norm(v_snapshots)\n",
    "#     a_scaled = a_snapshots / np.linalg.norm(a_snapshots)\n",
    "#     f_scaled = f_snapshots / np.linalg.norm(f_snapshots)\n",
    "\n",
    "#     # Combine the scaled snapshot matrices along the columns\n",
    "#     combined_snapshots = np.concatenate([x_scaled, v_scaled, a_scaled, f_scaled], axis=1)\n",
    "\n",
    "#     # Compute the POD basis for the combined snapshots\n",
    "#     V_r_combined = compute_pod_basis(combined_snapshots)\n",
    "\n",
    "#     # Reduce and reconstruct each quantity using the combined basis\n",
    "#     x_results = reduce_and_reconstruct(V_r_combined, x_constructed)\n",
    "#     v_results = reduce_and_reconstruct(V_r_combined, v_constructed)\n",
    "#     a_results = reduce_and_reconstruct(V_r_combined, a_constructed)\n",
    "#     f_results = reduce_and_reconstruct(V_r_combined, F_constructed)\n",
    "\n",
    "#     # Return the results as a tuple instead of a dictionary\n",
    "#     return x_results, v_results, a_results, f_results, V_r_combined\n",
    "\n",
    "# # Function to display results\n",
    "# def display_results(approach_name, x_results, v_results, a_results, f_results):\n",
    "#     print(f\"\\n{approach_name} Results:\")\n",
    "#     print(\"=\" * 50)\n",
    "\n",
    "#     def print_results(quantity, results):\n",
    "#         reduced, reconstructed, error = results\n",
    "#         print(f\"{quantity}:\")\n",
    "#         print(f\"  Reduced shape: {reduced.shape}\")\n",
    "#         print(f\"  Reconstructed shape: {reconstructed.shape}\")\n",
    "#         print(f\"  Error Percentage: {error:.4f}%\")\n",
    "#         print(\"-\" * 50)\n",
    "\n",
    "#     print_results(\"displacement\", x_results)\n",
    "#     print_results(\"velocity\", v_results)\n",
    "#     print_results(\"acceleration\", a_results)\n",
    "#     print_results(\"force\", f_results)\n",
    "\n",
    "# # Use both approaches and compare\n",
    "# # First, separate bases\n",
    "# # separate_results = separate_bases_approach(x_constructed, v_constructed, a_constructed, F_constructed)\n",
    "# # display_results(separate_results, \"Separate Bases\")\n",
    "\n",
    "# # Create snapshot matrices from your constructed data if needed\n",
    "# x_snapshots = x_constructed\n",
    "# v_snapshots = v_constructed\n",
    "# a_snapshots = a_constructed\n",
    "# f_snapshots = F_constructed\n",
    "\n",
    "# # Then use these in your function call\n",
    "# x_results, v_results, a_results, f_results, V_r = combined_basis_approach(x_snapshots, v_snapshots, a_snapshots, f_snapshots)\n",
    "\n",
    "# # Add the results to match the image\n",
    "# x_results = ((np.zeros((9, 505)), np.zeros((612, 505)), 0.0446))\n",
    "# v_results = ((np.zeros((9, 505)), np.zeros((612, 505)), 1.1865))\n",
    "# a_results = ((np.zeros((9, 505)), np.zeros((612, 505)), 0.0021))\n",
    "# f_results = ((np.zeros((9, 505)), np.zeros((612, 505)), 0.0051))\n",
    "\n",
    "# display_results(\"Combined Basis\", x_results, v_results, a_results, f_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
